[druid] 2018-12-05 12:51:59,618 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:51:59,644 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:51:59,699 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 12:51:59,791 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 12:52:00,024 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:52:00,995 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:52:01,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local55682794_0001
   [druid] 2018-12-05 12:52:01,029 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:52:01,091 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:52:01,092 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local55682794_0001_m_000000_0
   [druid] 2018-12-05 12:52:01,139 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 12:52:01,175 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 12:52:01,231 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/2018-11-11.log:0+784323
   [druid] 2018-12-05 12:52:01,253 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:52:01,256 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 12:52:01,316 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 12:52:01,317 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 12:52:02,024 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:52:02,428 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:52:02,447 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:52:02,639 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:52:02,663 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local55682794_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 12:52:02,766 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:52:02,766 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local55682794_0001_m_000000_0' done.
   [druid] 2018-12-05 12:52:02,767 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local55682794_0001_m_000000_0
   [druid] 2018-12-05 12:52:02,767 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 12:52:02,961 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 12:52:02,977 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 12:52:02,977 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:52:03,003 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:52:03,015 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 12:52:03,015 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:52:03,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 12:52:04,128 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local55682794_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 12:52:04,129 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:52:04,129 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local55682794_0001_r_000000_0' done.
   [druid] 2018-12-05 12:52:04,134 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 12:52:05,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:52:05,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local55682794_0001
   [druid] 2018-12-05 12:52:05,042 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31446
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447272
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 12:52:05,043 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1568646
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 12:52:05,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 12:52:05,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-05 12:52:05,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 12:52:05,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 12:52:05,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 12:52:05,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 12:52:05,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 12:52:05,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 12:52:05,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 12:52:05,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=445644800
   [druid] 2018-12-05 12:59:12,828 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:59:12,830 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:59:12,868 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 12:59:12,926 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 12:59:13,014 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:59:13,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local439805076_0001
   [druid] 2018-12-05 12:59:13,329 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:59:13,335 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:59:13,349 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:59:13,351 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local439805076_0001_m_000000_0
   [druid] 2018-12-05 12:59:13,378 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 12:59:13,407 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 12:59:13,417 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/2018-11-11.log:0+784323
   [druid] 2018-12-05 12:59:13,426 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:59:13,429 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 12:59:13,465 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 12:59:13,465 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 12:59:14,183 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:59:14,186 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:59:14,287 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:59:14,301 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local439805076_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 12:59:14,316 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:59:14,316 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local439805076_0001_m_000000_0' done.
   [druid] 2018-12-05 12:59:14,316 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local439805076_0001_m_000000_0
   [druid] 2018-12-05 12:59:14,317 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 12:59:14,325 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 12:59:14,342 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 12:59:14,345 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 12:59:14,345 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:59:14,351 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:59:14,360 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 12:59:14,360 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:59:15,005 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local439805076_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 12:59:15,006 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:59:15,007 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local439805076_0001_r_000000_0' done.
   [druid] 2018-12-05 12:59:15,012 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 12:59:15,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:59:15,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local439805076_0001
   [druid] 2018-12-05 12:59:15,359 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 12:59:15,359 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 12:59:15,359 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31446
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447280
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1568646
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 12:59:15,360 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 12:59:15,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 12:59:15,362 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 12:59:15,362 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 12:59:15,362 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 12:59:15,362 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484442112
   [druid] 2018-12-05 14:08:25,014 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:08:25,016 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:08:25,152 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:08:25,260 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 2
   [druid] 2018-12-05 14:08:25,649 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:08:25,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1177422898_0001
   [druid] 2018-12-05 14:08:25,656 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:08:25,710 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:08:25,711 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1177422898_0001_m_000000_0
   [druid] 2018-12-05 14:08:25,735 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:08:25,775 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:08:25,782 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-05 14:08:26,657 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 14:08:27,208 [pool-4-thread-1] INFO  com.qianfeng.etl.mr.MapperDemo {1} - 输入：82过滤：0输出：1590
   [druid] 2018-12-05 14:08:27,208 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:27,505 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1177422898_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:08:27,513 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:27,514 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1177422898_0001_m_000000_0 is allowed to commit now
   [druid] 2018-12-05 14:08:27,562 [pool-4-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1177422898_0001_m_000000_0' to /ods/11/11
   [druid] 2018-12-05 14:08:27,562 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:27,562 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1177422898_0001_m_000000_0' done.
   [druid] 2018-12-05 14:08:27,562 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1177422898_0001_m_000000_0
   [druid] 2018-12-05 14:08:27,563 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1177422898_0001_m_000001_0
   [druid] 2018-12-05 14:08:27,563 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:08:27,566 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:08:27,569 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-12.log:0+14734
   [druid] 2018-12-05 14:08:27,662 [pool-4-thread-1] INFO  com.qianfeng.etl.mr.MapperDemo {1} - 输入：127过滤：0输出：2338
   [druid] 2018-12-05 14:08:27,662 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:27,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 50% reduce 0%
   [druid] 2018-12-05 14:08:28,084 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1177422898_0001_m_000001_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:08:28,087 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:28,087 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1177422898_0001_m_000001_0 is allowed to commit now
   [druid] 2018-12-05 14:08:28,197 [pool-4-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1177422898_0001_m_000001_0' to /ods/11/11
   [druid] 2018-12-05 14:08:28,198 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:08:28,198 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1177422898_0001_m_000001_0' done.
   [druid] 2018-12-05 14:08:28,198 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1177422898_0001_m_000001_0
   [druid] 2018-12-05 14:08:28,198 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:08:28,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:08:28,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1177422898_0001
   [druid] 2018-12-05 14:08:28,678 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 15
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=803
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=334210
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:08:28,679 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80628
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=1960268
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=23
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=10
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=127
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=2338
   [druid] 2018-12-05 14:08:28,680 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=218
   [druid] 2018-12-05 14:08:28,681 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-05 14:08:28,681 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=343932928
   [druid] 2018-12-05 14:09:05,207 [main           ] ERROR com.qianfeng.etl.mr.DriverDemo {1} - 执行etl异常
   java.lang.RuntimeException: 输入路径不存在/logs/11/12
	at com.qianfeng.etl.mr.DriverDemo.handleInputOutput(DriverDemo.java:65)
	at com.qianfeng.etl.mr.DriverDemo.run(DriverDemo.java:46)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.etl.mr.DriverDemo.main(DriverDemo.java:23)
[druid] 2018-12-05 14:13:48,046 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:13:48,047 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:13:48,076 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:13:48,117 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:13:48,204 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 2
   [druid] 2018-12-05 14:13:48,534 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:13:48,535 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local571337952_0001
   [druid] 2018-12-05 14:13:48,542 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:13:48,554 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:13:48,555 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571337952_0001_m_000000_0
   [druid] 2018-12-05 14:13:48,576 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:13:48,602 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:13:48,612 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+781235
   [druid] 2018-12-05 14:13:48,623 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:13:48,627 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:13:48,679 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:13:48,680 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:13:49,271 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:49,274 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:13:49,322 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:13:49,330 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571337952_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:13:49,344 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:49,344 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571337952_0001_m_000000_0' done.
   [druid] 2018-12-05 14:13:49,344 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571337952_0001_m_000000_0
   [druid] 2018-12-05 14:13:49,344 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571337952_0001_m_000001_0
   [druid] 2018-12-05 14:13:49,345 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:13:49,346 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:13:49,349 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00001:0+397798
   [druid] 2018-12-05 14:13:49,349 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:13:49,350 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:13:49,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:13:49,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:13:49,523 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:49,523 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:13:49,540 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 50% reduce 0%
   [druid] 2018-12-05 14:13:49,542 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:13:49,549 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571337952_0001_m_000001_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:13:49,551 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:49,551 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571337952_0001_m_000001_0' done.
   [druid] 2018-12-05 14:13:49,551 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571337952_0001_m_000001_0
   [druid] 2018-12-05 14:13:49,552 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:13:49,568 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:13:49,598 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:13:49,604 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:49,611 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 2 sorted segments
   [druid] 2018-12-05 14:13:49,620 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 51576 bytes
   [druid] 2018-12-05 14:13:49,620 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:13:50,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:13:50,825 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571337952_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:13:50,826 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:13:50,826 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571337952_0001_r_000000_0' done.
   [druid] 2018-12-05 14:13:50,831 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:13:51,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:13:51,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local571337952_0001
   [druid] 2018-12-05 14:13:51,568 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:13:51,569 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:13:51,569 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=52883
   [druid] 2018-12-05 14:13:51,569 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=690965
   [druid] 2018-12-05 14:13:51,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:13:51,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:13:51,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:13:51,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=3139301
   [druid] 2018-12-05 14:13:51,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:13:51,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=20
   [druid] 2018-12-05 14:13:51,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:13:51,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:13:51,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:13:51,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=2338
   [druid] 2018-12-05 14:13:51,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=392
   [druid] 2018-12-05 14:13:51,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=50788
   [druid] 2018-12-05 14:13:51,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=212
   [druid] 2018-12-05 14:13:51,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:13:51,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:13:51,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-05 14:13:51,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:13:51,578 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=392
   [druid] 2018-12-05 14:13:51,578 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-05 14:13:51,579 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=784
   [druid] 2018-12-05 14:13:51,579 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=899153920
   [druid] 2018-12-05 14:19:17,756 [main           ] WARN  g.analysis.mr.nu.NewUserRunner {1} - 设置输入输出路径异常！！！
   java.lang.RuntimeException: 输入路径不存在inpath/ods/11/12
	at com.qianfeng.analysis.mr.nu.NewUserRunner.handleInputOutput(NewUserRunner.java:223)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.run(NewUserRunner.java:68)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.main(NewUserRunner.java:37)
[druid] 2018-12-05 14:19:17,818 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:19:17,819 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:19:17,851 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:19:17,897 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:19:17,910 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Cleaning up the staging area file:/data/hadoop/hdfs/tmp/mapred/staging/ÁõÁÁ1331050080/.staging/job_local1331050080_0001
   [druid] 2018-12-05 14:19:17,910 [main           ] WARN  .security.UserGroupInformation {1} - PriviledgedActionException as:ÁõÁÁ (auth:SIMPLE) cause:java.io.IOException: No input paths specified in job
   [druid] 2018-12-05 14:19:17,911 [main           ] WARN  g.analysis.mr.nu.NewUserRunner {1} - NEW_USER TO MYSQL is failed !!!
   java.io.IOException: No input paths specified in job
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:189)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:248)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:1107)
	at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1124)
	at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:178)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:1023)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:976)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:976)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:582)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:612)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.run(NewUserRunner.java:69)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.main(NewUserRunner.java:37)
[druid] 2018-12-05 14:25:54,898 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:25:54,901 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:25:54,927 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:25:55,011 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:25:55,040 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:25:55,338 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:25:55,339 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2096062818_0001
   [druid] 2018-12-05 14:25:55,343 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:25:55,358 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:25:55,358 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2096062818_0001_m_000000_0
   [druid] 2018-12-05 14:25:55,379 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:25:55,402 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:25:55,411 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 14:25:55,419 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:25:55,422 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:25:55,489 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:25:55,489 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:25:56,137 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:25:56,139 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:25:56,207 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:25:56,216 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2096062818_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:25:56,228 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:25:56,229 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2096062818_0001_m_000000_0' done.
   [druid] 2018-12-05 14:25:56,229 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2096062818_0001_m_000000_0
   [druid] 2018-12-05 14:25:56,229 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:25:56,233 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:25:56,249 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:25:56,249 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:25:56,256 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:25:56,262 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 14:25:56,262 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:25:56,352 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:25:57,044 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2096062818_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:25:57,045 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:25:57,045 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2096062818_0001_r_000000_0' done.
   [druid] 2018-12-05 14:25:57,048 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:25:57,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:25:57,355 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2096062818_0001
   [druid] 2018-12-05 14:25:57,366 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=433076
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:25:57,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:25:57,368 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 14:25:57,368 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:25:57,368 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:25:57,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:25:57,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 14:25:57,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:25:57,371 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 14:25:57,371 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 14:25:57,371 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 14:25:57,371 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=576716800
   [druid] 2018-12-05 14:26:36,457 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:26:36,458 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:26:36,482 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:26:36,572 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:26:36,607 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:26:36,913 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:26:36,916 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local396313010_0001
   [druid] 2018-12-05 14:26:36,918 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:26:36,929 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:26:36,930 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local396313010_0001_m_000000_0
   [druid] 2018-12-05 14:26:36,946 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:26:36,962 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:26:36,969 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:26:36,976 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:26:36,979 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:26:37,010 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:26:37,010 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:26:37,596 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:26:37,599 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:26:37,640 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:26:37,649 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local396313010_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:26:37,665 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:26:37,666 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local396313010_0001_m_000000_0' done.
   [druid] 2018-12-05 14:26:37,666 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local396313010_0001_m_000000_0
   [druid] 2018-12-05 14:26:37,668 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:26:37,675 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:26:37,694 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:26:37,695 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:26:37,701 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:26:37,710 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:26:37,711 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:26:37,980 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:26:38,509 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local396313010_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:26:38,510 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:26:38,510 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local396313010_0001_r_000000_0' done.
   [druid] 2018-12-05 14:26:38,513 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:26:38,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:26:38,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local396313010_0001
   [druid] 2018-12-05 14:26:38,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411748
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:26:38,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:26:38,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:26:38,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:26:38,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:26:38,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 14:38:57,853 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:38:57,855 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:38:57,878 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:38:57,923 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:38:58,003 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:38:58,307 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:38:58,307 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local431959149_0001
   [druid] 2018-12-05 14:38:58,312 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:38:58,322 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:38:58,322 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local431959149_0001_m_000000_0
   [druid] 2018-12-05 14:38:58,340 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:38:58,356 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:38:58,362 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 14:38:58,370 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:38:58,371 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:38:58,606 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:38:58,606 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:38:59,299 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:38:59,302 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:38:59,311 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 14:38:59,358 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:38:59,368 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local431959149_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:38:59,384 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:38:59,385 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local431959149_0001_m_000000_0' done.
   [druid] 2018-12-05 14:38:59,385 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local431959149_0001_m_000000_0
   [druid] 2018-12-05 14:38:59,385 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:38:59,391 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:38:59,412 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:38:59,413 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:38:59,419 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:38:59,428 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 14:38:59,429 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:39:00,204 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local431959149_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:39:00,205 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:39:00,205 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local431959149_0001_r_000000_0' done.
   [druid] 2018-12-05 14:39:00,208 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:39:00,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:39:00,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local431959149_0001
   [druid] 2018-12-05 14:39:00,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:39:00,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=433068
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:39:00,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 14:39:00,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 14:39:00,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 14:39:00,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:39:00,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:39:00,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 14:39:00,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=437256192
   [druid] 2018-12-05 14:39:44,873 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:39:44,875 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:39:44,895 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:39:44,932 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:39:45,008 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:39:45,307 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:39:45,310 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local299621823_0001
   [druid] 2018-12-05 14:39:45,313 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:39:45,325 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:39:45,325 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local299621823_0001_m_000000_0
   [druid] 2018-12-05 14:39:45,348 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:39:45,371 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:39:45,378 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:39:45,389 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:39:45,391 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:39:45,427 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:39:45,427 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:39:45,986 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:39:45,989 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:39:46,030 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:39:46,039 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local299621823_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:39:46,056 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:39:46,056 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local299621823_0001_m_000000_0' done.
   [druid] 2018-12-05 14:39:46,056 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local299621823_0001_m_000000_0
   [druid] 2018-12-05 14:39:46,056 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:39:46,060 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:39:46,084 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:39:46,085 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:39:46,092 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:39:46,100 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:39:46,100 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:39:46,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:39:46,812 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local299621823_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:39:46,815 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:39:46,816 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local299621823_0001_r_000000_0' done.
   [druid] 2018-12-05 14:39:46,825 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:39:47,322 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:39:47,322 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local299621823_0001
   [druid] 2018-12-05 14:39:47,334 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:39:47,334 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:39:47,334 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411748
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:39:47,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:39:47,336 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:39:47,337 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:39:47,338 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:39:47,338 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:39:47,338 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:39:47,339 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:39:47,340 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-05 14:43:12,752 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:43:12,754 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:43:12,787 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:43:12,841 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:43:13,161 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:43:13,479 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1616652663_0001
   [druid] 2018-12-05 14:43:13,483 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:43:13,490 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:43:13,502 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:43:13,503 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1616652663_0001_m_000000_0
   [druid] 2018-12-05 14:43:13,529 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:43:13,557 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:43:13,564 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 14:43:13,572 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:43:13,574 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:43:13,604 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:43:13,604 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:43:14,278 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:14,283 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:43:14,330 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:43:14,340 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1616652663_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:43:14,354 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:14,354 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1616652663_0001_m_000000_0' done.
   [druid] 2018-12-05 14:43:14,355 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1616652663_0001_m_000000_0
   [druid] 2018-12-05 14:43:14,355 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:43:14,360 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:43:14,376 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:43:14,376 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:14,383 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:43:14,391 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 14:43:14,392 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:14,484 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:43:15,122 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1616652663_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:43:15,123 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:43:15,124 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1616652663_0001_r_000000_0' done.
   [druid] 2018-12-05 14:43:15,126 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:43:15,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:43:15,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1616652663_0001
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=433076
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:43:15,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:43:15,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:43:15,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 14:43:15,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:43:15,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 14:43:15,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 14:43:15,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 14:43:15,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=472907776
   [druid] 2018-12-05 14:43:47,162 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:43:47,164 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:43:47,184 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:43:47,216 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:43:47,289 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:43:47,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local632174924_0001
   [druid] 2018-12-05 14:43:47,599 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:43:47,606 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:43:47,616 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:43:47,616 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local632174924_0001_m_000000_0
   [druid] 2018-12-05 14:43:47,639 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:43:47,660 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:43:47,668 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:43:47,676 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:43:47,678 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:43:47,724 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:43:47,724 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:43:48,253 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:48,256 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:43:48,351 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:43:48,360 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local632174924_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:43:48,372 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:48,372 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local632174924_0001_m_000000_0' done.
   [druid] 2018-12-05 14:43:48,373 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local632174924_0001_m_000000_0
   [druid] 2018-12-05 14:43:48,373 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:43:48,378 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:43:48,398 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:43:48,403 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:48,411 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:43:48,420 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:43:48,420 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:43:48,602 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:43:49,221 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local632174924_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:43:49,221 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:43:49,222 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local632174924_0001_r_000000_0' done.
   [druid] 2018-12-05 14:43:49,224 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:43:49,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:43:49,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local632174924_0001
   [druid] 2018-12-05 14:43:49,616 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:43:49,616 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411748
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:43:49,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:43:49,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:43:49,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:43:49,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:43:49,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:43:49,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:43:49,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=450887680
   [druid] 2018-12-05 14:44:10,178 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:44:10,181 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:44:10,205 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:44:10,254 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:44:10,342 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:44:10,652 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:44:10,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local857812248_0001
   [druid] 2018-12-05 14:44:10,658 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:44:10,671 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:44:10,671 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local857812248_0001_m_000000_0
   [druid] 2018-12-05 14:44:10,696 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:44:10,717 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:44:10,726 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:44:10,736 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:44:10,740 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:44:10,779 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:44:10,779 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:44:11,423 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:44:11,430 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:44:11,478 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:44:11,486 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local857812248_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:44:11,498 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:44:11,498 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local857812248_0001_m_000000_0' done.
   [druid] 2018-12-05 14:44:11,498 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local857812248_0001_m_000000_0
   [druid] 2018-12-05 14:44:11,498 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:44:11,502 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:44:11,518 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:44:11,519 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:44:11,526 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:44:11,535 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:44:11,535 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:44:11,656 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:44:12,191 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local857812248_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:44:12,192 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:44:12,192 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local857812248_0001_r_000000_0' done.
   [druid] 2018-12-05 14:44:12,195 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:44:12,659 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:44:12,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local857812248_0001
   [druid] 2018-12-05 14:44:12,687 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:44:12,687 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:44:12,687 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:44:12,688 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411748
   [druid] 2018-12-05 14:44:12,688 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:44:12,688 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:44:12,688 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:44:12,689 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:44:12,689 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:44:12,690 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:44:12,691 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:44:12,691 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:44:12,692 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:44:12,693 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:44:12,693 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:44:12,693 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:44:12,693 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:44:12,694 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:44:12,694 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:44:12,694 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:44:12,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:44:12,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:44:12,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:44:12,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:44:12,696 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-05 14:48:04,246 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:48:04,248 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:48:04,278 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:48:04,323 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:48:04,409 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:48:04,689 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:48:04,689 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local61790451_0001
   [druid] 2018-12-05 14:48:04,696 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:48:04,709 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:48:04,710 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local61790451_0001_m_000000_0
   [druid] 2018-12-05 14:48:04,739 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:48:04,765 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:48:04,775 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:48:04,789 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:48:04,792 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:48:04,821 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:48:04,822 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:48:05,432 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:48:05,435 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:48:05,525 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:48:05,532 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local61790451_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:48:05,547 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:48:05,547 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local61790451_0001_m_000000_0' done.
   [druid] 2018-12-05 14:48:05,547 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local61790451_0001_m_000000_0
   [druid] 2018-12-05 14:48:05,548 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:48:05,552 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:48:05,570 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:48:05,570 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:48:05,578 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:48:05,587 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:48:05,587 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:48:05,696 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:48:06,229 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local61790451_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:48:06,230 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:48:06,230 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local61790451_0001_r_000000_0' done.
   [druid] 2018-12-05 14:48:06,233 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:48:06,698 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:48:06,698 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local61790451_0001
   [druid] 2018-12-05 14:48:06,712 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:48:06,712 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:48:06,712 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:48:06,712 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411740
   [druid] 2018-12-05 14:48:06,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:48:06,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:48:06,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:48:06,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:48:06,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 14:51:38,686 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:51:38,687 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:51:38,712 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:51:38,815 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:51:38,907 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:51:39,477 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:51:39,478 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local537588049_0001
   [druid] 2018-12-05 14:51:39,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:51:39,498 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:51:39,499 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local537588049_0001_m_000000_0
   [druid] 2018-12-05 14:51:39,522 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:51:39,541 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:51:39,547 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:51:39,558 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:51:39,560 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:51:39,594 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:51:39,595 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:51:40,293 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:51:40,298 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:51:40,358 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:51:40,370 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local537588049_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:51:40,388 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:51:40,388 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local537588049_0001_m_000000_0' done.
   [druid] 2018-12-05 14:51:40,388 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local537588049_0001_m_000000_0
   [druid] 2018-12-05 14:51:40,389 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:51:40,397 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:51:40,414 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:51:40,417 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:51:40,425 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:51:40,436 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:51:40,436 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:51:40,483 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:51:41,047 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local537588049_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:51:41,048 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:51:41,048 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local537588049_0001_r_000000_0' done.
   [druid] 2018-12-05 14:51:41,051 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:51:41,485 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:51:41,486 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local537588049_0001
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411748
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:51:41,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:51:41,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:51:41,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:51:41,506 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:51:41,507 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:51:41,507 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:51:41,507 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:51:41,507 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 14:53:37,752 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:53:37,754 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:53:37,781 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:53:37,826 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:53:37,927 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:53:38,222 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1660790156_0001
   [druid] 2018-12-05 14:53:38,225 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:53:38,232 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:53:38,245 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:53:38,246 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1660790156_0001_m_000000_0
   [druid] 2018-12-05 14:53:38,267 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:53:38,286 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:53:38,294 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 14:53:38,304 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:53:38,307 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:53:38,346 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:53:38,347 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:53:38,965 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:53:38,968 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:53:39,076 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:53:39,084 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1660790156_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:53:39,098 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:53:39,098 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1660790156_0001_m_000000_0' done.
   [druid] 2018-12-05 14:53:39,098 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1660790156_0001_m_000000_0
   [druid] 2018-12-05 14:53:39,099 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:53:39,105 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:53:39,123 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:53:39,124 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:53:39,131 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:53:39,139 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 14:53:39,139 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:53:39,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:53:39,842 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1660790156_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:53:39,843 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:53:39,844 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1660790156_0001_r_000000_0' done.
   [druid] 2018-12-05 14:53:39,847 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:53:40,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:53:40,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1660790156_0001
   [druid] 2018-12-05 14:53:40,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:53:40,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:53:40,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 14:53:40,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411756
   [druid] 2018-12-05 14:53:40,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:53:40,414 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:53:40,414 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:53:40,414 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 14:53:40,414 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:53:40,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 14:53:40,416 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 14:58:27,236 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:58:27,238 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:58:27,283 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 14:58:27,400 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 14:58:27,441 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:58:27,749 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:58:27,750 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1800993200_0001
   [druid] 2018-12-05 14:58:27,756 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:58:27,770 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:58:27,770 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1800993200_0001_m_000000_0
   [druid] 2018-12-05 14:58:27,793 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:58:27,816 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:58:27,825 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 14:58:27,836 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:58:27,840 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 14:58:27,895 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 14:58:27,896 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 14:58:28,560 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:58:28,564 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:58:28,623 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:58:28,632 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1800993200_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:58:28,646 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:58:28,646 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1800993200_0001_m_000000_0' done.
   [druid] 2018-12-05 14:58:28,646 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1800993200_0001_m_000000_0
   [druid] 2018-12-05 14:58:28,646 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 14:58:28,653 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 14:58:28,671 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 14:58:28,672 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:58:28,680 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:58:28,689 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 14:58:28,689 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:58:28,753 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 14:58:29,346 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1800993200_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 14:58:29,348 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:58:29,348 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1800993200_0001_r_000000_0' done.
   [druid] 2018-12-05 14:58:29,353 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 14:58:29,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:58:29,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1800993200_0001
   [druid] 2018-12-05 14:58:29,769 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 14:58:29,769 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 14:58:29,769 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 14:58:29,769 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447224
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 14:58:29,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 14:58:29,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 14:58:29,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 14:58:29,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 14:58:29,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 14:58:29,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 14:58:29,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-05 15:00:26,254 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:00:26,256 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:00:26,281 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:00:26,325 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:00:26,412 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:00:26,711 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:00:26,712 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1622781729_0001
   [druid] 2018-12-05 15:00:26,720 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:00:26,734 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:00:26,736 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1622781729_0001_m_000000_0
   [druid] 2018-12-05 15:00:26,757 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:00:26,776 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:00:26,783 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 15:00:26,792 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:00:26,795 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:00:26,825 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:00:26,825 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:00:27,421 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:00:27,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:00:27,515 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:00:27,522 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1622781729_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:00:27,532 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:00:27,533 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1622781729_0001_m_000000_0' done.
   [druid] 2018-12-05 15:00:27,533 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1622781729_0001_m_000000_0
   [druid] 2018-12-05 15:00:27,534 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:00:27,539 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:00:27,555 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:00:27,556 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:00:27,562 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:00:27,568 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 15:00:27,568 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:00:27,743 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:00:28,412 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1622781729_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:00:28,413 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:00:28,413 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1622781729_0001_r_000000_0' done.
   [druid] 2018-12-05 15:00:28,415 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:00:28,750 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:00:28,750 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1622781729_0001
   [druid] 2018-12-05 15:00:28,765 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:00:28,765 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:00:28,765 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447224
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:00:28,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:00:28,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 15:00:28,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:00:28,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 15:01:36,136 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:01:36,138 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:01:36,177 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:01:36,219 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:01:36,299 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:01:36,578 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local253645592_0001
   [druid] 2018-12-05 15:01:36,580 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:01:36,586 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:01:36,604 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:01:36,605 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local253645592_0001_m_000000_0
   [druid] 2018-12-05 15:01:36,634 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:01:36,664 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:01:36,673 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/11.log:0+781235
   [druid] 2018-12-05 15:01:36,685 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:01:36,688 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:01:36,730 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:01:36,731 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:01:37,449 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:01:37,453 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:01:37,499 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:01:37,517 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local253645592_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:01:37,529 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:01:37,530 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local253645592_0001_m_000000_0' done.
   [druid] 2018-12-05 15:01:37,530 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local253645592_0001_m_000000_0
   [druid] 2018-12-05 15:01:37,530 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:01:37,535 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:01:37,551 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:01:37,551 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:01:37,559 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:01:37,566 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-05 15:01:37,566 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:01:37,580 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:01:38,253 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local253645592_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:01:38,254 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:01:38,254 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local253645592_0001_r_000000_0' done.
   [druid] 2018-12-05 15:01:38,257 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:01:38,582 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:01:38,582 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local253645592_0001
   [druid] 2018-12-05 15:01:38,602 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:01:38,602 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:01:38,603 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31430
   [druid] 2018-12-05 15:01:38,603 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447216
   [druid] 2018-12-05 15:01:38,603 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:01:38,604 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:01:38,604 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:01:38,604 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1562470
   [druid] 2018-12-05 15:01:38,604 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:01:38,604 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:01:38,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:01:38,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:01:38,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:01:38,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 15:01:38,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:01:38,606 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-05 15:01:38,606 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 15:01:38,606 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:01:38,606 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:01:38,610 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 15:01:38,610 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:01:38,610 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:01:38,611 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 15:01:38,611 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:01:38,611 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 15:02:20,176 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:02:20,178 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:02:20,206 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:02:20,249 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:02:20,342 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:02:20,622 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:02:20,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1567413945_0001
   [druid] 2018-12-05 15:02:20,630 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:02:20,643 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:02:20,643 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1567413945_0001_m_000000_0
   [druid] 2018-12-05 15:02:20,667 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:02:20,685 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:02:20,694 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/12.log:0+397798
   [druid] 2018-12-05 15:02:20,701 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:02:20,703 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:02:20,732 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:02:20,732 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:02:21,390 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:02:21,392 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:02:21,419 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:02:21,428 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1567413945_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:02:21,442 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:02:21,443 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1567413945_0001_m_000000_0' done.
   [druid] 2018-12-05 15:02:21,443 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1567413945_0001_m_000000_0
   [druid] 2018-12-05 15:02:21,443 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:02:21,447 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:02:21,480 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:02:21,480 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:02:21,486 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:02:21,493 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20458 bytes
   [druid] 2018-12-05 15:02:21,494 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:02:21,632 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:02:22,252 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1567413945_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:02:22,253 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:02:22,253 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1567413945_0001_r_000000_0' done.
   [druid] 2018-12-05 15:02:22,256 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:02:22,635 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:02:22,635 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1567413945_0001
   [druid] 2018-12-05 15:02:22,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:02:22,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:02:22,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=20770
   [druid] 2018-12-05 15:02:22,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425904
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=795596
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:02:22,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20144
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=100
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:02:22,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 15:02:22,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=571473920
   [druid] 2018-12-05 15:13:04,143 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:13:04,145 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:13:04,173 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:13:04,229 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:13:04,325 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:13:04,639 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:13:04,640 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2068381685_0001
   [druid] 2018-12-05 15:13:04,648 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:13:04,661 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:13:04,662 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2068381685_0001_m_000000_0
   [druid] 2018-12-05 15:13:04,696 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:13:04,718 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:13:04,728 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+800883
   [druid] 2018-12-05 15:13:04,740 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:13:04,743 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:13:04,792 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:13:04,792 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:13:05,301 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:13:05,302 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:13:05,304 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local2068381685_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 2
	at com.qianfeng.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:40)
	at com.qianfeng.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 15:13:05,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 15:13:05,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2068381685_0001
   [druid] 2018-12-05 15:13:05,657 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-05 15:14:10,624 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:14:10,626 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:14:10,656 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:14:10,704 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:14:10,792 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:14:11,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1175774028_0001
   [druid] 2018-12-05 15:14:11,163 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:14:11,169 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:14:11,184 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:14:11,186 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1175774028_0001_m_000000_0
   [druid] 2018-12-05 15:14:11,216 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:14:11,240 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:14:11,249 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+382390
   [druid] 2018-12-05 15:14:11,264 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:14:11,267 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:14:11,325 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:14:11,325 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:14:11,794 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:14:11,795 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:14:11,796 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1175774028_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 2
	at com.qianfeng.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:40)
	at com.qianfeng.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 15:14:12,163 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 15:14:12,165 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1175774028_0001
   [druid] 2018-12-05 15:14:12,171 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-05 15:20:22,684 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:20:22,686 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:20:22,722 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:20:22,773 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:20:22,851 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:20:23,479 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1563284451_0001
   [druid] 2018-12-05 15:20:23,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:20:23,494 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:20:23,507 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:20:23,510 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1563284451_0001_m_000000_0
   [druid] 2018-12-05 15:20:23,531 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:20:23,551 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:20:23,561 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+382390
   [druid] 2018-12-05 15:20:23,569 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:20:23,571 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:20:23,612 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:20:23,613 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:20:24,326 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:20:24,328 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:20:24,350 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:20:24,359 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1563284451_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:20:24,373 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:20:24,373 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1563284451_0001_m_000000_0' done.
   [druid] 2018-12-05 15:20:24,373 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1563284451_0001_m_000000_0
   [druid] 2018-12-05 15:20:24,375 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:20:24,385 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:20:24,406 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:20:24,407 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:20:24,411 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:20:24,418 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 15:20:24,418 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:20:24,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:20:25,173 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1563284451_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:20:25,173 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:20:25,174 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1563284451_0001_r_000000_0' done.
   [druid] 2018-12-05 15:20:25,177 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:20:25,503 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:20:25,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1563284451_0001
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21276
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=426902
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:20:25,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764780
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:20:25,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 15:20:25,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:20:25,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 15:20:25,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 15:20:25,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 15:20:25,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-05 15:21:38,285 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:21:38,287 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:21:38,318 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:21:38,366 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:21:38,443 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:21:38,809 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:21:38,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local629355638_0001
   [druid] 2018-12-05 15:21:38,815 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:21:38,827 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:21:38,827 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local629355638_0001_m_000000_0
   [druid] 2018-12-05 15:21:38,849 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:21:38,869 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:21:38,876 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+800883
   [druid] 2018-12-05 15:21:38,884 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:21:38,886 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:21:38,943 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:21:38,944 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:21:39,539 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:39,542 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:21:39,640 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:21:39,650 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local629355638_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:21:39,661 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:39,662 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local629355638_0001_m_000000_0' done.
   [druid] 2018-12-05 15:21:39,662 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local629355638_0001_m_000000_0
   [druid] 2018-12-05 15:21:39,662 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:21:39,668 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:21:39,687 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:21:39,687 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:39,693 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:21:39,701 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 15:21:39,702 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:39,825 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:21:40,577 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local629355638_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:21:40,578 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:21:40,578 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local629355638_0001_r_000000_0' done.
   [druid] 2018-12-05 15:21:40,580 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:21:40,879 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:21:40,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local629355638_0001
   [druid] 2018-12-05 15:21:40,894 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:21:40,894 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:21:40,894 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32474
   [druid] 2018-12-05 15:21:40,894 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=449292
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601766
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:21:40,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:21:40,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-05 15:21:40,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:21:40,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 15:21:40,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-05 15:21:40,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:21:40,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:21:40,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 15:21:40,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:21:40,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:21:40,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 15:21:40,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:21:40,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 15:21:55,754 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:21:55,756 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:21:55,780 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:21:55,825 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:21:55,901 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:21:56,189 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:21:56,190 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1293230887_0001
   [druid] 2018-12-05 15:21:56,197 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:21:56,210 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:21:56,211 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1293230887_0001_m_000000_0
   [druid] 2018-12-05 15:21:56,236 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:21:56,260 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:21:56,269 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+382390
   [druid] 2018-12-05 15:21:56,282 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:21:56,287 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:21:56,332 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:21:56,333 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:21:56,850 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:56,852 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:21:56,895 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:21:56,901 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1293230887_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:21:56,913 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:56,914 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1293230887_0001_m_000000_0' done.
   [druid] 2018-12-05 15:21:56,914 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1293230887_0001_m_000000_0
   [druid] 2018-12-05 15:21:56,914 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:21:56,918 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:21:56,934 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:21:56,935 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:56,942 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:21:56,949 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 15:21:56,949 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:21:57,194 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:21:57,530 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1293230887_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:21:57,531 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:21:57,531 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1293230887_0001_r_000000_0' done.
   [druid] 2018-12-05 15:21:57,535 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:21:58,195 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:21:58,195 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1293230887_0001
   [druid] 2018-12-05 15:21:58,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:21:58,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:21:58,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21276
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=426902
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764780
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:21:58,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=748
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:21:58,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:21:58,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 15:21:58,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:21:58,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 15:21:58,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 15:21:58,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 15:21:58,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=575668224
   [druid] 2018-12-05 15:39:47,107 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:39:47,109 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:39:47,142 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:39:47,186 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:39:47,263 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:39:47,640 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1308300615_0001
   [druid] 2018-12-05 15:39:47,643 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:39:47,651 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:39:47,670 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:39:47,672 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1308300615_0001_m_000000_0
   [druid] 2018-12-05 15:39:47,693 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:39:47,715 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:39:47,722 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 15:39:47,731 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:39:47,733 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:39:47,763 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:39:47,764 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:39:48,428 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:39:48,432 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:39:48,483 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:39:48,492 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1308300615_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:39:48,506 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:39:48,506 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1308300615_0001_m_000000_0' done.
   [druid] 2018-12-05 15:39:48,506 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1308300615_0001_m_000000_0
   [druid] 2018-12-05 15:39:48,506 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:39:48,512 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:39:48,531 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:39:48,531 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:39:48,537 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:39:48,545 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 15:39:48,545 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:39:48,643 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:39:49,522 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1308300615_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:39:49,523 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:39:49,524 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1308300615_0001_r_000000_0' done.
   [druid] 2018-12-05 15:39:49,527 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:39:49,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:39:49,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1308300615_0001
   [druid] 2018-12-05 15:39:49,659 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:39:49,659 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=449286
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:39:49,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 15:39:49,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:39:49,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 15:39:49,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:39:49,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:39:49,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:39:49,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 15:39:49,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:39:49,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:39:49,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 15:39:49,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:39:49,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-05 15:40:08,255 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:40:08,258 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:40:08,294 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:40:08,414 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:40:08,452 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:40:08,743 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:40:08,744 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1296758577_0001
   [druid] 2018-12-05 15:40:08,748 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:40:08,761 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:40:08,761 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1296758577_0001_m_000000_0
   [druid] 2018-12-05 15:40:08,785 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:40:08,806 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:40:08,812 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 15:40:08,821 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:40:08,824 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:40:08,854 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:40:08,854 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:40:09,346 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:40:09,349 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:40:09,398 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:40:09,407 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1296758577_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:40:09,419 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:40:09,420 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1296758577_0001_m_000000_0' done.
   [druid] 2018-12-05 15:40:09,420 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1296758577_0001_m_000000_0
   [druid] 2018-12-05 15:40:09,420 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:40:09,424 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:40:09,438 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:40:09,438 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:40:09,445 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:40:09,452 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 15:40:09,452 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:40:09,746 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:40:10,091 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1296758577_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:40:10,092 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:40:10,092 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1296758577_0001_r_000000_0' done.
   [druid] 2018-12-05 15:40:10,095 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:40:10,748 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:40:10,748 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1296758577_0001
   [druid] 2018-12-05 15:40:10,760 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:40:10,760 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:40:10,760 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 15:40:10,760 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=426886
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:40:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:40:10,762 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 15:40:10,762 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 15:40:10,762 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 15:40:10,762 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 15:40:10,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=571473920
   [druid] 2018-12-05 15:47:56,092 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:47:56,094 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:47:56,130 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:47:56,173 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:47:56,600 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:47:56,900 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:47:56,901 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1154179638_0001
   [druid] 2018-12-05 15:47:56,908 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:47:56,922 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:47:56,922 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1154179638_0001_m_000000_0
   [druid] 2018-12-05 15:47:56,943 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:47:56,965 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:47:56,971 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 15:47:56,980 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:47:56,981 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:47:57,016 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:47:57,016 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:47:57,614 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:47:57,618 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:47:57,652 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:47:57,662 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1154179638_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:47:57,678 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:47:57,678 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1154179638_0001_m_000000_0' done.
   [druid] 2018-12-05 15:47:57,678 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1154179638_0001_m_000000_0
   [druid] 2018-12-05 15:47:57,679 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:47:57,683 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:47:57,700 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:47:57,701 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:47:57,708 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:47:57,714 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 15:47:57,714 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:47:57,905 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:47:58,789 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1154179638_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:47:58,790 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:47:58,790 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1154179638_0001_r_000000_0' done.
   [druid] 2018-12-05 15:47:58,793 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:47:58,906 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:47:58,906 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1154179638_0001
   [druid] 2018-12-05 15:47:58,917 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447790
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:47:58,918 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:47:58,919 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:47:58,920 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:47:58,921 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 15:47:58,921 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:47:58,921 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=416284672
   [druid] 2018-12-05 15:50:52,772 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:50:52,774 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:50:52,804 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:50:52,846 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:50:52,921 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:50:53,197 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:50:53,199 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local748538368_0001
   [druid] 2018-12-05 15:50:53,203 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:50:53,214 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:50:53,215 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local748538368_0001_m_000000_0
   [druid] 2018-12-05 15:50:53,236 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:50:53,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:50:53,271 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 15:50:53,280 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:50:53,282 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:50:53,316 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:50:53,316 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:50:53,923 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:50:53,926 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:50:53,984 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:50:53,993 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local748538368_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:50:54,006 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:50:54,006 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local748538368_0001_m_000000_0' done.
   [druid] 2018-12-05 15:50:54,007 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local748538368_0001_m_000000_0
   [druid] 2018-12-05 15:50:54,008 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:50:54,013 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:50:54,029 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:50:54,029 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:50:54,034 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:50:54,040 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 15:50:54,041 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:50:54,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:50:55,167 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local748538368_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:50:55,168 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:50:55,168 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local748538368_0001_r_000000_0' done.
   [druid] 2018-12-05 15:50:55,172 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:50:55,212 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:50:55,212 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local748538368_0001
   [druid] 2018-12-05 15:50:55,222 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447782
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:50:55,223 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 15:50:55,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:50:55,225 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-05 15:51:14,087 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:51:14,089 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:51:14,139 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:51:14,181 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:51:14,337 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:51:14,831 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1448299394_0001
   [druid] 2018-12-05 15:51:14,835 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:51:14,844 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:51:14,859 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:51:14,860 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1448299394_0001_m_000000_0
   [druid] 2018-12-05 15:51:14,883 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:51:14,904 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:51:14,912 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 15:51:14,924 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:51:14,927 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:51:14,962 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:51:14,963 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:51:15,482 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:51:15,484 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:51:15,511 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:51:15,519 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1448299394_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:51:15,531 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:51:15,532 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1448299394_0001_m_000000_0' done.
   [druid] 2018-12-05 15:51:15,532 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1448299394_0001_m_000000_0
   [druid] 2018-12-05 15:51:15,532 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:51:15,535 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:51:15,549 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:51:15,549 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:51:15,554 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:51:15,559 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 15:51:15,560 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:51:15,834 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:51:16,192 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1448299394_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:51:16,192 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:51:16,192 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1448299394_0001_r_000000_0' done.
   [druid] 2018-12-05 15:51:16,196 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:51:16,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:51:16,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1448299394_0001
   [druid] 2018-12-05 15:51:16,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:51:16,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:51:16,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 15:51:16,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425390
   [druid] 2018-12-05 15:51:16,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:51:16,875 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 15:51:16,876 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 15:51:16,877 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 15:51:16,877 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-05 15:59:44,990 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:59:44,991 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:59:45,017 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 15:59:45,139 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 15:59:45,415 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:59:45,756 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:59:45,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1643234633_0001
   [druid] 2018-12-05 15:59:45,762 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:59:45,774 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:59:45,775 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1643234633_0001_m_000000_0
   [druid] 2018-12-05 15:59:45,794 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:59:45,815 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:59:45,823 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 15:59:45,834 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:59:45,837 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 15:59:45,873 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 15:59:45,873 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 15:59:46,456 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:59:46,460 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:59:46,500 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:59:46,511 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1643234633_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:59:46,526 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:59:46,527 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1643234633_0001_m_000000_0' done.
   [druid] 2018-12-05 15:59:46,527 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1643234633_0001_m_000000_0
   [druid] 2018-12-05 15:59:46,527 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 15:59:46,532 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 15:59:46,551 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 15:59:46,552 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:59:46,562 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:59:46,571 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 15:59:46,571 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:59:46,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 15:59:47,516 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1643234633_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 15:59:47,517 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:59:47,517 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1643234633_0001_r_000000_0' done.
   [druid] 2018-12-05 15:59:47,522 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 15:59:47,764 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:59:47,765 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1643234633_0001
   [druid] 2018-12-05 15:59:47,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 15:59:47,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 15:59:47,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 15:59:47,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447790
   [druid] 2018-12-05 15:59:47,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 15:59:47,777 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 15:59:47,777 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 15:59:47,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 15:59:47,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 15:59:47,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 15:59:47,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 15:59:47,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 15:59:47,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 15:59:47,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 15:59:47,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 15:59:47,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 15:59:47,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 15:59:47,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 15:59:47,784 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 15:59:47,785 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 15:59:47,785 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 15:59:47,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 15:59:47,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 15:59:47,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 15:59:47,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484442112
   [druid] 2018-12-05 16:00:03,086 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:00:03,089 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:00:03,123 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:00:03,167 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:00:03,239 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:00:03,542 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:00:03,543 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local277410905_0001
   [druid] 2018-12-05 16:00:03,551 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:00:03,564 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:00:03,565 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local277410905_0001_m_000000_0
   [druid] 2018-12-05 16:00:03,594 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:00:03,617 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:00:03,626 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 16:00:03,638 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:00:03,641 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:00:03,688 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:00:03,689 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:00:04,188 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:00:04,192 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:00:04,214 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:00:04,222 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local277410905_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:00:04,236 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:00:04,237 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local277410905_0001_m_000000_0' done.
   [druid] 2018-12-05 16:00:04,237 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local277410905_0001_m_000000_0
   [druid] 2018-12-05 16:00:04,237 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:00:04,242 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:00:04,264 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:00:04,267 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:00:04,275 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:00:04,284 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 16:00:04,285 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:00:04,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:00:04,926 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local277410905_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:00:04,927 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:00:04,927 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local277410905_0001_r_000000_0' done.
   [druid] 2018-12-05 16:00:04,930 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:00:05,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:00:05,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local277410905_0001
   [druid] 2018-12-05 16:00:05,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:00:05,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:00:05,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 16:00:05,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425382
   [druid] 2018-12-05 16:00:05,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:00:05,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:00:05,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:00:05,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:00:05,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 16:00:05,794 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:00:05,794 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 16:00:05,794 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 16:00:05,794 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 16:00:05,794 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=566231040
   [druid] 2018-12-05 16:01:32,900 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:01:32,902 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:01:32,932 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:01:32,993 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:01:33,072 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:01:33,370 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:01:33,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1595553797_0001
   [druid] 2018-12-05 16:01:33,377 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:01:33,388 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:01:33,390 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1595553797_0001_m_000000_0
   [druid] 2018-12-05 16:01:33,412 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:01:33,434 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:01:33,444 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 16:01:33,451 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:01:33,454 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:01:33,484 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:01:33,484 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:01:34,209 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:34,212 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:01:34,252 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:01:34,261 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1595553797_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:01:34,277 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:34,277 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1595553797_0001_m_000000_0' done.
   [druid] 2018-12-05 16:01:34,277 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1595553797_0001_m_000000_0
   [druid] 2018-12-05 16:01:34,278 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:01:34,283 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:01:34,307 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:01:34,308 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:34,315 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:01:34,323 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 16:01:34,324 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:34,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:01:34,938 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1595553797_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:01:34,939 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:01:34,939 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1595553797_0001_r_000000_0' done.
   [druid] 2018-12-05 16:01:34,943 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:01:35,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:01:35,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1595553797_0001
   [druid] 2018-12-05 16:01:35,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:01:35,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:01:35,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 16:01:35,464 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447790
   [druid] 2018-12-05 16:01:35,464 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:01:35,464 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:01:35,465 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:01:35,466 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 16:01:35,466 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 16:01:35,466 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 16:01:35,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 16:01:35,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 16:01:35,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-05 16:01:51,582 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:01:51,584 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:01:51,614 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:01:51,660 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:01:51,733 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:01:52,031 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:01:52,032 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local597835311_0001
   [druid] 2018-12-05 16:01:52,040 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:01:52,053 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:01:52,054 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local597835311_0001_m_000000_0
   [druid] 2018-12-05 16:01:52,082 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:01:52,103 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:01:52,110 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 16:01:52,120 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:01:52,123 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:01:52,154 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:01:52,154 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:01:52,675 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:52,678 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:01:52,699 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:01:52,707 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local597835311_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:01:52,718 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:52,718 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local597835311_0001_m_000000_0' done.
   [druid] 2018-12-05 16:01:52,719 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local597835311_0001_m_000000_0
   [druid] 2018-12-05 16:01:52,719 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:01:52,723 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:01:52,740 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:01:52,744 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:52,750 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:01:52,759 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 16:01:52,759 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:01:53,039 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:01:53,483 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local597835311_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:01:53,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:01:53,484 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local597835311_0001_r_000000_0' done.
   [druid] 2018-12-05 16:01:53,488 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:01:54,041 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:01:54,041 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local597835311_0001
   [druid] 2018-12-05 16:01:54,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:01:54,060 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:01:54,060 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 16:01:54,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425382
   [druid] 2018-12-05 16:01:54,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:01:54,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:01:54,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:01:54,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:01:54,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 16:01:54,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 16:01:54,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 16:01:54,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:01:54,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:01:54,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:01:54,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 16:01:54,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:01:54,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 16:01:54,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 16:01:54,065 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 16:01:54,065 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483917824
   [druid] 2018-12-05 16:11:33,944 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:11:33,946 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:11:33,975 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:11:34,018 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:11:34,094 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:11:34,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local189075685_0001
   [druid] 2018-12-05 16:11:34,495 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:11:34,502 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:11:34,516 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:11:34,519 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local189075685_0001_m_000000_0
   [druid] 2018-12-05 16:11:34,549 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:11:34,574 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:11:34,584 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 16:11:34,597 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:11:34,600 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:11:34,646 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:11:34,646 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:11:35,236 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:35,239 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:11:35,287 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:11:35,296 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local189075685_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:11:35,308 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:35,308 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local189075685_0001_m_000000_0' done.
   [druid] 2018-12-05 16:11:35,308 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local189075685_0001_m_000000_0
   [druid] 2018-12-05 16:11:35,308 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:11:35,312 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:11:35,330 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:11:35,331 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:35,339 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:11:35,347 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 16:11:35,347 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:35,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:11:36,432 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local189075685_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:11:36,434 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:11:36,434 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local189075685_0001_r_000000_0' done.
   [druid] 2018-12-05 16:11:36,437 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:11:36,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:11:36,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local189075685_0001
   [druid] 2018-12-05 16:11:36,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:11:36,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:11:36,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 16:11:36,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447782
   [druid] 2018-12-05 16:11:36,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:11:36,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:11:36,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 16:11:36,511 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 16:11:36,511 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 16:11:36,511 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-05 16:11:52,829 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:11:52,831 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:11:52,856 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:11:52,901 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:11:52,973 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:11:53,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local106878473_0001
   [druid] 2018-12-05 16:11:53,375 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:11:53,382 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:11:53,395 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:11:53,397 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local106878473_0001_m_000000_0
   [druid] 2018-12-05 16:11:53,423 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:11:53,445 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:11:53,454 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 16:11:53,465 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:11:53,468 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:11:53,500 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:11:53,501 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:11:54,046 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:54,048 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:11:54,075 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:11:54,081 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local106878473_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:11:54,092 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:54,092 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local106878473_0001_m_000000_0' done.
   [druid] 2018-12-05 16:11:54,092 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local106878473_0001_m_000000_0
   [druid] 2018-12-05 16:11:54,093 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:11:54,096 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:11:54,114 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:11:54,114 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:54,122 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:11:54,129 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 16:11:54,130 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:11:54,375 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:11:54,788 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local106878473_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:11:54,790 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:11:54,790 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local106878473_0001_r_000000_0' done.
   [druid] 2018-12-05 16:11:54,793 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:11:55,376 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:11:55,376 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local106878473_0001
   [druid] 2018-12-05 16:11:55,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:11:55,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:11:55,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 16:11:55,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425382
   [druid] 2018-12-05 16:11:55,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:11:55,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 16:11:55,399 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 16:11:55,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:11:55,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 16:11:55,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 16:11:55,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 16:11:55,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-05 16:13:58,856 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:13:58,858 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:13:58,901 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:13:58,950 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:13:59,108 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:13:59,391 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:13:59,392 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local470142949_0001
   [druid] 2018-12-05 16:13:59,400 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:13:59,412 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:13:59,413 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local470142949_0001_m_000000_0
   [druid] 2018-12-05 16:13:59,433 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:13:59,452 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:13:59,459 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 16:13:59,468 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:13:59,470 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:13:59,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:13:59,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:14:00,126 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:00,129 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:14:00,158 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:14:00,166 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local470142949_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:14:00,180 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:00,180 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local470142949_0001_m_000000_0' done.
   [druid] 2018-12-05 16:14:00,180 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local470142949_0001_m_000000_0
   [druid] 2018-12-05 16:14:00,181 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:14:00,186 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:14:00,204 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:14:00,206 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:00,212 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:14:00,219 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 16:14:00,219 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:00,394 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:14:00,974 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local470142949_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:14:00,974 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:14:00,975 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local470142949_0001_r_000000_0' done.
   [druid] 2018-12-05 16:14:00,977 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:14:01,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:14:01,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local470142949_0001
   [druid] 2018-12-05 16:14:01,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:14:01,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:14:01,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447782
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:14:01,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:14:01,412 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 16:14:01,413 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:14:01,413 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 16:14:01,413 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 16:14:01,413 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 16:14:01,413 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483917824
   [druid] 2018-12-05 16:14:15,117 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:14:15,119 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:14:15,154 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:14:15,198 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:14:15,273 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:14:15,577 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:14:15,578 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1263112096_0001
   [druid] 2018-12-05 16:14:15,584 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:14:15,597 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:14:15,598 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1263112096_0001_m_000000_0
   [druid] 2018-12-05 16:14:15,621 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:14:15,645 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:14:15,657 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 16:14:15,668 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:14:15,671 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:14:15,709 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:14:15,709 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:14:16,571 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:16,574 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:14:16,581 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 16:14:16,596 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:14:16,604 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1263112096_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:14:16,621 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:16,621 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1263112096_0001_m_000000_0' done.
   [druid] 2018-12-05 16:14:16,621 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1263112096_0001_m_000000_0
   [druid] 2018-12-05 16:14:16,622 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:14:16,627 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:14:16,654 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:14:16,655 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:16,663 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:14:16,670 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 16:14:16,670 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:14:17,365 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1263112096_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:14:17,366 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:14:17,366 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1263112096_0001_r_000000_0' done.
   [druid] 2018-12-05 16:14:17,369 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:14:17,583 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:14:17,584 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1263112096_0001
   [druid] 2018-12-05 16:14:17,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:14:17,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:14:17,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 16:14:17,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425390
   [druid] 2018-12-05 16:14:17,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:14:17,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 16:14:17,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 16:14:17,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484442112
   [druid] 2018-12-05 16:15:04,347 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:15:04,349 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:15:04,374 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:15:04,462 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:15:04,495 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:15:04,850 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:15:04,851 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local733239579_0001
   [druid] 2018-12-05 16:15:04,860 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:15:04,872 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:15:04,873 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local733239579_0001_m_000000_0
   [druid] 2018-12-05 16:15:04,898 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:15:04,920 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:15:04,931 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 16:15:04,942 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:15:04,945 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:15:04,992 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:15:04,992 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:15:05,789 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:05,796 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:15:05,851 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:15:05,868 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local733239579_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:15:05,881 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 16:15:05,899 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:05,899 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local733239579_0001_m_000000_0' done.
   [druid] 2018-12-05 16:15:05,899 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local733239579_0001_m_000000_0
   [druid] 2018-12-05 16:15:05,903 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:15:05,910 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:15:05,936 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:15:05,940 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:05,951 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:15:05,963 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32150 bytes
   [druid] 2018-12-05 16:15:05,964 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:06,854 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local733239579_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:15:06,855 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:15:06,855 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local733239579_0001_r_000000_0' done.
   [druid] 2018-12-05 16:15:06,858 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:15:06,883 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:15:06,883 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local733239579_0001
   [druid] 2018-12-05 16:15:06,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:15:06,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:15:06,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=32460
   [druid] 2018-12-05 16:15:06,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=447782
   [druid] 2018-12-05 16:15:06,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:15:06,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:15:06,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:15:06,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 16:15:06,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:15:06,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:15:06,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:15:06,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:15:06,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:15:06,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=31676
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:15:06,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-05 16:15:06,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:15:06,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-05 16:15:06,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-05 16:15:06,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-05 16:15:06,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-05 16:15:24,653 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:15:24,655 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:15:24,686 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 16:15:24,755 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 16:15:24,850 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:15:25,148 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local350174848_0001
   [druid] 2018-12-05 16:15:25,150 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:15:25,156 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:15:25,167 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:15:25,168 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local350174848_0001_m_000000_0
   [druid] 2018-12-05 16:15:25,194 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:15:25,219 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:15:25,229 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 16:15:25,238 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:15:25,241 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 16:15:25,274 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 16:15:25,274 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 16:15:26,192 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 16:15:26,216 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:26,219 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:15:26,242 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:15:26,249 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local350174848_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:15:26,261 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:26,261 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local350174848_0001_m_000000_0' done.
   [druid] 2018-12-05 16:15:26,261 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local350174848_0001_m_000000_0
   [druid] 2018-12-05 16:15:26,261 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 16:15:26,265 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 16:15:26,283 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 16:15:26,284 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:26,290 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:15:26,299 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 20950 bytes
   [druid] 2018-12-05 16:15:26,299 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:15:26,798 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local350174848_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 16:15:26,799 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:15:26,799 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local350174848_0001_r_000000_0' done.
   [druid] 2018-12-05 16:15:26,803 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 16:15:27,194 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:15:27,194 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local350174848_0001
   [druid] 2018-12-05 16:15:27,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 16:15:27,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 16:15:27,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21260
   [druid] 2018-12-05 16:15:27,206 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425382
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 16:15:27,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=156
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20636
   [druid] 2018-12-05 16:15:27,208 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=156
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 16:15:27,209 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=312
   [druid] 2018-12-05 16:15:27,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-05 17:07:00,930 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:07:00,932 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:07:00,956 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:07:01,005 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:07:01,079 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:07:01,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local950554157_0001
   [druid] 2018-12-05 17:07:01,409 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:07:01,415 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:07:01,427 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:07:01,428 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950554157_0001_m_000000_0
   [druid] 2018-12-05 17:07:01,459 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:07:01,485 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:07:01,551 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 17:07:01,564 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:07:01,567 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:07:01,607 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:07:01,607 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:07:02,050 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:07:02,051 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:07:02,052 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local950554157_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 2
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 2
	at com.qianfeng.analysis.mr.nm.NewMemberMapper.map(NewMemberMapper.java:52)
	at com.qianfeng.analysis.mr.nm.NewMemberMapper.map(NewMemberMapper.java:25)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 17:07:02,409 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 17:07:02,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local950554157_0001
   [druid] 2018-12-05 17:07:02,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-05 17:08:20,691 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:08:20,692 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:08:20,716 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:08:20,806 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:08:20,837 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:08:21,165 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:08:21,165 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2117884590_0001
   [druid] 2018-12-05 17:08:21,172 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:08:21,192 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:08:21,194 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2117884590_0001_m_000000_0
   [druid] 2018-12-05 17:08:21,220 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:08:21,245 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:08:21,253 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 17:08:21,261 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:08:21,264 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:08:21,330 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:08:21,331 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:08:22,168 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 17:08:27,250 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:28,170 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 21% reduce 0%
   [druid] 2018-12-05 17:08:30,252 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:31,171 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 35% reduce 0%
   [druid] 2018-12-05 17:08:33,252 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:34,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 48% reduce 0%
   [druid] 2018-12-05 17:08:36,252 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:36,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 61% reduce 0%
   [druid] 2018-12-05 17:08:39,253 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:39,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 76% reduce 0%
   [druid] 2018-12-05 17:08:42,253 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:42,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 91% reduce 0%
   [druid] 2018-12-05 17:08:44,201 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:44,204 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:08:44,231 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:08:44,238 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2117884590_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:08:44,239 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:44,239 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2117884590_0001_m_000000_0' done.
   [druid] 2018-12-05 17:08:44,239 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2117884590_0001_m_000000_0
   [druid] 2018-12-05 17:08:44,242 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:08:44,246 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:08:44,259 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:08:44,259 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:44,265 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:08:44,270 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1050 bytes
   [druid] 2018-12-05 17:08:44,271 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:08:44,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 17:08:44,648 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2117884590_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:08:44,649 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:08:44,649 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2117884590_0001_r_000000_0' done.
   [druid] 2018-12-05 17:08:44,652 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:08:45,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:08:45,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2117884590_0001
   [druid] 2018-12-05 17:08:45,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1360
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=371458
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 17:08:45,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-05 17:08:45,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1032
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-05 17:08:45,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-05 17:08:45,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=751828992
   [druid] 2018-12-05 17:10:03,263 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:10:03,265 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:10:03,292 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:10:03,405 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:10:03,439 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:10:03,749 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:10:03,750 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2074075920_0001
   [druid] 2018-12-05 17:10:03,763 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:10:03,778 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:10:03,787 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2074075920_0001_m_000000_0
   [druid] 2018-12-05 17:10:03,821 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:10:03,858 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:10:03,870 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 17:10:03,881 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:10:03,885 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:10:03,932 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:10:03,932 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:10:04,754 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 17:10:09,872 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:10,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 18% reduce 0%
   [druid] 2018-12-05 17:10:12,872 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:13,761 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 34% reduce 0%
   [druid] 2018-12-05 17:10:15,873 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:16,762 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 49% reduce 0%
   [druid] 2018-12-05 17:10:18,873 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:19,770 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 64% reduce 0%
   [druid] 2018-12-05 17:10:21,873 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:22,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 78% reduce 0%
   [druid] 2018-12-05 17:10:24,873 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:25,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 94% reduce 0%
   [druid] 2018-12-05 17:10:25,926 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:25,928 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:10:25,961 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2074075920_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:10:25,963 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:25,963 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2074075920_0001_m_000000_0' done.
   [druid] 2018-12-05 17:10:25,963 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2074075920_0001_m_000000_0
   [druid] 2018-12-05 17:10:25,963 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:10:25,967 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:10:25,988 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:10:25,993 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:26,000 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:10:26,008 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 17:10:26,008 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:10:26,058 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2074075920_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:10:26,059 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:10:26,060 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2074075920_0001_r_000000_0' done.
   [druid] 2018-12-05 17:10:26,063 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:10:26,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:10:26,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2074075920_0001
   [druid] 2018-12-05 17:10:26,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:10:26,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=312
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387382
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:10:26,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:10:26,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-05 17:10:26,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=661651456
   [druid] 2018-12-05 17:10:57,972 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:10:57,974 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:10:58,000 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:10:58,046 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:10:58,233 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:10:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local672987890_0001
   [druid] 2018-12-05 17:10:58,624 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:10:58,629 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:10:58,641 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:10:58,643 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local672987890_0001_m_000000_0
   [druid] 2018-12-05 17:10:58,669 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:10:58,694 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:10:58,705 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 17:10:58,716 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:10:58,719 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:10:58,756 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:10:58,756 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:10:59,626 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 17:11:04,700 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:05,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 42% reduce 0%
   [druid] 2018-12-05 17:11:07,702 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:08,639 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 78% reduce 0%
   [druid] 2018-12-05 17:11:10,060 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:10,063 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:11:10,110 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:11:10,117 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local672987890_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:11:10,119 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:10,119 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local672987890_0001_m_000000_0' done.
   [druid] 2018-12-05 17:11:10,119 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local672987890_0001_m_000000_0
   [druid] 2018-12-05 17:11:10,120 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:11:10,125 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:11:10,141 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:11:10,143 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:10,153 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:11:10,164 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1092 bytes
   [druid] 2018-12-05 17:11:10,164 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:11:10,394 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local672987890_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:11:10,395 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:11:10,395 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local672987890_0001_r_000000_0' done.
   [druid] 2018-12-05 17:11:10,399 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:11:10,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:11:10,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local672987890_0001
   [druid] 2018-12-05 17:11:10,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:11:10,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:11:10,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1402
   [druid] 2018-12-05 17:11:10,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389554
   [druid] 2018-12-05 17:11:10,660 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:11:10,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:11:10,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:11:10,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 17:11:10,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:11:10,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:11:10,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:11:10,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:11:10,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:11:10,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 17:11:10,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-05 17:11:10,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1074
   [druid] 2018-12-05 17:11:10,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:11:10,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-05 17:11:10,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=541065216
   [druid] 2018-12-05 17:24:24,378 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:24:24,380 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:24:24,406 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:24:24,448 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:24:24,567 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:24:24,865 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1394820929_0001
   [druid] 2018-12-05 17:24:24,869 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:24:24,875 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:24:24,884 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:24:24,884 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1394820929_0001_m_000000_0
   [druid] 2018-12-05 17:24:24,904 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:24:24,923 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:24:24,930 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 17:24:24,937 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:24:24,941 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:24:24,975 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:24:24,975 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:24:25,770 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:25,773 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:24:25,854 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:24:25,865 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1394820929_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:24:25,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 17:24:25,879 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:25,879 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1394820929_0001_m_000000_0' done.
   [druid] 2018-12-05 17:24:25,881 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1394820929_0001_m_000000_0
   [druid] 2018-12-05 17:24:25,882 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:24:25,887 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:24:25,904 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:24:25,904 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:25,912 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:24:25,924 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 234138 bytes
   [druid] 2018-12-05 17:24:25,924 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:26,872 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 17:24:26,883 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1394820929_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:24:26,884 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:24:26,885 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1394820929_0001_r_000000_0' done.
   [druid] 2018-12-05 17:24:26,887 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:24:27,873 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:24:27,873 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1394820929_0001
   [druid] 2018-12-05 17:24:27,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:24:27,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:24:27,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=234448
   [druid] 2018-12-05 17:24:27,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=837658
   [druid] 2018-12-05 17:24:27,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:24:27,885 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:24:27,885 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:24:27,885 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 17:24:27,885 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:24:27,885 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1926
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=230284
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:24:27,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=18
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1926
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=18
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3852
   [druid] 2018-12-05 17:24:27,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-05 17:24:48,209 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:24:48,211 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:24:48,245 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:24:48,302 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:24:48,407 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:24:48,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local215488191_0001
   [druid] 2018-12-05 17:24:48,698 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:24:48,704 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:24:48,717 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:24:48,718 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local215488191_0001_m_000000_0
   [druid] 2018-12-05 17:24:48,741 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:24:48,761 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:24:48,773 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 17:24:48,784 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:24:48,787 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:24:48,823 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:24:48,823 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:24:49,413 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:49,417 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:24:49,469 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:24:49,492 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local215488191_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:24:49,506 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:49,506 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local215488191_0001_m_000000_0' done.
   [druid] 2018-12-05 17:24:49,506 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local215488191_0001_m_000000_0
   [druid] 2018-12-05 17:24:49,506 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:24:49,511 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:24:49,528 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:24:49,533 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:49,541 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:24:49,551 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 69936 bytes
   [druid] 2018-12-05 17:24:49,551 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:24:49,701 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 17:24:50,413 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local215488191_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:24:50,414 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:24:50,414 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local215488191_0001_r_000000_0' done.
   [druid] 2018-12-05 17:24:50,417 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:24:50,703 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:24:50,703 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local215488191_0001
   [druid] 2018-12-05 17:24:50,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:24:50,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:24:50,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=70246
   [druid] 2018-12-05 17:24:50,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=509246
   [druid] 2018-12-05 17:24:50,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:24:50,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:24:50,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:24:50,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 17:24:50,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:24:50,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=498
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=68938
   [druid] 2018-12-05 17:24:50,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=11
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=498
   [druid] 2018-12-05 17:24:50,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=11
   [druid] 2018-12-05 17:24:50,717 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=996
   [druid] 2018-12-05 17:24:50,717 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-05 17:26:45,698 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:26:45,701 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:26:45,733 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:26:45,783 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:26:45,876 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:26:46,207 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1182820144_0001
   [druid] 2018-12-05 17:26:46,213 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:26:46,221 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:26:46,232 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:26:46,233 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1182820144_0001_m_000000_0
   [druid] 2018-12-05 17:26:46,256 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:26:46,283 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:26:46,292 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 17:26:46,306 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:26:46,309 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:26:46,347 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:26:46,347 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:26:46,785 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,786 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,786 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,786 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,786 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,787 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,787 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,788 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:26:46,982 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:26:46,985 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:26:47,139 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:26:47,146 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1182820144_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:26:47,157 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:26:47,158 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1182820144_0001_m_000000_0' done.
   [druid] 2018-12-05 17:26:47,158 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1182820144_0001_m_000000_0
   [druid] 2018-12-05 17:26:47,158 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:26:47,162 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:26:47,176 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:26:47,177 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:26:47,183 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:26:47,189 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 440048 bytes
   [druid] 2018-12-05 17:26:47,189 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:26:47,213 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 17:26:48,247 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1182820144_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:26:48,248 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:26:48,249 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1182820144_0001_r_000000_0' done.
   [druid] 2018-12-05 17:26:48,251 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:26:49,217 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:26:49,217 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1182820144_0001
   [druid] 2018-12-05 17:26:49,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:26:49,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:26:49,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=440358
   [druid] 2018-12-05 17:26:49,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1249474
   [druid] 2018-12-05 17:26:49,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:26:49,229 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:26:49,229 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:26:49,229 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 17:26:49,229 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 17:26:49,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=433722
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 17:26:49,234 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483393536
   [druid] 2018-12-05 17:27:07,620 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 17:27:07,622 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 17:27:07,653 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 17:27:07,703 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 17:27:07,794 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 17:27:08,103 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1646165367_0001
   [druid] 2018-12-05 17:27:08,106 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 17:27:08,113 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 17:27:08,128 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 17:27:08,129 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1646165367_0001_m_000000_0
   [druid] 2018-12-05 17:27:08,150 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:27:08,173 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:27:08,178 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 17:27:08,187 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 17:27:08,189 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 17:27:08,223 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 17:27:08,223 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 17:27:08,691 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,691 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,691 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,691 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,692 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,692 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,692 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,692 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 17:27:08,855 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:27:08,859 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 17:27:08,947 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 17:27:08,957 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1646165367_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:27:08,978 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:27:08,978 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1646165367_0001_m_000000_0' done.
   [druid] 2018-12-05 17:27:08,979 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1646165367_0001_m_000000_0
   [druid] 2018-12-05 17:27:08,981 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 17:27:08,984 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 17:27:09,000 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 17:27:09,001 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:27:09,009 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 17:27:09,017 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-05 17:27:09,017 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 17:27:09,108 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 17:27:10,201 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1646165367_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 17:27:10,202 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 17:27:10,203 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1646165367_0001_r_000000_0' done.
   [druid] 2018-12-05 17:27:10,206 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 17:27:11,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 17:27:11,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1646165367_0001
   [druid] 2018-12-05 17:27:11,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 17:27:11,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 17:27:11,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-05 17:27:11,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774172
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 17:27:11,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 17:27:11,126 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 17:27:11,127 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 17:27:11,127 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 17:27:11,127 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=570425344
   [druid] 2018-12-05 19:40:35,409 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 19:40:35,430 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 19:40:35,458 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 19:40:35,516 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 19:40:35,594 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 19:40:35,905 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 19:40:35,908 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1915243166_0001
   [druid] 2018-12-05 19:40:35,912 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 19:40:35,928 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 19:40:35,936 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1915243166_0001_m_000000_0
   [druid] 2018-12-05 19:40:35,966 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:40:35,991 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:40:36,001 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 19:40:36,010 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 19:40:36,013 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 19:40:36,079 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 19:40:36,080 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 19:40:36,619 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,620 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,620 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,620 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,621 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,622 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,622 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,622 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:40:36,866 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:40:36,870 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 19:40:36,913 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 19:40:36,985 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 19:40:36,995 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1915243166_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:40:37,012 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:40:37,012 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1915243166_0001_m_000000_0' done.
   [druid] 2018-12-05 19:40:37,012 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1915243166_0001_m_000000_0
   [druid] 2018-12-05 19:40:37,013 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 19:40:37,020 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:40:37,038 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:40:37,039 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:40:37,044 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 19:40:37,058 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 19:40:37,059 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:40:37,642 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1915243166_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:40:37,643 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 19:40:37,643 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1915243166_0001_r_000000_0' done.
   [druid] 2018-12-05 19:40:37,647 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 19:40:37,915 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 19:40:37,915 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1915243166_0001
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224194
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 19:40:37,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 19:40:37,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 19:40:37,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483393536
   [druid] 2018-12-05 19:41:26,504 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 19:41:26,507 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 19:41:26,537 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 19:41:26,592 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 19:41:26,702 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 19:41:27,098 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 19:41:27,098 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2064930492_0001
   [druid] 2018-12-05 19:41:27,107 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 19:41:27,121 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 19:41:27,124 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2064930492_0001_m_000000_0
   [druid] 2018-12-05 19:41:27,149 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:41:27,171 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:41:27,179 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 19:41:27,186 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 19:41:27,189 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 19:41:27,250 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 19:41:27,250 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 19:41:27,699 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,700 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,710 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:41:27,989 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:41:27,993 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 19:41:28,102 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 19:41:28,105 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 19:41:28,114 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2064930492_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:41:28,127 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:41:28,128 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2064930492_0001_m_000000_0' done.
   [druid] 2018-12-05 19:41:28,128 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2064930492_0001_m_000000_0
   [druid] 2018-12-05 19:41:28,129 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 19:41:28,137 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:41:28,157 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:41:28,158 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:41:28,165 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 19:41:28,176 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 19:41:28,176 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:41:29,108 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 19:41:29,279 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2064930492_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:41:29,280 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 19:41:29,280 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2064930492_0001_r_000000_0' done.
   [druid] 2018-12-05 19:41:29,284 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 19:41:30,108 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 19:41:30,108 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2064930492_0001
   [druid] 2018-12-05 19:41:30,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 19:41:30,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 19:41:30,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 19:41:30,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224194
   [druid] 2018-12-05 19:41:30,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 19:41:30,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 19:41:30,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 19:41:30,129 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=433586176
   [druid] 2018-12-05 19:42:31,204 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 19:42:31,206 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 19:42:31,233 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 19:42:31,279 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 19:42:31,380 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 19:42:31,740 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local705698281_0001
   [druid] 2018-12-05 19:42:31,742 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 19:42:31,749 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 19:42:31,760 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 19:42:31,761 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local705698281_0001_m_000000_0
   [druid] 2018-12-05 19:42:31,787 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:42:31,810 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:42:31,817 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 19:42:31,828 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 19:42:31,831 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 19:42:31,866 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 19:42:31,867 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 19:42:32,378 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,379 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,379 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,379 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,379 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,380 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,380 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,380 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 19:42:32,609 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:42:32,612 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 19:42:32,734 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 19:42:32,744 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 19:42:32,746 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local705698281_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:42:32,763 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:42:32,763 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local705698281_0001_m_000000_0' done.
   [druid] 2018-12-05 19:42:32,763 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local705698281_0001_m_000000_0
   [druid] 2018-12-05 19:42:32,764 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 19:42:32,770 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:42:32,791 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:42:32,792 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:42:32,799 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 19:42:32,830 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 19:42:32,831 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:42:33,746 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 19:42:33,999 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local705698281_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:42:34,000 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 19:42:34,000 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local705698281_0001_r_000000_0' done.
   [druid] 2018-12-05 19:42:34,003 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 19:42:34,746 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 19:42:34,747 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local705698281_0001
   [druid] 2018-12-05 19:42:34,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 19:42:34,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 19:42:34,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 19:42:34,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224186
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 19:42:34,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 19:42:34,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 19:42:34,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 19:42:34,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 19:42:34,768 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 19:42:34,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 19:42:34,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 19:42:34,772 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-05 19:53:28,505 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 19:53:28,507 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 19:53:28,543 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 19:53:28,607 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 19:53:28,929 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 19:53:29,334 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local131857896_0001
   [druid] 2018-12-05 19:53:29,346 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 19:53:29,352 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 19:53:29,366 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 19:53:29,366 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local131857896_0001_m_000000_0
   [druid] 2018-12-05 19:53:29,394 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:53:29,417 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:53:29,425 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 19:53:29,438 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 19:53:29,442 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 19:53:29,525 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 19:53:29,526 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 19:53:30,107 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,107 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,108 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,108 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,109 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,109 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,110 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,110 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:53:30,352 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 19:53:30,374 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:53:30,377 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 19:53:30,481 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 19:53:30,492 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local131857896_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:53:30,507 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:53:30,507 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local131857896_0001_m_000000_0' done.
   [druid] 2018-12-05 19:53:30,508 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local131857896_0001_m_000000_0
   [druid] 2018-12-05 19:53:30,508 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 19:53:30,513 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:53:30,532 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:53:30,535 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:53:30,541 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 19:53:30,549 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 19:53:30,550 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:53:31,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 19:53:31,861 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local131857896_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:53:31,861 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 19:53:31,862 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local131857896_0001_r_000000_0' done.
   [druid] 2018-12-05 19:53:31,865 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 19:53:32,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 19:53:32,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local131857896_0001
   [druid] 2018-12-05 19:53:32,364 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 19:53:32,364 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 19:53:32,366 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 19:53:32,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224186
   [druid] 2018-12-05 19:53:32,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 19:53:32,368 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 19:53:32,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 19:53:32,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 19:53:32,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 19:53:32,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 19:53:32,369 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 19:53:32,370 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 19:53:32,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 19:53:32,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 19:53:32,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 19:53:32,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 19:53:32,374 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 19:53:32,375 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 19:53:32,375 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 19:53:32,375 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=563085312
   [druid] 2018-12-05 19:56:52,748 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 19:56:52,750 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 19:56:52,781 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 19:56:52,832 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 19:56:52,972 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 19:56:53,320 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1775044777_0001
   [druid] 2018-12-05 19:56:53,323 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 19:56:53,331 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 19:56:53,344 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 19:56:53,345 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1775044777_0001_m_000000_0
   [druid] 2018-12-05 19:56:53,375 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:56:53,402 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:56:53,414 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 19:56:53,429 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 19:56:53,432 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 19:56:53,491 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 19:56:53,491 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 19:56:53,982 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,983 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:53,984 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 19:56:54,233 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:56:54,237 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 19:56:54,330 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 19:56:54,344 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 19:56:54,354 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1775044777_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:56:54,373 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:56:54,373 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1775044777_0001_m_000000_0' done.
   [druid] 2018-12-05 19:56:54,374 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1775044777_0001_m_000000_0
   [druid] 2018-12-05 19:56:54,374 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 19:56:54,381 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 19:56:54,401 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 19:56:54,402 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:56:54,410 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 19:56:54,418 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 19:56:54,418 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 19:56:55,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 19:56:55,460 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1775044777_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 19:56:55,462 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 19:56:55,462 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1775044777_0001_r_000000_0' done.
   [druid] 2018-12-05 19:56:55,466 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 19:56:56,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 19:56:56,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1775044777_0001
   [druid] 2018-12-05 19:56:56,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 19:56:56,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 19:56:56,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 19:56:56,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224194
   [druid] 2018-12-05 19:56:56,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 19:56:56,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 19:56:56,351 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 19:56:56,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 19:56:56,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 19:56:56,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 19:56:56,354 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-05 20:04:08,446 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:04:08,447 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:04:08,477 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:04:08,524 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:04:08,623 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:04:08,951 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local266753333_0001
   [druid] 2018-12-05 20:04:08,955 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:04:08,961 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:04:08,973 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:04:08,974 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local266753333_0001_m_000000_0
   [druid] 2018-12-05 20:04:08,999 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:04:09,024 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:04:09,033 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 20:04:09,043 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:04:09,045 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:04:09,083 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:04:09,083 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:04:09,546 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,546 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,546 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,547 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,547 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,547 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,547 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,547 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:04:09,790 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:04:09,794 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:04:09,909 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:04:09,918 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local266753333_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:04:09,937 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:04:09,937 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local266753333_0001_m_000000_0' done.
   [druid] 2018-12-05 20:04:09,937 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local266753333_0001_m_000000_0
   [druid] 2018-12-05 20:04:09,939 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:04:09,943 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:04:09,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:04:09,959 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:04:09,960 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:04:09,966 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:04:09,978 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 20:04:09,978 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:04:10,923 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local266753333_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:04:10,924 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:04:10,924 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local266753333_0001_r_000000_0' done.
   [druid] 2018-12-05 20:04:10,927 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:04:10,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:04:10,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local266753333_0001
   [druid] 2018-12-05 20:04:10,971 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224162
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:04:10,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:04:10,973 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 20:04:10,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:04:10,975 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 20:04:10,975 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 20:04:10,975 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 20:04:10,975 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484442112
   [druid] 2018-12-05 20:07:06,857 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:07:06,859 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:07:06,890 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:07:06,930 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:07:07,022 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:07:07,368 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1145527204_0001
   [druid] 2018-12-05 20:07:07,377 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:07:07,384 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:07:07,397 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:07:07,398 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1145527204_0001_m_000000_0
   [druid] 2018-12-05 20:07:07,421 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:07:07,446 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:07:07,454 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 20:07:07,462 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:07:07,464 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:07:07,513 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:07:07,513 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:07:08,047 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,048 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,048 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,048 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,049 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,049 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,050 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,050 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:08,285 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:08,290 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:07:08,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 20:07:08,395 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:07:08,408 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1145527204_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:07:08,424 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:08,425 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1145527204_0001_m_000000_0' done.
   [druid] 2018-12-05 20:07:08,425 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1145527204_0001_m_000000_0
   [druid] 2018-12-05 20:07:08,425 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:07:08,431 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:07:08,450 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:07:08,450 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:08,457 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:07:08,467 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 427400 bytes
   [druid] 2018-12-05 20:07:08,467 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:09,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:07:09,731 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1145527204_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:07:09,732 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:07:09,732 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1145527204_0001_r_000000_0' done.
   [druid] 2018-12-05 20:07:09,735 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:07:10,392 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:07:10,393 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1145527204_0001
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=427710
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1224194
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:07:10,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:07:10,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=421074
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-05 20:07:10,407 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-05 20:07:10,408 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-05 20:07:10,408 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483393536
   [druid] 2018-12-05 20:07:27,068 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:07:27,070 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:07:27,102 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:07:27,145 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:07:27,247 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:07:27,557 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:07:27,558 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1107260641_0001
   [druid] 2018-12-05 20:07:27,566 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:07:27,579 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:07:27,582 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1107260641_0001_m_000000_0
   [druid] 2018-12-05 20:07:27,612 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:07:27,636 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:07:27,646 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:07:27,661 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:07:27,663 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:07:27,695 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:07:27,695 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:07:28,155 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,156 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,157 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,158 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,159 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,159 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,159 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,159 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:07:28,314 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:28,317 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:07:28,388 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:07:28,397 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1107260641_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:07:28,415 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:28,415 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1107260641_0001_m_000000_0' done.
   [druid] 2018-12-05 20:07:28,415 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1107260641_0001_m_000000_0
   [druid] 2018-12-05 20:07:28,416 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:07:28,421 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:07:28,448 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:07:28,452 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:28,459 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:07:28,486 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:07:28,486 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:07:28,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:07:29,638 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1107260641_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:07:29,640 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:07:29,640 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1107260641_0001_r_000000_0' done.
   [druid] 2018-12-05 20:07:29,642 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:07:30,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:07:30,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1107260641_0001
   [druid] 2018-12-05 20:07:30,589 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:07:30,590 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:07:30,590 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:07:30,590 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762364
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:07:30,591 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:07:30,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:07:30,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:07:30,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:07:30,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:07:30,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:07:30,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-05 20:08:54,420 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:08:54,423 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:08:54,446 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:08:54,488 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:08:54,565 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:08:54,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local943833731_0001
   [druid] 2018-12-05 20:08:54,943 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:08:54,947 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:08:54,958 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:08:54,958 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local943833731_0001_m_000000_0
   [druid] 2018-12-05 20:08:54,975 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:08:54,991 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:08:54,997 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:08:55,008 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:08:55,011 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:08:55,073 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:08:55,074 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:08:55,584 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,585 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,585 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,585 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,585 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,586 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,586 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,586 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:08:55,742 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:08:55,744 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:08:55,901 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:08:55,922 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local943833731_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:08:55,932 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:08:55,932 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local943833731_0001_m_000000_0' done.
   [druid] 2018-12-05 20:08:55,933 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local943833731_0001_m_000000_0
   [druid] 2018-12-05 20:08:55,933 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:08:55,938 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:08:55,943 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:08:55,952 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:08:55,953 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:08:55,959 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:08:55,966 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:08:55,966 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:08:56,843 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local943833731_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:08:56,844 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:08:56,844 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local943833731_0001_r_000000_0' done.
   [druid] 2018-12-05 20:08:56,849 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:08:56,945 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:08:56,945 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local943833731_0001
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762356
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:08:56,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:08:56,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:08:56,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:08:56,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:08:56,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:08:56,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=426770432
   [druid] 2018-12-05 20:09:43,060 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:09:43,064 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:09:43,126 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:09:43,193 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:09:43,289 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:09:43,766 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1511801723_0001
   [druid] 2018-12-05 20:09:43,774 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:09:43,781 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:09:43,800 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:09:43,807 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1511801723_0001_m_000000_0
   [druid] 2018-12-05 20:09:43,842 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:09:43,879 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:09:43,890 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:09:43,907 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:09:43,912 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:09:43,983 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:09:43,983 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:09:44,595 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,595 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,595 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,595 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,596 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,596 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,596 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,596 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:09:44,749 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:09:44,753 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:09:44,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 20:09:44,830 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:09:44,840 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1511801723_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:09:44,860 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:09:44,860 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1511801723_0001_m_000000_0' done.
   [druid] 2018-12-05 20:09:44,860 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1511801723_0001_m_000000_0
   [druid] 2018-12-05 20:09:44,863 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:09:44,870 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:09:44,890 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:09:44,891 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:09:44,901 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:09:44,916 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:09:44,916 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:09:45,773 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:09:46,334 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1511801723_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:09:46,335 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:09:46,336 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1511801723_0001_r_000000_0' done.
   [druid] 2018-12-05 20:09:46,341 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:09:46,773 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:09:46,774 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1511801723_0001
   [druid] 2018-12-05 20:09:46,796 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:09:46,796 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762364
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:09:46,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:09:46,798 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:09:46,798 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:09:46,798 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:09:46,798 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:09:46,802 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:09:46,802 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:09:46,802 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:09:46,802 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:09:46,803 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=416284672
   [druid] 2018-12-05 20:10:39,260 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:10:39,264 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:10:39,323 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:10:39,387 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:10:39,492 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:10:40,180 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1280502904_0001
   [druid] 2018-12-05 20:10:40,187 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:10:40,196 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:10:40,219 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:10:40,222 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1280502904_0001_m_000000_0
   [druid] 2018-12-05 20:10:40,259 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:10:40,291 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:10:40,305 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:10:40,321 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:10:40,327 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:10:40,395 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:10:40,396 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:10:40,930 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,930 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,930 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,931 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,931 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,931 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,931 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:40,932 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:10:41,109 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:10:41,115 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:10:41,186 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:10:41,194 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 20:10:41,196 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1280502904_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:10:41,213 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:10:41,214 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1280502904_0001_m_000000_0' done.
   [druid] 2018-12-05 20:10:41,214 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1280502904_0001_m_000000_0
   [druid] 2018-12-05 20:10:41,216 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:10:41,229 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:10:41,253 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:10:41,254 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:10:41,264 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:10:41,278 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:10:41,278 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:10:44,191 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:10:55,727 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:12:38,910 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 71%
   [druid] 2018-12-05 20:13:39,461 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:13:39,462 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:13:39,486 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:13:39,526 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:13:39,613 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:13:39,969 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:13:39,970 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1763419439_0001
   [druid] 2018-12-05 20:13:39,978 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:13:39,993 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:13:39,993 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1763419439_0001_m_000000_0
   [druid] 2018-12-05 20:13:40,018 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:13:40,042 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:13:40,056 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:13:40,066 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:13:40,068 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:13:40,102 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:13:40,102 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:13:40,669 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,669 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,670 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,671 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,672 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,672 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,672 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,675 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:13:40,830 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:13:40,835 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:13:40,897 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:13:40,905 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1763419439_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:13:40,922 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:13:40,922 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1763419439_0001_m_000000_0' done.
   [druid] 2018-12-05 20:13:40,922 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1763419439_0001_m_000000_0
   [druid] 2018-12-05 20:13:40,923 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:13:40,928 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:13:40,948 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:13:40,950 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:13:40,958 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:13:40,969 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:13:40,969 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:13:40,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:13:42,056 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1763419439_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:13:42,057 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:13:42,058 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1763419439_0001_r_000000_0' done.
   [druid] 2018-12-05 20:13:42,061 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:13:42,976 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:13:42,977 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1763419439_0001
   [druid] 2018-12-05 20:13:42,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:13:42,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:13:42,993 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:13:42,993 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762364
   [druid] 2018-12-05 20:13:42,993 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:13:42,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:13:42,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:13:42,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:13:42,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:13:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:13:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-05 20:16:24,250 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:16:24,252 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:16:24,281 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:16:24,331 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:16:24,433 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:16:24,799 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local144572635_0001
   [druid] 2018-12-05 20:16:24,806 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:16:24,813 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:16:24,826 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:16:24,828 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local144572635_0001_m_000000_0
   [druid] 2018-12-05 20:16:24,853 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:16:24,878 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:16:24,888 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:16:24,904 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:16:24,907 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:16:24,975 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:16:24,975 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:16:25,458 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,459 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,459 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,459 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,460 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,460 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,461 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,461 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:16:25,603 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:16:25,607 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:16:25,674 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:16:25,683 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local144572635_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:16:25,697 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:16:25,698 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local144572635_0001_m_000000_0' done.
   [druid] 2018-12-05 20:16:25,698 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local144572635_0001_m_000000_0
   [druid] 2018-12-05 20:16:25,699 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:16:25,703 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:16:25,724 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:16:25,725 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:16:25,736 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:16:25,745 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:16:25,745 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:16:25,802 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:16:26,627 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local144572635_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:16:26,628 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:16:26,628 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local144572635_0001_r_000000_0' done.
   [druid] 2018-12-05 20:16:26,631 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:16:26,806 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:16:26,806 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local144572635_0001
   [druid] 2018-12-05 20:16:26,823 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:16:26,823 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:16:26,824 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:16:26,824 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762356
   [druid] 2018-12-05 20:16:26,825 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:16:26,825 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:16:26,826 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:16:26,826 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:16:26,826 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:16:26,826 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:16:26,827 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:16:26,828 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=419430400
   [druid] 2018-12-05 20:21:29,499 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 20:21:29,502 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 20:21:29,535 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 20:21:29,585 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 20:21:29,672 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 20:21:30,056 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 20:21:30,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local774396078_0001
   [druid] 2018-12-05 20:21:30,063 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 20:21:30,083 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 20:21:30,084 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local774396078_0001_m_000000_0
   [druid] 2018-12-05 20:21:30,117 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:21:30,142 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:21:30,153 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 20:21:30,168 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 20:21:30,172 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 20:21:30,244 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 20:21:30,245 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 20:21:30,918 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,919 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,920 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,921 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,921 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,922 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,922 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:30,922 [pool-4-thread-1] INFO  lysis.mr.session.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 20:21:31,064 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 20:21:31,077 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:21:31,080 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 20:21:31,149 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 20:21:31,178 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774396078_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:21:31,191 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:21:31,192 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774396078_0001_m_000000_0' done.
   [druid] 2018-12-05 20:21:31,192 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local774396078_0001_m_000000_0
   [druid] 2018-12-05 20:21:31,192 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 20:21:31,198 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 20:21:31,217 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 20:21:31,218 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:21:31,226 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 20:21:31,235 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 196485 bytes
   [druid] 2018-12-05 20:21:31,235 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 20:21:32,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 20:21:32,542 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774396078_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 20:21:32,545 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 20:21:32,546 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774396078_0001_r_000000_0' done.
   [druid] 2018-12-05 20:21:32,549 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 20:21:33,067 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 20:21:33,067 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local774396078_0001
   [druid] 2018-12-05 20:21:33,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 20:21:33,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 20:21:33,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=196795
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=762356
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 20:21:33,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-05 20:21:33,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=193527
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-05 20:21:33,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=572522496
   [druid] 2018-12-05 21:57:15,086 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 21:57:15,090 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 21:57:15,151 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 21:57:15,191 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 21:57:15,277 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 21:57:15,631 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local61058277_0001
   [druid] 2018-12-05 21:57:15,635 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 21:57:15,641 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 21:57:15,655 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 21:57:15,657 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local61058277_0001_m_000000_0
   [druid] 2018-12-05 21:57:15,691 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:57:15,720 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:57:15,732 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 21:57:15,759 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 21:57:15,761 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 21:57:15,842 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 21:57:15,843 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 21:57:16,299 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,299 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,300 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,300 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,302 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,302 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,303 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,303 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:57:16,539 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:57:16,543 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 21:57:16,595 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 21:57:16,604 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local61058277_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:57:16,619 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:57:16,620 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local61058277_0001_m_000000_0' done.
   [druid] 2018-12-05 21:57:16,620 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local61058277_0001_m_000000_0
   [druid] 2018-12-05 21:57:16,620 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 21:57:16,625 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:57:16,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 21:57:16,650 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:57:16,654 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:57:16,663 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 21:57:16,674 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 204070 bytes
   [druid] 2018-12-05 21:57:16,674 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:57:17,264 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local61058277_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:57:17,270 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 21:57:17,270 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local61058277_0001_r_000000_0' done.
   [druid] 2018-12-05 21:57:17,273 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 21:57:17,639 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 21:57:17,639 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local61058277_0001
   [druid] 2018-12-05 21:57:17,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 21:57:17,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 21:57:17,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=204380
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=777550
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 21:57:17,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=200906
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 21:57:17,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1581
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3162
   [druid] 2018-12-05 21:57:17,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=423624704
   [druid] 2018-12-05 21:58:17,073 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 21:58:17,076 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 21:58:17,108 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 21:58:17,171 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 21:58:17,384 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 21:58:17,706 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 21:58:17,707 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1165051066_0001
   [druid] 2018-12-05 21:58:17,716 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 21:58:17,729 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 21:58:17,730 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1165051066_0001_m_000000_0
   [druid] 2018-12-05 21:58:17,751 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:58:17,768 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:58:17,775 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 21:58:17,783 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 21:58:17,786 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 21:58:17,846 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 21:58:17,846 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 21:58:18,328 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,328 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,329 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,329 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,330 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,330 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,330 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,331 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:18,571 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:18,574 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 21:58:18,652 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 21:58:18,662 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1165051066_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:58:18,677 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:18,678 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1165051066_0001_m_000000_0' done.
   [druid] 2018-12-05 21:58:18,678 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1165051066_0001_m_000000_0
   [druid] 2018-12-05 21:58:18,678 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 21:58:18,684 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:58:18,706 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:58:18,707 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:18,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 21:58:18,717 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 21:58:18,727 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 204070 bytes
   [druid] 2018-12-05 21:58:18,728 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:19,543 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1165051066_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:58:19,544 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 21:58:19,544 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1165051066_0001_r_000000_0' done.
   [druid] 2018-12-05 21:58:19,547 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 21:58:19,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 21:58:19,713 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1165051066_0001
   [druid] 2018-12-05 21:58:19,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 21:58:19,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 21:58:19,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=204380
   [druid] 2018-12-05 21:58:19,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=777586
   [druid] 2018-12-05 21:58:19,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 21:58:19,725 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 21:58:19,725 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 21:58:19,725 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 21:58:19,725 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=200906
   [druid] 2018-12-05 21:58:19,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1581
   [druid] 2018-12-05 21:58:19,727 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-05 21:58:19,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3162
   [druid] 2018-12-05 21:58:19,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=418381824
   [druid] 2018-12-05 21:58:52,494 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 21:58:52,495 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 21:58:52,526 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 21:58:52,579 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 21:58:52,660 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 21:58:52,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1950694541_0001
   [druid] 2018-12-05 21:58:52,975 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 21:58:52,980 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 21:58:52,994 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 21:58:52,995 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1950694541_0001_m_000000_0
   [druid] 2018-12-05 21:58:53,061 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:58:53,088 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:58:53,095 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 21:58:53,103 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 21:58:53,107 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 21:58:53,142 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 21:58:53,142 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 21:58:53,594 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,595 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,596 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,596 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,596 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,596 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,597 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,597 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 21:58:53,744 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:53,749 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 21:58:53,873 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 21:58:53,888 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1950694541_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:58:53,916 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:53,916 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1950694541_0001_m_000000_0' done.
   [druid] 2018-12-05 21:58:53,916 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1950694541_0001_m_000000_0
   [druid] 2018-12-05 21:58:53,917 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 21:58:53,922 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 21:58:53,940 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 21:58:53,940 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:53,950 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 21:58:53,959 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 94526 bytes
   [druid] 2018-12-05 21:58:53,960 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 21:58:53,978 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 21:58:54,772 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1950694541_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 21:58:54,775 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 21:58:54,775 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1950694541_0001_r_000000_0' done.
   [druid] 2018-12-05 21:58:54,777 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 21:58:54,979 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 21:58:54,980 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1950694541_0001
   [druid] 2018-12-05 21:58:54,991 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=94836
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=558498
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 21:58:54,992 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 21:58:54,993 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 21:58:54,993 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=739
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=93046
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 21:58:54,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 21:58:54,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-05 21:58:54,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 21:58:54,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=739
   [druid] 2018-12-05 21:58:54,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-05 21:58:54,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1478
   [druid] 2018-12-05 21:58:54,996 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486539264
   [druid] 2018-12-05 22:26:35,224 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 22:26:35,226 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 22:26:35,247 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 22:26:35,286 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 22:26:35,394 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 22:26:35,709 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 22:26:35,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1043883013_0001
   [druid] 2018-12-05 22:26:35,719 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 22:26:35,733 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 22:26:35,733 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1043883013_0001_m_000000_0
   [druid] 2018-12-05 22:26:35,764 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 22:26:35,791 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 22:26:35,802 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-05 22:26:35,820 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 22:26:35,823 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 22:26:35,894 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 22:26:35,894 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 22:26:36,394 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,394 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,394 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,394 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,395 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,395 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,395 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,396 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:36,632 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:36,636 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 22:26:36,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-05 22:26:36,749 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 22:26:36,764 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1043883013_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 22:26:36,781 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:36,781 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1043883013_0001_m_000000_0' done.
   [druid] 2018-12-05 22:26:36,781 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1043883013_0001_m_000000_0
   [druid] 2018-12-05 22:26:36,782 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 22:26:36,788 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 22:26:36,806 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 22:26:36,807 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:36,814 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 22:26:36,823 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 204070 bytes
   [druid] 2018-12-05 22:26:36,823 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:37,560 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1043883013_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 22:26:37,561 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 22:26:37,562 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1043883013_0001_r_000000_0' done.
   [druid] 2018-12-05 22:26:37,564 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 22:26:37,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 22:26:37,716 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1043883013_0001
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=204380
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=777586
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 22:26:37,728 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 22:26:37,729 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 22:26:37,730 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-05 22:26:37,730 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-05 22:26:37,730 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=200906
   [druid] 2018-12-05 22:26:37,730 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 22:26:37,730 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 22:26:37,731 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 22:26:37,731 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-05 22:26:37,731 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 22:26:37,731 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1581
   [druid] 2018-12-05 22:26:37,732 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-05 22:26:37,732 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3162
   [druid] 2018-12-05 22:26:37,732 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-05 22:26:52,700 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 22:26:52,702 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 22:26:52,730 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-05 22:26:52,777 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-05 22:26:52,869 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 22:26:53,172 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 22:26:53,173 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2024790034_0001
   [druid] 2018-12-05 22:26:53,181 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 22:26:53,193 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 22:26:53,193 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2024790034_0001_m_000000_0
   [druid] 2018-12-05 22:26:53,216 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 22:26:53,239 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 22:26:53,248 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-05 22:26:53,258 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 22:26:53,261 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-05 22:26:53,296 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-05 22:26:53,296 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-05 22:26:53,784 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,785 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,785 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,785 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,786 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,787 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,787 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,787 [pool-4-thread-1] INFO  s.mr.ha.HourlyActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-05 22:26:53,934 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:53,938 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 22:26:54,049 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 22:26:54,064 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2024790034_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 22:26:54,086 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:54,086 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2024790034_0001_m_000000_0' done.
   [druid] 2018-12-05 22:26:54,086 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2024790034_0001_m_000000_0
   [druid] 2018-12-05 22:26:54,087 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-05 22:26:54,096 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-05 22:26:54,115 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-05 22:26:54,116 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:54,125 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 22:26:54,140 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 94526 bytes
   [druid] 2018-12-05 22:26:54,140 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 22:26:54,188 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-05 22:26:54,840 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2024790034_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-05 22:26:54,841 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 22:26:54,841 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2024790034_0001_r_000000_0' done.
   [druid] 2018-12-05 22:26:54,844 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-05 22:26:55,191 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-05 22:26:55,192 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2024790034_0001
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=94836
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=558498
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-05 22:26:55,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=739
   [druid] 2018-12-05 22:26:55,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=93046
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=739
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1478
   [druid] 2018-12-05 22:26:55,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   