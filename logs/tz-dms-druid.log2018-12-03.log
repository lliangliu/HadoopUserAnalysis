[druid] 2018-12-03 08:23:40,852 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 08:23:40,885 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 08:23:41,112 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 08:23:41,417 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 08:23:41,615 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 08:23:42,482 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 08:23:42,482 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local928313922_0001
   [druid] 2018-12-03 08:23:42,492 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 08:23:42,547 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 08:23:42,547 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local928313922_0001_m_000000_0
   [druid] 2018-12-03 08:23:42,627 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:23:42,657 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:23:42,697 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 08:23:42,707 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 08:23:42,710 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 08:23:42,787 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 08:23:42,787 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 08:23:43,490 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 08:23:43,527 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:23:43,530 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 08:23:43,667 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 08:23:43,675 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local928313922_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:23:43,685 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:23:43,685 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local928313922_0001_m_000000_0' done.
   [druid] 2018-12-03 08:23:43,685 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local928313922_0001_m_000000_0
   [druid] 2018-12-03 08:23:43,685 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 08:23:43,707 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:23:43,722 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:23:43,722 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:23:43,735 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 08:23:43,745 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 08:23:43,745 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:23:44,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 08:23:45,591 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local928313922_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:23:45,593 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 08:23:45,593 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local928313922_0001_r_000000_0' done.
   [druid] 2018-12-03 08:23:45,598 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 08:23:46,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 08:23:46,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local928313922_0001
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401888
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 08:23:46,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 08:23:46,566 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 08:23:46,568 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 08:23:46,568 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 08:23:46,571 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 08:23:46,571 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 08:23:46,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 08:23:46,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=381681664
   [druid] 2018-12-03 08:27:55,325 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 08:27:55,365 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 08:27:55,388 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 08:27:55,423 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 08:27:55,550 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 08:27:55,893 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local631856577_0001
   [druid] 2018-12-03 08:27:55,895 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 08:27:55,900 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 08:27:55,913 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 08:27:55,913 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local631856577_0001_m_000000_0
   [druid] 2018-12-03 08:27:55,933 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:27:55,953 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:27:55,960 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 08:27:55,970 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 08:27:55,973 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 08:27:56,045 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 08:27:56,045 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 08:27:56,563 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:27:56,565 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 08:27:56,743 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 08:27:56,750 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local631856577_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:27:56,765 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:27:56,765 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local631856577_0001_m_000000_0' done.
   [druid] 2018-12-03 08:27:56,765 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local631856577_0001_m_000000_0
   [druid] 2018-12-03 08:27:56,765 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 08:27:56,773 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:27:56,788 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:27:56,788 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:27:56,793 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 08:27:56,800 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 08:27:56,803 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:27:56,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 08:27:58,115 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local631856577_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:27:58,125 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 08:27:58,125 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local631856577_0001_r_000000_0' done.
   [druid] 2018-12-03 08:27:58,128 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 08:27:58,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 08:27:58,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local631856577_0001
   [druid] 2018-12-03 08:27:58,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 08:27:58,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 08:27:58,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 08:27:58,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401888
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 08:27:58,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 08:27:58,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 08:27:58,943 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 08:27:58,943 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483393536
   [druid] 2018-12-03 08:32:51,720 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 08:32:51,740 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 08:32:51,760 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 08:32:51,839 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 08:32:51,970 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 08:32:52,380 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 08:32:52,382 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2138653453_0001
   [druid] 2018-12-03 08:32:52,390 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 08:32:52,405 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 08:32:52,405 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2138653453_0001_m_000000_0
   [druid] 2018-12-03 08:32:52,427 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:32:52,460 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:32:52,510 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 08:32:52,577 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 08:32:52,580 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 08:32:52,620 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 08:32:52,620 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 08:32:53,317 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:32:53,320 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 08:32:53,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 08:32:53,432 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 08:32:53,439 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2138653453_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:32:53,449 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:32:53,449 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2138653453_0001_m_000000_0' done.
   [druid] 2018-12-03 08:32:53,449 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2138653453_0001_m_000000_0
   [druid] 2018-12-03 08:32:53,449 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 08:32:53,452 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:32:53,464 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:32:53,464 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:32:53,472 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 08:32:53,519 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 08:32:53,519 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:32:54,367 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2138653453_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:32:54,372 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 08:32:54,374 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2138653453_0001_r_000000_0' done.
   [druid] 2018-12-03 08:32:54,374 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 08:32:54,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 08:32:54,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2138653453_0001
   [druid] 2018-12-03 08:32:54,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 08:32:54,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 08:32:54,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401896
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 08:32:54,452 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 08:32:54,454 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 08:32:54,454 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 08:32:54,454 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 08:32:54,454 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 08:32:54,454 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=418381824
   [druid] 2018-12-03 08:42:34,886 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 08:42:34,888 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 08:42:34,954 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 08:42:35,007 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 08:42:35,147 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 08:42:35,435 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 08:42:35,438 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2013471524_0001
   [druid] 2018-12-03 08:42:35,441 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 08:42:35,450 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 08:42:35,451 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2013471524_0001_m_000000_0
   [druid] 2018-12-03 08:42:35,469 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:42:35,491 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:42:35,497 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 08:42:35,505 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 08:42:35,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 08:42:35,546 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 08:42:35,546 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 08:42:36,074 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:42:36,078 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 08:42:36,243 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 08:42:36,256 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2013471524_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:42:36,265 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:42:36,265 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2013471524_0001_m_000000_0' done.
   [druid] 2018-12-03 08:42:36,266 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2013471524_0001_m_000000_0
   [druid] 2018-12-03 08:42:36,266 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 08:42:36,269 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:42:36,284 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:42:36,284 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:42:36,291 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 08:42:36,297 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 08:42:36,297 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:42:36,441 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 08:42:37,568 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2013471524_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:42:37,575 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 08:42:37,576 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2013471524_0001_r_000000_0' done.
   [druid] 2018-12-03 08:42:37,578 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 08:42:38,444 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 08:42:38,444 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2013471524_0001
   [druid] 2018-12-03 08:42:38,467 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 08:42:38,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 08:42:38,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 08:42:38,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401896
   [druid] 2018-12-03 08:42:38,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 08:42:38,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 08:42:38,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 08:42:38,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 08:42:38,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 08:42:38,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 08:42:38,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 08:42:38,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 08:42:38,474 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 08:42:38,474 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-03 08:58:43,964 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 08:58:43,966 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 08:58:43,994 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 08:58:44,043 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 08:58:44,183 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 08:58:44,500 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 08:58:44,504 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1096807883_0001
   [druid] 2018-12-03 08:58:44,509 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 08:58:44,521 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 08:58:44,521 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1096807883_0001_m_000000_0
   [druid] 2018-12-03 08:58:44,550 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:58:44,572 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:58:44,581 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 08:58:44,590 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 08:58:44,592 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 08:58:44,654 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 08:58:44,654 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 08:58:45,301 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:58:45,305 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 08:58:45,348 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 08:58:45,355 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1096807883_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:58:45,368 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:58:45,368 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1096807883_0001_m_000000_0' done.
   [druid] 2018-12-03 08:58:45,369 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1096807883_0001_m_000000_0
   [druid] 2018-12-03 08:58:45,369 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 08:58:45,372 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 08:58:45,391 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 08:58:45,392 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:58:45,397 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 08:58:45,404 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 08:58:45,404 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 08:58:45,519 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 08:58:45,792 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1096807883_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 08:58:45,794 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 08:58:45,794 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1096807883_0001_r_000000_0' done.
   [druid] 2018-12-03 08:58:45,798 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 08:58:46,520 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 08:58:46,520 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1096807883_0001
   [druid] 2018-12-03 08:58:46,531 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401896
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 08:58:46,532 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 08:58:46,533 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 08:58:46,534 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=485490688
   [druid] 2018-12-03 09:22:05,058 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 09:22:05,059 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 09:22:05,107 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 09:22:05,145 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 09:22:05,219 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 09:22:07,131 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local646850256_0001
   [druid] 2018-12-03 09:22:07,133 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 09:22:07,138 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 09:22:07,153 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 09:22:07,153 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local646850256_0001_m_000000_0
   [druid] 2018-12-03 09:22:07,178 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:22:07,199 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:22:07,206 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 09:22:07,215 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 09:22:07,218 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 09:22:07,263 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 09:22:07,263 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 09:22:08,018 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:22:08,021 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 09:22:08,115 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 09:22:08,124 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local646850256_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:22:08,135 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:22:08,135 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local646850256_0001_m_000000_0' done.
   [druid] 2018-12-03 09:22:08,136 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local646850256_0001_m_000000_0
   [druid] 2018-12-03 09:22:08,136 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 09:22:08,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 09:22:08,141 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:22:08,161 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:22:08,161 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:22:08,168 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 09:22:08,177 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 09:22:08,177 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:22:08,533 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local646850256_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:22:08,534 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 09:22:08,534 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local646850256_0001_r_000000_0' done.
   [druid] 2018-12-03 09:22:08,537 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 09:22:09,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 09:22:09,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local646850256_0001
   [druid] 2018-12-03 09:22:09,155 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 09:22:09,156 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 09:22:09,156 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 09:22:09,156 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401888
   [druid] 2018-12-03 09:22:09,157 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 09:22:09,157 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 09:22:09,157 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 09:22:09,157 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 09:22:09,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 09:22:09,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 09:22:09,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 09:22:09,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 09:22:09,158 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 09:22:09,159 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 09:22:09,159 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 09:22:09,159 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 09:22:09,159 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 09:22:09,159 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 09:22:09,160 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 09:22:09,161 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-03 09:29:07,320 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 09:29:07,322 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 09:29:07,350 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 09:29:07,398 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 09:29:07,504 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 09:29:07,936 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local988773949_0001
   [druid] 2018-12-03 09:29:07,939 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 09:29:07,945 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 09:29:07,956 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 09:29:07,956 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local988773949_0001_m_000000_0
   [druid] 2018-12-03 09:29:07,978 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:29:08,003 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:29:08,011 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 09:29:08,022 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 09:29:08,025 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 09:29:08,084 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 09:29:08,084 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 09:29:08,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 09:29:09,354 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:29:09,356 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 09:29:09,402 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 09:29:09,410 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local988773949_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:29:09,423 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:29:09,424 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local988773949_0001_m_000000_0' done.
   [druid] 2018-12-03 09:29:09,424 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local988773949_0001_m_000000_0
   [druid] 2018-12-03 09:29:09,425 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 09:29:09,429 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:29:09,442 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:29:09,443 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:29:09,447 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 09:29:09,454 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 09:29:09,454 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:29:09,816 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local988773949_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:29:09,817 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 09:29:09,817 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local988773949_0001_r_000000_0' done.
   [druid] 2018-12-03 09:29:09,820 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 09:29:09,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 09:29:09,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local988773949_0001
   [druid] 2018-12-03 09:29:09,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 09:29:09,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 09:29:09,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 09:29:09,963 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401888
   [druid] 2018-12-03 09:29:09,963 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 09:29:09,963 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 09:29:09,963 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 09:29:09,964 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 09:29:09,964 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 09:29:09,964 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 09:29:09,964 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 09:29:09,965 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 09:29:09,965 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 09:29:09,965 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 09:29:09,965 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 09:29:09,966 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 09:29:09,966 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 09:29:09,966 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 09:29:09,966 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 09:29:09,967 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 09:29:09,968 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 09:29:09,968 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 09:29:09,969 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 09:29:09,969 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 09:29:09,969 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486539264
   [druid] 2018-12-03 09:43:37,346 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 09:43:37,348 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 09:43:37,375 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 09:43:37,423 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 09:43:37,691 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 09:43:37,962 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 09:43:37,963 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local912559718_0001
   [druid] 2018-12-03 09:43:37,969 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 09:43:37,982 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 09:43:37,985 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local912559718_0001_m_000000_0
   [druid] 2018-12-03 09:43:38,007 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:43:38,027 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:43:38,034 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 09:43:38,043 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 09:43:38,046 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 09:43:38,112 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 09:43:38,113 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 09:43:38,967 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 09:43:40,643 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:43:40,654 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 09:43:40,681 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 09:43:40,689 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local912559718_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:43:40,698 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:43:40,699 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local912559718_0001_m_000000_0' done.
   [druid] 2018-12-03 09:43:40,699 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local912559718_0001_m_000000_0
   [druid] 2018-12-03 09:43:40,699 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 09:43:40,703 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 09:43:40,968 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 09:43:41,248 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 09:43:41,249 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:43:41,254 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 09:43:41,262 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 09:43:41,262 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 09:43:41,591 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local912559718_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 09:43:41,592 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 09:43:41,592 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local912559718_0001_r_000000_0' done.
   [druid] 2018-12-03 09:43:41,595 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 09:43:41,968 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 09:43:41,969 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local912559718_0001
   [druid] 2018-12-03 09:43:41,981 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 09:43:41,981 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401888
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 09:43:41,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 09:43:41,983 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 09:43:41,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 09:43:41,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 09:43:41,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 09:43:41,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 09:43:41,984 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 09:43:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484442112
   [druid] 2018-12-03 10:29:58,678 [main           ] WARN  g.analysis.mr.nu.NewUserRunner {1} - 
   java.lang.RuntimeException: inpath/ods/2018/11
	at com.qianfeng.analysis.mr.nu.NewUserRunner.handleInputOutput(NewUserRunner.java:110)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.run(NewUserRunner.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.main(NewUserRunner.java:25)
[druid] 2018-12-03 10:29:58,769 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 10:29:58,770 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 10:29:58,806 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 10:29:58,852 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 10:29:58,865 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Cleaning up the staging area file:/opt/app/hadoop-2.7.2/data/tmp/mapred/staging/361391801/.staging/job_local361391801_0001
   [druid] 2018-12-03 10:29:58,866 [main           ] WARN  .security.UserGroupInformation {1} - PriviledgedActionException as: (auth:SIMPLE) cause:java.io.IOException: No input paths specified in job
   [druid] 2018-12-03 10:29:58,866 [main           ] WARN  g.analysis.mr.nu.NewUserRunner {1} - NEW_USER TO MYSQL is failed !!!
   java.io.IOException: No input paths specified in job
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:189)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:248)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:1107)
	at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1124)
	at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:178)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:1023)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:976)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:976)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:582)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:612)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.run(NewUserRunner.java:57)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.nu.NewUserRunner.main(NewUserRunner.java:25)
[druid] 2018-12-03 10:30:55,861 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 10:30:55,863 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 10:30:55,891 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 10:30:55,935 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 10:30:56,024 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 10:30:56,321 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1620239648_0001
   [druid] 2018-12-03 10:30:56,326 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 10:30:56,332 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 10:30:56,344 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 10:30:56,345 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1620239648_0001_m_000000_0
   [druid] 2018-12-03 10:30:56,372 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:30:56,398 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:30:56,407 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 10:30:56,420 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 10:30:56,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 10:30:56,480 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 10:30:56,480 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 10:30:57,119 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:30:57,123 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 10:30:57,156 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 10:30:57,165 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1620239648_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:30:57,181 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:30:57,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1620239648_0001_m_000000_0' done.
   [druid] 2018-12-03 10:30:57,182 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1620239648_0001_m_000000_0
   [druid] 2018-12-03 10:30:57,183 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 10:30:57,190 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:30:57,209 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:30:57,210 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:30:57,216 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 10:30:57,223 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 10:30:57,223 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:30:57,430 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 10:30:57,718 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1620239648_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:30:57,719 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 10:30:57,719 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1620239648_0001_r_000000_0' done.
   [druid] 2018-12-03 10:30:57,722 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 10:30:58,432 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 10:30:58,432 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1620239648_0001
   [druid] 2018-12-03 10:30:58,445 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 10:30:58,445 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 10:30:58,445 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 10:30:58,445 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401916
   [druid] 2018-12-03 10:30:58,445 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 10:30:58,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 10:30:58,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 10:30:58,448 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 10:30:58,448 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 10:30:58,448 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 10:30:58,448 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 10:30:58,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 10:30:58,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-03 10:33:21,218 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 10:33:21,220 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 10:33:21,249 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 10:33:21,295 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 10:33:21,382 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 10:33:21,671 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 10:33:21,672 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local788202493_0001
   [druid] 2018-12-03 10:33:21,677 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 10:33:21,688 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 10:33:21,688 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local788202493_0001_m_000000_0
   [druid] 2018-12-03 10:33:21,710 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:33:21,728 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:33:21,734 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 10:33:21,743 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 10:33:21,746 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 10:33:21,808 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 10:33:21,809 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 10:33:22,356 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:33:22,359 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 10:33:22,407 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 10:33:22,413 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local788202493_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:33:22,422 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:33:22,423 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local788202493_0001_m_000000_0' done.
   [druid] 2018-12-03 10:33:22,423 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local788202493_0001_m_000000_0
   [druid] 2018-12-03 10:33:22,424 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 10:33:22,427 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:33:22,439 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:33:22,440 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:33:22,444 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 10:33:22,450 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 10:33:22,451 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:33:22,684 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 10:33:26,833 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local788202493_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:33:26,835 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 10:33:26,835 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local788202493_0001_r_000000_0' done.
   [druid] 2018-12-03 10:33:26,840 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 10:33:27,689 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 10:33:27,689 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local788202493_0001
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401908
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 10:33:27,709 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 10:33:27,710 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 10:33:27,711 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-03 10:42:27,806 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 10:42:27,809 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 10:42:27,841 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 10:42:27,889 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 10:42:27,968 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 10:42:28,324 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 10:42:28,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local246773236_0001
   [druid] 2018-12-03 10:42:28,329 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 10:42:28,341 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 10:42:28,342 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local246773236_0001_m_000000_0
   [druid] 2018-12-03 10:42:28,370 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:42:28,391 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:42:28,398 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 10:42:28,410 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 10:42:28,413 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 10:42:28,477 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 10:42:28,478 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 10:42:28,980 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:42:28,984 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 10:42:29,009 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 10:42:29,018 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local246773236_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:42:29,032 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:42:29,032 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local246773236_0001_m_000000_0' done.
   [druid] 2018-12-03 10:42:29,033 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local246773236_0001_m_000000_0
   [druid] 2018-12-03 10:42:29,033 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 10:42:29,036 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:42:29,050 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:42:29,050 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:42:29,056 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 10:42:29,063 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 10:42:29,064 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:42:29,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 10:42:29,863 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local246773236_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:42:29,866 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 10:42:29,867 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local246773236_0001_r_000000_0' done.
   [druid] 2018-12-03 10:42:29,871 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 10:42:30,328 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 10:42:30,328 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local246773236_0001
   [druid] 2018-12-03 10:42:30,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 10:42:30,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 10:42:30,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 10:42:30,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401908
   [druid] 2018-12-03 10:42:30,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 10:42:30,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 10:42:30,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 10:42:30,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 10:42:30,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 10:42:30,349 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 10:42:30,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 10:42:30,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 10:42:30,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 10:42:30,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 10:42:30,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486539264
   [druid] 2018-12-03 10:47:19,003 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 10:47:19,005 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 10:47:19,038 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 10:47:19,083 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 10:47:19,161 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 10:47:19,753 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local403648468_0001
   [druid] 2018-12-03 10:47:19,758 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 10:47:19,764 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 10:47:19,778 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 10:47:19,778 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local403648468_0001_m_000000_0
   [druid] 2018-12-03 10:47:19,796 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:47:19,819 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:47:19,827 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 10:47:19,836 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 10:47:19,838 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 10:47:19,900 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 10:47:19,902 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 10:47:20,758 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 10:47:23,359 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:47:23,362 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 10:47:23,399 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 10:47:23,406 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local403648468_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:47:23,418 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:47:23,419 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local403648468_0001_m_000000_0' done.
   [druid] 2018-12-03 10:47:23,419 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local403648468_0001_m_000000_0
   [druid] 2018-12-03 10:47:23,419 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 10:47:23,423 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 10:47:23,438 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 10:47:23,438 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:47:23,443 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 10:47:23,450 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 15874 bytes
   [druid] 2018-12-03 10:47:23,451 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 10:47:23,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 10:47:24,061 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local403648468_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 10:47:24,062 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 10:47:24,062 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local403648468_0001_r_000000_0' done.
   [druid] 2018-12-03 10:47:24,065 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 10:47:24,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 10:47:24,763 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local403648468_0001
   [druid] 2018-12-03 10:47:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 10:47:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 10:47:24,785 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=16242
   [druid] 2018-12-03 10:47:24,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=401908
   [druid] 2018-12-03 10:47:24,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 10:47:24,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 10:47:24,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 10:47:24,786 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 10:47:24,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 10:47:24,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 10:47:24,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 10:47:24,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 10:47:24,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 10:47:24,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 10:47:24,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=124
   [druid] 2018-12-03 10:47:24,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=15624
   [druid] 2018-12-03 10:47:24,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 10:47:24,788 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 10:47:24,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 10:47:24,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 10:47:24,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 10:47:24,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=124
   [druid] 2018-12-03 10:47:24,789 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 10:47:24,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=248
   [druid] 2018-12-03 10:47:24,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=421527552
   [druid] 2018-12-03 14:17:40,106 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:17:40,204 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:17:40,358 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:17:40,419 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:17:40,492 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:17:41,032 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:17:41,033 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1538713934_0001
   [druid] 2018-12-03 14:17:41,040 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:17:41,052 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:17:41,053 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1538713934_0001_m_000000_0
   [druid] 2018-12-03 14:17:41,072 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:17:41,091 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:17:41,097 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:17:41,109 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:17:41,111 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:17:41,170 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:17:41,170 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:17:41,581 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:17:41,582 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:17:41,583 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1538713934_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.valueOf(Long.java:803)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:51)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 14:17:42,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:17:42,038 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1538713934_0001
   [druid] 2018-12-03 14:17:42,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-03 14:20:38,462 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:20:38,465 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:20:38,497 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:20:38,549 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:20:38,679 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:20:38,999 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:20:39,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local579799761_0001
   [druid] 2018-12-03 14:20:39,006 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:20:39,018 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:20:39,018 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local579799761_0001_m_000000_0
   [druid] 2018-12-03 14:20:39,048 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:20:39,067 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:20:39,073 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:20:39,081 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:20:39,084 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:20:39,132 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:20:39,132 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:20:39,532 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:20:39,533 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:20:39,534 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local579799761_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.valueOf(Long.java:803)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:51)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 14:20:40,008 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:20:40,012 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local579799761_0001
   [druid] 2018-12-03 14:20:40,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-03 14:23:21,496 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:23:21,498 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:23:21,519 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:23:21,559 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:23:21,631 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:23:21,939 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:23:21,942 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1435599559_0001
   [druid] 2018-12-03 14:23:21,945 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:23:21,956 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:23:21,957 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1435599559_0001_m_000000_0
   [druid] 2018-12-03 14:23:21,979 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:23:22,005 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:23:22,012 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:23:22,020 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:23:22,022 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:23:22,072 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:23:22,072 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:23:22,491 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:23:22,491 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:23:22,492 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1435599559_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.valueOf(Long.java:803)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:51)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 14:23:22,949 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:23:22,951 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1435599559_0001
   [druid] 2018-12-03 14:23:22,964 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-03 14:27:37,044 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:27:37,046 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:27:37,071 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:27:37,127 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:27:37,230 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:27:37,519 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:27:37,522 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local487297434_0001
   [druid] 2018-12-03 14:27:37,524 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:27:37,533 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:27:37,534 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local487297434_0001_m_000000_0
   [druid] 2018-12-03 14:27:37,554 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:27:37,576 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:27:37,582 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:27:37,592 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:27:37,594 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:27:37,656 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:27:37,656 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:27:38,087 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:27:38,087 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:27:38,088 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local487297434_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.valueOf(Long.java:803)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:51)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 14:27:38,525 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:27:38,526 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local487297434_0001
   [druid] 2018-12-03 14:27:38,531 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-03 14:32:41,840 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:32:41,842 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:32:41,871 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:32:41,916 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:32:42,018 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:32:42,344 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:32:42,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local308865929_0001
   [druid] 2018-12-03 14:32:42,354 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:32:42,369 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:32:42,371 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local308865929_0001_m_000000_0
   [druid] 2018-12-03 14:32:42,404 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:32:42,434 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:32:42,443 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:32:42,454 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:32:42,457 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:32:42,512 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:32:42,513 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:32:42,977 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:32:42,977 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:32:42,978 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local308865929_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.valueOf(Long.java:803)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:51)
	at com.qianfeng.analysis.mr.au.ActiveUserMapper.map(ActiveUserMapper.java:22)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 14:32:43,348 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:32:43,350 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local308865929_0001
   [druid] 2018-12-03 14:32:43,355 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-03 14:45:04,471 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 14:45:04,475 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 14:45:04,510 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 14:45:04,560 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 14:45:04,678 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 14:45:05,004 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 14:45:05,005 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local896273405_0001
   [druid] 2018-12-03 14:45:05,012 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 14:45:05,023 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 14:45:05,024 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local896273405_0001_m_000000_0
   [druid] 2018-12-03 14:45:05,045 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:45:05,062 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:45:05,069 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 14:45:05,077 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 14:45:05,079 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 14:45:05,144 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 14:45:05,144 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 14:45:05,588 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,588 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,590 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,590 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,590 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,590 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,591 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,591 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:05,591 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 14:45:06,012 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 14:45:06,123 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 14:45:06,238 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 14:45:07,043 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 14:45:07,179 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local896273405_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 14:45:07,262 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 14:45:07,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local896273405_0001_m_000000_0' done.
   [druid] 2018-12-03 14:45:07,263 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local896273405_0001_m_000000_0
   [druid] 2018-12-03 14:45:07,263 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 14:45:07,373 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 14:45:07,386 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 14:45:07,386 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 14:45:07,400 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 14:45:07,431 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 166456 bytes
   [druid] 2018-12-03 14:45:07,431 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 14:45:08,086 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 14:45:16,389 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 14:45:17,088 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 73%
   [druid] 2018-12-03 14:45:19,389 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 14:45:20,089 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 14:45:22,389 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 14:45:28,213 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local896273405_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 14:45:28,214 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 14:45:28,214 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local896273405_0001_r_000000_0' done.
   [druid] 2018-12-03 14:45:28,224 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 14:45:29,091 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local896273405_0001
   [druid] 2018-12-03 14:45:29,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 14:45:29,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 14:45:29,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=166824
   [druid] 2018-12-03 14:45:29,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=703116
   [druid] 2018-12-03 14:45:29,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 14:45:29,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 14:45:29,112 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 14:45:29,112 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 14:45:29,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1294
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=163866
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=8
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 14:45:29,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1294
   [druid] 2018-12-03 14:45:29,116 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=8
   [druid] 2018-12-03 14:45:29,116 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2588
   [druid] 2018-12-03 14:45:29,116 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=572522496
   [druid] 2018-12-03 16:06:15,551 [main           ] WARN  lysis.mr.am.ActiveMemberRunner {1} - 
   java.lang.RuntimeException: inpath/ods/12/02
	at com.qianfeng.analysis.mr.am.ActiveMemberRunner.handleInputOutput(ActiveMemberRunner.java:110)
	at com.qianfeng.analysis.mr.am.ActiveMemberRunner.run(ActiveMemberRunner.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.am.ActiveMemberRunner.main(ActiveMemberRunner.java:25)
[druid] 2018-12-03 16:06:16,302 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 16:06:16,304 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 16:06:16,859 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 16:06:17,063 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 16:06:17,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Cleaning up the staging area file:/opt/app/hadoop-2.7.2/data/tmp/mapred/staging/1369867402/.staging/job_local1369867402_0001
   [druid] 2018-12-03 16:06:17,324 [main           ] WARN  .security.UserGroupInformation {1} - PriviledgedActionException as: (auth:SIMPLE) cause:java.io.IOException: No input paths specified in job
   [druid] 2018-12-03 16:06:17,324 [main           ] WARN  lysis.mr.am.ActiveMemberRunner {1} - NEW_USER TO MYSQL is failed !!!
   java.io.IOException: No input paths specified in job
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:189)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:248)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:1107)
	at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1124)
	at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:178)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:1023)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:976)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:976)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:582)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:612)
	at com.qianfeng.analysis.mr.am.ActiveMemberRunner.run(ActiveMemberRunner.java:57)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.qianfeng.analysis.mr.am.ActiveMemberRunner.main(ActiveMemberRunner.java:25)
[druid] 2018-12-03 16:07:11,095 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 16:07:11,097 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 16:07:11,138 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 16:07:11,303 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 16:07:13,132 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 16:07:20,675 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 16:07:20,681 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local246211482_0001
   [druid] 2018-12-03 16:07:20,687 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 16:07:20,747 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 16:07:20,747 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local246211482_0001_m_000000_0
   [druid] 2018-12-03 16:07:20,780 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 16:07:20,815 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 16:07:20,821 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop01:8020/ods/11/11/part-m-00000:0+317956
   [druid] 2018-12-03 16:07:20,833 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 16:07:20,835 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 16:07:20,870 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 16:07:20,870 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 16:07:21,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 16:07:22,143 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 16:07:22,169 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 16:07:22,242 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 16:07:22,251 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local246211482_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 16:07:22,265 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 16:07:22,266 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local246211482_0001_m_000000_0' done.
   [druid] 2018-12-03 16:07:22,266 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local246211482_0001_m_000000_0
   [druid] 2018-12-03 16:07:22,266 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 16:07:22,272 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 16:07:22,288 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 16:07:22,289 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 16:07:22,293 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 16:07:22,300 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 50896 bytes
   [druid] 2018-12-03 16:07:22,300 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 16:07:22,726 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 16:07:24,701 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local246211482_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 16:07:24,702 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 16:07:24,702 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local246211482_0001_r_000000_0' done.
   [druid] 2018-12-03 16:07:24,705 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 16:07:24,736 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 16:07:24,737 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local246211482_0001
   [druid] 2018-12-03 16:07:24,780 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 16:07:24,780 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 16:07:24,780 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=51264
   [druid] 2018-12-03 16:07:24,780 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=472000
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=635912
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 16:07:24,781 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=656
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=382
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=50130
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 16:07:24,782 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 16:07:24,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=382
   [druid] 2018-12-03 16:07:24,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 16:07:24,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=764
   [druid] 2018-12-03 16:07:24,783 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=575668224
   [druid] 2018-12-03 18:51:22,031 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 18:51:22,055 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 18:51:22,351 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 18:51:22,547 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 18:51:23,320 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 18:51:23,372 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local965923657_0001
   [druid] 2018-12-03 18:51:23,406 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 18:51:23,471 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 18:51:23,472 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local965923657_0001_m_000000_0
   [druid] 2018-12-03 18:51:23,550 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 18:51:23,581 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 18:51:23,588 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 18:51:24,447 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 18:51:24,895 [pool-4-thread-1] INFO  com.qianfeng.etl.mr.MapperDemo {1} - 8201350
   [druid] 2018-12-03 18:51:24,895 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:51:25,392 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local965923657_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 18:51:25,421 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:51:25,421 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local965923657_0001_m_000000_0 is allowed to commit now
   [druid] 2018-12-03 18:51:25,485 [pool-4-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local965923657_0001_m_000000_0' to /ods/11/11
   [druid] 2018-12-03 18:51:25,486 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:51:25,486 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local965923657_0001_m_000000_0' done.
   [druid] 2018-12-03 18:51:25,486 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local965923657_0001_m_000000_0
   [druid] 2018-12-03 18:51:25,486 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 18:51:26,477 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 18:51:26,478 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local965923657_0001
   [druid] 2018-12-03 18:51:26,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 15
   [druid] 2018-12-03 18:51:26,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 18:51:26,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=162
   [druid] 2018-12-03 18:51:26,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=166980
   [druid] 2018-12-03 18:51:26,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 18:51:26,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 18:51:26,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 18:51:26,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=32947
   [druid] 2018-12-03 18:51:26,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=643496
   [druid] 2018-12-03 18:51:26,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=7
   [druid] 2018-12-03 18:51:26,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 18:51:26,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=2
   [druid] 2018-12-03 18:51:26,575 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 18:51:26,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-03 18:51:26,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1350
   [druid] 2018-12-03 18:51:26,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=109
   [druid] 2018-12-03 18:51:26,576 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-03 18:51:26,577 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=80216064
   [druid] 2018-12-03 18:52:52,783 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 18:52:52,786 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 18:52:52,823 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 18:52:52,867 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 18:52:52,946 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 18:52:53,329 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 18:52:53,335 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local725995262_0001
   [druid] 2018-12-03 18:52:53,338 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 18:52:53,351 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 18:52:53,352 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local725995262_0001_m_000000_0
   [druid] 2018-12-03 18:52:53,377 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 18:52:53,402 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 18:52:53,409 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 18:52:53,434 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 18:52:53,436 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 18:52:53,488 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 18:52:53,488 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 18:52:54,121 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:52:54,125 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 18:52:54,339 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 18:52:54,341 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 18:52:54,365 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local725995262_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 18:52:54,375 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:52:54,375 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local725995262_0001_m_000000_0' done.
   [druid] 2018-12-03 18:52:54,375 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local725995262_0001_m_000000_0
   [druid] 2018-12-03 18:52:54,376 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 18:52:54,392 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 18:52:54,404 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 18:52:54,405 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:52:54,420 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 18:52:54,452 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 24066 bytes
   [druid] 2018-12-03 18:52:54,454 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:52:55,352 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 18:52:57,156 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local725995262_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 18:52:57,158 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 18:52:57,159 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local725995262_0001_r_000000_0' done.
   [druid] 2018-12-03 18:52:57,165 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 18:52:57,353 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 18:52:57,353 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local725995262_0001
   [druid] 2018-12-03 18:52:57,378 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 18:52:57,378 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 18:52:57,378 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=24390
   [druid] 2018-12-03 18:52:57,378 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=417500
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 18:52:57,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=188
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=23688
   [druid] 2018-12-03 18:52:57,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=188
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 18:52:57,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=376
   [druid] 2018-12-03 18:52:57,382 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=567279616
   [druid] 2018-12-03 18:57:10,563 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 18:57:10,565 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 18:57:10,587 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 18:57:10,626 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 18:57:10,705 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 18:57:11,365 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local440764316_0001
   [druid] 2018-12-03 18:57:11,377 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 18:57:11,384 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 18:57:11,395 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 18:57:11,396 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local440764316_0001_m_000000_0
   [druid] 2018-12-03 18:57:11,423 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 18:57:11,443 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 18:57:11,450 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 18:57:11,457 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 18:57:11,461 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 18:57:11,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 18:57:11,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 18:57:12,101 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:57:12,104 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 18:57:12,160 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 18:57:12,168 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local440764316_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 18:57:12,181 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:57:12,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local440764316_0001_m_000000_0' done.
   [druid] 2018-12-03 18:57:12,181 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local440764316_0001_m_000000_0
   [druid] 2018-12-03 18:57:12,181 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 18:57:12,186 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 18:57:12,204 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 18:57:12,205 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:57:12,212 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 18:57:12,223 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 24066 bytes
   [druid] 2018-12-03 18:57:12,223 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 18:57:12,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 18:57:13,114 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local440764316_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 18:57:13,131 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 18:57:13,131 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local440764316_0001_r_000000_0' done.
   [druid] 2018-12-03 18:57:13,134 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 18:57:13,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 18:57:13,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local440764316_0001
   [druid] 2018-12-03 18:57:13,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 18:57:13,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 18:57:13,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=24390
   [druid] 2018-12-03 18:57:13,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=417500
   [druid] 2018-12-03 18:57:13,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 18:57:13,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=188
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=23688
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 18:57:13,404 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=188
   [druid] 2018-12-03 18:57:13,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 18:57:13,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=376
   [druid] 2018-12-03 18:57:13,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-03 19:18:05,564 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 19:18:05,566 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 19:18:05,587 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 19:18:05,624 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 19:18:05,691 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 19:18:05,973 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 19:18:05,974 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local774868498_0001
   [druid] 2018-12-03 19:18:05,979 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 19:18:05,993 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 19:18:05,994 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local774868498_0001_m_000000_0
   [druid] 2018-12-03 19:18:06,020 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:18:06,042 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:18:06,052 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 19:18:06,062 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 19:18:06,066 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 19:18:06,133 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 19:18:06,133 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 19:18:06,689 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:18:06,692 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 19:18:06,760 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 19:18:06,767 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774868498_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:18:06,781 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:18:06,782 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774868498_0001_m_000000_0' done.
   [druid] 2018-12-03 19:18:06,782 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local774868498_0001_m_000000_0
   [druid] 2018-12-03 19:18:06,783 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 19:18:06,787 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:18:06,805 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:18:06,806 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:18:06,812 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 19:18:06,821 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 24066 bytes
   [druid] 2018-12-03 19:18:06,821 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:18:06,978 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 19:18:07,384 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774868498_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:18:07,385 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 19:18:07,385 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774868498_0001_r_000000_0' done.
   [druid] 2018-12-03 19:18:07,389 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 19:18:07,980 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 19:18:07,980 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local774868498_0001
   [druid] 2018-12-03 19:18:08,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 19:18:08,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 19:18:08,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=24390
   [druid] 2018-12-03 19:18:08,001 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=417500
   [druid] 2018-12-03 19:18:08,001 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 19:18:08,002 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 19:18:08,002 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 19:18:08,003 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 19:18:08,004 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 19:18:08,004 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 19:18:08,004 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 19:18:08,004 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 19:18:08,005 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 19:18:08,005 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 19:18:08,005 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=188
   [druid] 2018-12-03 19:18:08,005 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=23688
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 19:18:08,006 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=188
   [druid] 2018-12-03 19:18:08,007 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 19:18:08,007 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=376
   [druid] 2018-12-03 19:18:08,007 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=419430400
   [druid] 2018-12-03 19:19:13,853 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 19:19:13,855 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 19:19:13,883 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 19:19:13,926 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 19:19:14,004 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 19:19:14,265 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local80419048_0001
   [druid] 2018-12-03 19:19:14,271 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 19:19:14,277 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 19:19:14,290 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 19:19:14,290 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local80419048_0001_m_000000_0
   [druid] 2018-12-03 19:19:14,313 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:19:14,336 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:19:14,344 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 19:19:14,352 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 19:19:14,355 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 19:19:14,392 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 19:19:14,392 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 19:19:14,787 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,788 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,788 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,788 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,789 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,789 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,789 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,790 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:14,790 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:19:15,094 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:19:15,098 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 19:19:15,196 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 19:19:15,204 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local80419048_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:19:15,226 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:19:15,226 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local80419048_0001_m_000000_0' done.
   [druid] 2018-12-03 19:19:15,227 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local80419048_0001_m_000000_0
   [druid] 2018-12-03 19:19:15,227 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 19:19:15,232 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:19:15,256 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:19:15,259 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:19:15,266 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 19:19:15,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 19:19:15,277 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 348420 bytes
   [druid] 2018-12-03 19:19:15,277 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:19:15,932 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local80419048_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:19:15,932 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 19:19:15,933 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local80419048_0001_r_000000_0' done.
   [druid] 2018-12-03 19:19:15,935 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 19:19:16,272 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 19:19:16,272 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local80419048_0001
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=348744
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1066236
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 19:19:16,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 19:19:16,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=2682
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=343054
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=8
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=2682
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=8
   [druid] 2018-12-03 19:19:16,285 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=5364
   [druid] 2018-12-03 19:19:16,286 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=570425344
   [druid] 2018-12-03 19:20:32,086 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 19:20:32,087 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 19:20:32,110 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 19:20:32,153 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 19:20:32,231 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 19:20:32,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1600622967_0001
   [druid] 2018-12-03 19:20:32,574 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 19:20:32,581 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 19:20:32,593 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 19:20:32,594 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1600622967_0001_m_000000_0
   [druid] 2018-12-03 19:20:32,615 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:20:32,634 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:20:32,642 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 19:20:32,651 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 19:20:32,654 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 19:20:32,685 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 19:20:32,685 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 19:20:33,133 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,133 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,133 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,134 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,134 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,134 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,134 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,134 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:20:33,135 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 19:21:19,937 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 19:21:19,939 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 19:21:19,984 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 19:21:20,030 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 19:21:20,260 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 19:21:20,553 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 19:21:20,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local326003585_0001
   [druid] 2018-12-03 19:21:20,560 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 19:21:20,571 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 19:21:20,572 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local326003585_0001_m_000000_0
   [druid] 2018-12-03 19:21:20,593 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:21:20,611 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:21:20,619 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 19:21:20,627 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 19:21:20,629 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 19:21:20,666 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 19:21:20,667 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 19:21:21,309 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:21:21,313 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 19:21:21,371 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 19:21:21,405 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local326003585_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:21:21,417 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:21:21,417 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local326003585_0001_m_000000_0' done.
   [druid] 2018-12-03 19:21:21,417 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local326003585_0001_m_000000_0
   [druid] 2018-12-03 19:21:21,418 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 19:21:21,423 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 19:21:21,440 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 19:21:21,441 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:21:21,447 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 19:21:21,455 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 171936 bytes
   [druid] 2018-12-03 19:21:21,456 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 19:21:21,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 19:21:21,964 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local326003585_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 19:21:21,965 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 19:21:21,965 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local326003585_0001_r_000000_0' done.
   [druid] 2018-12-03 19:21:21,968 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 19:21:22,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 19:21:22,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local326003585_0001
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=172260
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=713280
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 19:21:22,572 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1534
   [druid] 2018-12-03 19:21:22,573 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=168866
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1534
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3068
   [druid] 2018-12-03 19:21:22,574 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=417333248
   [druid] 2018-12-03 20:01:37,070 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:01:37,073 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:01:37,106 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:01:37,145 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:01:37,196 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:01:38,220 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:01:38,224 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local801662037_0001
   [druid] 2018-12-03 20:01:38,233 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:01:38,249 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:01:38,251 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local801662037_0001_m_000000_0
   [druid] 2018-12-03 20:01:38,281 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:01:38,307 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:01:38,319 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:01:38,335 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:01:38,339 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:01:38,436 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:01:38,437 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:01:39,633 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:01:42,623 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:01:42,812 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 20:01:43,880 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 20:01:44,108 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local801662037_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:01:44,534 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:01:44,536 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local801662037_0001_m_000000_0' done.
   [druid] 2018-12-03 20:01:44,536 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local801662037_0001_m_000000_0
   [druid] 2018-12-03 20:01:44,540 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 20:01:44,758 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 20:01:44,891 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:01:44,925 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:01:44,925 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:01:45,039 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 20:01:45,761 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 171936 bytes
   [druid] 2018-12-03 20:01:45,762 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:01:49,701 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local801662037_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:01:49,702 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 20:01:49,702 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local801662037_0001_r_000000_0' done.
   [druid] 2018-12-03 20:01:49,736 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 20:01:49,759 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 20:01:49,759 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local801662037_0001
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=172260
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=713280
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 20:01:49,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 20:01:49,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 20:01:49,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 20:01:49,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 20:01:49,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 20:01:49,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1534
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=168866
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 20:01:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 20:01:49,820 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 20:01:49,820 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1534
   [druid] 2018-12-03 20:01:49,820 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 20:01:49,820 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3068
   [druid] 2018-12-03 20:01:49,820 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=533725184
   [druid] 2018-12-03 20:02:04,961 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:02:04,964 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:02:04,996 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:02:05,034 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:02:05,101 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:02:05,517 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:02:05,520 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1608458495_0001
   [druid] 2018-12-03 20:02:05,528 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:02:05,543 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:02:05,544 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1608458495_0001_m_000000_0
   [druid] 2018-12-03 20:02:05,573 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:02:05,602 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:02:05,615 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:02:05,626 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:02:05,630 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:02:05,668 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:02:05,668 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:02:06,327 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:02:06,330 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 20:02:06,391 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 20:02:06,400 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1608458495_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:02:06,418 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:02:06,418 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1608458495_0001_m_000000_0' done.
   [druid] 2018-12-03 20:02:06,418 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1608458495_0001_m_000000_0
   [druid] 2018-12-03 20:02:06,419 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 20:02:06,426 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:02:06,452 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:02:06,457 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:02:06,464 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 20:02:06,481 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 171936 bytes
   [druid] 2018-12-03 20:02:06,482 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:02:06,526 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 20:02:07,337 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1608458495_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:02:07,338 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 20:02:07,338 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1608458495_0001_r_000000_0' done.
   [druid] 2018-12-03 20:02:07,340 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 20:02:07,529 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 20:02:07,529 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1608458495_0001
   [druid] 2018-12-03 20:02:07,558 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 20:02:07,558 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 20:02:07,558 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=172260
   [druid] 2018-12-03 20:02:07,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=713288
   [druid] 2018-12-03 20:02:07,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 20:02:07,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 20:02:07,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 20:02:07,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 20:02:07,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 20:02:07,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 20:02:07,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 20:02:07,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1534
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=168866
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 20:02:07,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 20:02:07,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 20:02:07,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 20:02:07,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 20:02:07,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1534
   [druid] 2018-12-03 20:02:07,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 20:02:07,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3068
   [druid] 2018-12-03 20:02:07,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-03 20:05:01,230 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:05:01,232 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:05:01,265 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:05:01,316 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:05:01,361 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:05:01,882 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:05:01,883 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local949469185_0001
   [druid] 2018-12-03 20:05:01,895 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:05:01,910 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:05:01,921 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local949469185_0001_m_000000_0
   [druid] 2018-12-03 20:05:01,956 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:05:01,985 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:05:01,998 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:05:02,015 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:05:02,021 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:05:02,061 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:05:02,062 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:05:02,849 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:05:02,853 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 20:05:02,895 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:05:03,117 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 20:05:03,137 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local949469185_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:05:03,164 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:05:03,164 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local949469185_0001_m_000000_0' done.
   [druid] 2018-12-03 20:05:03,165 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local949469185_0001_m_000000_0
   [druid] 2018-12-03 20:05:03,165 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 20:05:03,171 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:05:03,189 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:05:03,190 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:05:03,197 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 20:05:03,208 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 171936 bytes
   [druid] 2018-12-03 20:05:03,209 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:05:03,923 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 20:05:04,262 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local949469185_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:05:04,263 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 20:05:04,263 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local949469185_0001_r_000000_0' done.
   [druid] 2018-12-03 20:05:04,266 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 20:05:04,923 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 20:05:04,924 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local949469185_0001
   [druid] 2018-12-03 20:05:04,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 20:05:04,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 20:05:04,938 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=172260
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=713280
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 20:05:04,939 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1534
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=168866
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 20:05:04,940 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1534
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3068
   [druid] 2018-12-03 20:05:04,941 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=534773760
   [druid] 2018-12-03 20:23:01,218 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:23:01,220 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:23:01,249 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:23:01,300 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:23:01,348 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:23:01,731 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local790606133_0001
   [druid] 2018-12-03 20:23:01,736 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:23:01,744 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:23:01,764 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:23:01,764 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local790606133_0001_m_000000_0
   [druid] 2018-12-03 20:23:01,798 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:23:01,828 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:23:01,846 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:23:01,859 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:23:01,864 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:23:01,924 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:23:01,924 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:23:02,616 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:23:02,620 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 20:23:02,682 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 20:23:02,694 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local790606133_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:23:02,720 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:23:02,720 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local790606133_0001_m_000000_0' done.
   [druid] 2018-12-03 20:23:02,720 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local790606133_0001_m_000000_0
   [druid] 2018-12-03 20:23:02,720 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 20:23:02,727 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:23:02,736 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 20:23:02,747 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:23:02,748 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:23:02,756 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 20:23:02,766 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 171936 bytes
   [druid] 2018-12-03 20:23:02,766 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:23:03,475 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local790606133_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:23:03,475 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 20:23:03,476 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local790606133_0001_r_000000_0' done.
   [druid] 2018-12-03 20:23:03,478 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 20:23:03,739 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 20:23:03,739 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local790606133_0001
   [druid] 2018-12-03 20:23:03,754 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=172260
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=713280
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 20:23:03,755 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 20:23:03,756 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1534
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=168866
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=4
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1534
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=4
   [druid] 2018-12-03 20:23:03,757 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3068
   [druid] 2018-12-03 20:23:03,758 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=570425344
   [druid] 2018-12-03 20:25:56,857 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:25:56,860 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:25:56,894 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:25:56,942 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:25:56,992 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:25:57,390 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:25:57,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1302429224_0001
   [druid] 2018-12-03 20:25:57,399 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:25:57,414 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:25:57,415 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1302429224_0001_m_000000_0
   [druid] 2018-12-03 20:25:57,442 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:25:57,466 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:25:57,724 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:25:57,737 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:25:57,739 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:25:57,776 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:25:57,776 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:26:00,359 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:34:11,676 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:34:11,678 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:34:11,710 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:34:11,749 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:34:11,788 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:34:12,521 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:34:12,522 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1991352009_0001
   [druid] 2018-12-03 20:34:12,532 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:34:12,546 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:34:12,548 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1991352009_0001_m_000000_0
   [druid] 2018-12-03 20:34:12,580 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:34:12,608 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:34:12,716 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:34:12,734 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:34:12,738 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:34:12,788 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:34:12,789 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:34:13,699 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:35:52,857 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:35:52,859 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:35:52,880 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 20:35:53,005 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:35:53,077 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:35:53,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local222214715_0001
   [druid] 2018-12-03 20:35:53,605 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:35:53,611 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:35:53,624 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:35:53,624 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local222214715_0001_m_000000_0
   [druid] 2018-12-03 20:35:53,651 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:35:53,667 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:35:53,674 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 20:35:53,683 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 20:35:53,686 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 20:35:53,746 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 20:35:53,746 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 20:35:54,605 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:35:55,333 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:35:56,024 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 20:35:56,074 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 20:35:56,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local222214715_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:35:56,270 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:35:56,270 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local222214715_0001_m_000000_0' done.
   [druid] 2018-12-03 20:35:56,270 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local222214715_0001_m_000000_0
   [druid] 2018-12-03 20:35:56,271 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 20:35:56,276 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:35:56,313 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:35:56,313 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:35:56,321 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 20:35:56,330 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 24066 bytes
   [druid] 2018-12-03 20:35:56,330 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:35:56,609 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 20:35:58,341 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local222214715_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 20:35:58,344 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 20:35:58,344 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local222214715_0001_r_000000_0' done.
   [druid] 2018-12-03 20:35:58,347 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 20:35:58,609 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 20:35:58,609 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local222214715_0001
   [druid] 2018-12-03 20:35:58,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 20:35:58,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=24390
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=417500
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1286992
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 20:35:58,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1350
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=188
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=23688
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 20:35:58,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=2
   [druid] 2018-12-03 20:35:58,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 20:35:58,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=188
   [druid] 2018-12-03 20:35:58,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=2
   [druid] 2018-12-03 20:35:58,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=376
   [druid] 2018-12-03 20:35:58,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=482344960
   [druid] 2018-12-03 20:42:46,842 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:42:46,845 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:42:46,947 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:42:47,087 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:42:47,520 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:42:47,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1018662213_0001
   [druid] 2018-12-03 20:42:47,531 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:42:47,616 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:42:47,617 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1018662213_0001_m_000000_0
   [druid] 2018-12-03 20:42:47,641 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:42:47,663 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:42:51,281 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 20:42:51,283 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:43:28,192 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:43:29,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 1% reduce 0%
   [druid] 2018-12-03 20:43:45,677 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:44:06,751 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:44:06,754 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:44:06,877 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:44:06,977 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:44:07,725 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local323011590_0001
   [druid] 2018-12-03 20:44:07,739 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:44:07,752 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:44:07,798 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:44:07,799 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local323011590_0001_m_000000_0
   [druid] 2018-12-03 20:44:07,835 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:44:07,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:44:12,457 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 20:44:12,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:44:43,140 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:44:43,142 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:44:43,231 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:44:43,278 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:44:44,034 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:44:44,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local149355880_0001
   [druid] 2018-12-03 20:44:44,042 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:44:44,070 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:44:44,071 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local149355880_0001_m_000000_0
   [druid] 2018-12-03 20:44:44,098 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:44:44,124 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:44:47,784 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 20:44:47,787 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:50:49,808 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:50:49,810 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:50:49,918 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:50:50,004 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:50:50,455 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:50:50,456 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1169797335_0001
   [druid] 2018-12-03 20:50:50,466 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:50:50,538 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:50:50,539 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1169797335_0001_m_000000_0
   [druid] 2018-12-03 20:50:50,573 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:50:50,598 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:50:54,973 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 20:50:54,975 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 20:51:04,831 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 20:51:05,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 1% reduce 0%
   [druid] 2018-12-03 20:52:04,021 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 20:52:04,023 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 20:52:04,096 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 20:52:04,139 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 20:52:04,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1486216198_0001
   [druid] 2018-12-03 20:52:04,633 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 20:52:04,640 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 20:52:04,690 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 20:52:04,690 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1486216198_0001_m_000000_0
   [druid] 2018-12-03 20:52:04,725 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 20:52:04,756 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 20:52:08,386 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 20:52:08,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 21:15:54,339 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 21:15:54,342 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 21:15:54,440 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 21:15:54,512 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 21:15:55,074 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local353446319_0001
   [druid] 2018-12-03 21:15:55,080 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 21:15:55,093 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 21:15:55,175 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 21:15:55,187 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local353446319_0001_m_000000_0
   [druid] 2018-12-03 21:15:55,219 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 21:15:55,251 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 21:15:55,258 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 21:15:55,993 [pool-4-thread-1] INFO  com.qianfeng.etl.mr.MapperDemo {1} - 8201350
   [druid] 2018-12-03 21:15:55,993 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:15:56,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 21:16:06,833 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 21:16:06,835 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 21:16:06,939 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 21:16:07,006 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 21:16:07,406 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1136344765_0001
   [druid] 2018-12-03 21:16:07,417 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 21:16:07,425 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 21:16:07,539 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 21:16:07,540 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1136344765_0001_m_000000_0
   [druid] 2018-12-03 21:16:07,567 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 21:16:07,617 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 21:16:07,627 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/logs/11/11/2018-11-11.log:0+32947
   [druid] 2018-12-03 21:16:08,264 [pool-4-thread-1] INFO  com.qianfeng.etl.mr.MapperDemo {1} - 8201350
   [druid] 2018-12-03 21:16:08,265 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:16:08,411 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 21:16:10,106 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1136344765_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 21:16:10,120 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:16:10,121 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1136344765_0001_m_000000_0 is allowed to commit now
   [druid] 2018-12-03 21:16:11,742 [pool-4-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1136344765_0001_m_000000_0' to /ods/11/11
   [druid] 2018-12-03 21:16:11,743 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:16:11,743 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1136344765_0001_m_000000_0' done.
   [druid] 2018-12-03 21:16:11,744 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1136344765_0001_m_000000_0
   [druid] 2018-12-03 21:16:11,745 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 21:16:12,420 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 21:16:13,420 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1136344765_0001
   [druid] 2018-12-03 21:16:13,432 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 15
   [druid] 2018-12-03 21:16:13,432 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 21:16:13,432 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=162
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=166984
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=32947
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=643496
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=7
   [druid] 2018-12-03 21:16:13,433 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=3
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1350
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=109
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-03 21:16:13,434 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=168296448
   [druid] 2018-12-03 21:16:39,998 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 21:16:39,999 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 21:16:40,028 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 21:16:40,066 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 21:16:40,112 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 21:16:40,594 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1057601881_0001
   [druid] 2018-12-03 21:16:40,599 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 21:16:40,607 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 21:16:40,621 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 21:16:40,622 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1057601881_0001_m_000000_0
   [druid] 2018-12-03 21:16:40,651 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 21:16:40,679 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 21:16:40,699 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+643496
   [druid] 2018-12-03 21:16:40,714 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 21:16:40,717 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 21:16:40,771 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 21:16:40,772 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 21:16:41,806 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 21:17:03,629 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:39:21,986 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 21:39:21,989 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 21:39:22,014 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 21:39:22,057 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 21:39:22,136 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 21:39:22,439 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 21:39:22,440 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local449204343_0001
   [druid] 2018-12-03 21:39:22,448 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 21:39:22,462 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 21:39:22,462 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local449204343_0001_m_000000_0
   [druid] 2018-12-03 21:39:22,486 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 21:39:22,505 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 21:39:22,512 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/new/1.log:0+2249
   [druid] 2018-12-03 21:39:22,519 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 21:39:22,523 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 21:39:22,597 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 21:39:22,598 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 21:39:23,011 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:39:23,014 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 21:39:23,043 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local449204343_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 21:39:23,051 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:39:23,052 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local449204343_0001_m_000000_0' done.
   [druid] 2018-12-03 21:39:23,052 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local449204343_0001_m_000000_0
   [druid] 2018-12-03 21:39:23,052 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 21:39:23,056 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 21:39:23,071 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 21:39:23,072 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:39:23,077 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 21:39:23,085 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-03 21:39:23,085 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 21:39:23,446 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 21:39:23,705 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local449204343_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 21:39:23,706 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 21:39:23,707 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local449204343_0001_r_000000_0' done.
   [druid] 2018-12-03 21:39:23,709 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 21:39:24,448 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 21:39:24,449 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local449204343_0001
   [druid] 2018-12-03 21:39:24,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 21:39:24,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 21:39:24,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=298
   [druid] 2018-12-03 21:39:24,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=369320
   [druid] 2018-12-03 21:39:24,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 21:39:24,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 21:39:24,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 21:39:24,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=4498
   [druid] 2018-12-03 21:39:24,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=5
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-03 21:39:24,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=93
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-03 21:39:24,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=424673280
   [druid] 2018-12-03 22:01:45,831 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 22:01:45,833 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 22:01:45,855 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 22:01:45,899 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 22:01:46,005 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 22:01:46,360 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 22:01:46,361 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1229659193_0001
   [druid] 2018-12-03 22:01:46,369 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 22:01:46,382 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 22:01:46,383 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1229659193_0001_m_000000_0
   [druid] 2018-12-03 22:01:46,412 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:01:46,441 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:01:46,452 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/2018-11-11.log:0+784323
   [druid] 2018-12-03 22:01:46,463 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 22:01:46,468 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 22:01:46,528 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 22:01:46,528 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 22:01:46,949 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,953 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,953 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,953 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,954 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,954 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,954 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,955 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:46,955 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTimeuuid
   [druid] 2018-12-03 22:01:47,364 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 22:01:48,211 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:01:48,215 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 22:01:48,542 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 22:01:49,913 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1229659193_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:01:49,924 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:01:49,925 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1229659193_0001_m_000000_0' done.
   [druid] 2018-12-03 22:01:49,925 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1229659193_0001_m_000000_0
   [druid] 2018-12-03 22:01:49,926 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 22:01:49,930 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:01:49,946 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:01:49,951 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:01:49,957 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 22:01:49,964 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 423488 bytes
   [druid] 2018-12-03 22:01:49,964 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:01:50,366 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 22:02:03,399 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1229659193_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:02:03,400 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 22:02:03,400 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1229659193_0001_r_000000_0' done.
   [druid] 2018-12-03 22:02:03,403 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 22:02:04,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 22:02:04,367 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1229659193_0001
   [druid] 2018-12-03 22:02:04,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 22:02:04,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 22:02:04,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=423816
   [druid] 2018-12-03 22:02:04,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1216392
   [druid] 2018-12-03 22:02:04,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 22:02:04,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 22:02:04,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 22:02:04,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1568646
   [druid] 2018-12-03 22:02:04,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 22:02:04,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 22:02:04,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 22:02:04,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 22:02:04,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 22:02:04,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-03 22:02:04,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-03 22:02:04,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=417162
   [druid] 2018-12-03 22:02:04,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 22:02:04,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 22:02:04,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 22:02:04,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=22
   [druid] 2018-12-03 22:02:04,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 22:02:04,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-03 22:02:04,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=22
   [druid] 2018-12-03 22:02:04,392 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-03 22:02:04,392 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=578813952
   [druid] 2018-12-03 22:10:57,461 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 22:10:57,462 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 22:10:57,481 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 22:10:57,517 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 22:10:57,583 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 22:10:57,954 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1604482005_0001
   [druid] 2018-12-03 22:10:57,962 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 22:10:57,968 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 22:10:57,982 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 22:10:57,985 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1604482005_0001_m_000000_0
   [druid] 2018-12-03 22:10:58,017 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:10:58,049 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:10:58,063 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/2018-11-11.log:0+784323
   [druid] 2018-12-03 22:10:58,075 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 22:10:58,079 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 22:10:58,145 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 22:10:58,146 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 22:10:58,991 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-03 22:10:59,152 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:10:59,156 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 22:10:59,207 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 22:10:59,216 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1604482005_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:10:59,234 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:10:59,234 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1604482005_0001_m_000000_0' done.
   [druid] 2018-12-03 22:10:59,234 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1604482005_0001_m_000000_0
   [druid] 2018-12-03 22:10:59,235 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 22:10:59,240 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:10:59,284 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:10:59,284 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:10:59,306 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 22:10:59,331 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31118 bytes
   [druid] 2018-12-03 22:10:59,332 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:10:59,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 22:11:00,567 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1604482005_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:11:00,569 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 22:11:00,569 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1604482005_0001_r_000000_0' done.
   [druid] 2018-12-03 22:11:00,573 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 22:11:00,994 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 22:11:00,995 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1604482005_0001
   [druid] 2018-12-03 22:11:01,008 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 22:11:01,008 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 22:11:01,008 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=31446
   [druid] 2018-12-03 22:11:01,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=431616
   [druid] 2018-12-03 22:11:01,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 22:11:01,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 22:11:01,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1568646
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-03 22:11:01,010 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=236
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=30644
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=236
   [druid] 2018-12-03 22:11:01,011 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-03 22:11:01,013 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=472
   [druid] 2018-12-03 22:11:01,013 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=542113792
   [druid] 2018-12-03 22:12:57,894 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-03 22:12:57,895 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-03 22:12:57,936 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-03 22:12:57,978 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-03 22:12:58,071 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-03 22:12:58,382 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-03 22:12:58,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local956013143_0001
   [druid] 2018-12-03 22:12:58,390 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-03 22:12:58,402 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-03 22:12:58,402 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local956013143_0001_m_000000_0
   [druid] 2018-12-03 22:12:58,423 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:12:58,445 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:12:58,453 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/2018-11-11.log:0+784323
   [druid] 2018-12-03 22:12:58,461 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-03 22:12:58,464 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-03 22:12:58,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-03 22:12:58,507 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-03 22:12:59,174 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:12:59,178 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-03 22:12:59,265 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-03 22:12:59,273 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local956013143_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:12:59,288 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:12:59,288 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local956013143_0001_m_000000_0' done.
   [druid] 2018-12-03 22:12:59,288 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local956013143_0001_m_000000_0
   [druid] 2018-12-03 22:12:59,288 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-03 22:12:59,293 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-03 22:12:59,308 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-03 22:12:59,309 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:12:59,315 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-03 22:12:59,322 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 223969 bytes
   [druid] 2018-12-03 22:12:59,322 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:12:59,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-03 22:13:01,321 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local956013143_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-03 22:13:01,322 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-03 22:13:01,323 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local956013143_0001_r_000000_0' done.
   [druid] 2018-12-03 22:13:01,327 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-03 22:13:01,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-03 22:13:01,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local956013143_0001
   [druid] 2018-12-03 22:13:01,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-03 22:13:01,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-03 22:13:01,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=224297
   [druid] 2018-12-03 22:13:01,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=817350
   [druid] 2018-12-03 22:13:01,400 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1568646
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-03 22:13:01,401 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1590
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1926
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=220115
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=108
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1926
   [druid] 2018-12-03 22:13:01,402 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-03 22:13:01,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3852
   [druid] 2018-12-03 22:13:01,403 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=483917824
   [druid] 2018-12-03 22:36:46,764 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:36:47,751 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 10% reduce 0%
   [druid] 2018-12-03 22:36:49,778 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-03 22:36:52,167 [pool-4-thread-1] WARN  hadoop.hdfs.BlockReaderFactory {1} - I/O error constructing remote block reader.
   java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3567)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:840)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:755)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:376)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:658)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1654)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:868)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:904)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:954)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:59)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:91)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:483)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 22:36:53,504 [pool-4-thread-1] WARN  g.apache.hadoop.hdfs.DFSClient {1} - Failed to connect to /192.168.8.10:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
   java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3567)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:840)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:755)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:376)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:658)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1654)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:868)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:904)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:954)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:59)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:91)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:483)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-03 22:36:54,420 [pool-4-thread-1] INFO  g.apache.hadoop.hdfs.DFSClient {1} - Could not obtain BP-1062874490-192.168.8.10-1543269861015:blk_1073741828_1004 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[192.168.8.10:50010,DS-95a1b5dc-c2fb-4f73-9489-a277dc1cc077,DISK] Dead nodes:  DatanodeInfoWithStorage[192.168.8.10:50010,DS-95a1b5dc-c2fb-4f73-9489-a277dc1cc077,DISK]. Will get new block locations from namenode and retry...
   [druid] 2018-12-03 22:36:54,422 [pool-4-thread-1] WARN  g.apache.hadoop.hdfs.DFSClient {1} - DFS chooseDataNode: got # 1 IOException, will wait for 1359.030080203365 msec.
   