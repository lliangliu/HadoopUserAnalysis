[druid] 2018-12-06 14:34:05,548 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:34:05,567 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:34:05,892 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:34:06,088 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:34:06,301 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:34:07,141 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:34:07,189 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1619392876_0001
   [druid] 2018-12-06 14:34:07,255 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:34:07,305 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:34:07,305 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1619392876_0001_m_000000_0
   [druid] 2018-12-06 14:34:07,341 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:34:07,375 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:34:07,382 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 14:34:07,399 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:34:07,402 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:34:07,458 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:34:07,458 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:34:08,152 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,152 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,152 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,153 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,153 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,154 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,154 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,154 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:08,287 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 14:34:08,327 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:08,331 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:34:08,651 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:34:08,659 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1619392876_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:34:08,669 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:08,669 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1619392876_0001_m_000000_0' done.
   [druid] 2018-12-06 14:34:08,669 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1619392876_0001_m_000000_0
   [druid] 2018-12-06 14:34:08,670 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:34:08,685 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:34:08,698 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:34:08,699 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:08,710 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:34:08,717 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 440048 bytes
   [druid] 2018-12-06 14:34:08,718 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:09,288 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:34:10,348 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1619392876_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:34:10,349 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:34:10,349 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1619392876_0001_r_000000_0' done.
   [druid] 2018-12-06 14:34:10,360 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:34:11,288 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:34:11,288 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1619392876_0001
   [druid] 2018-12-06 14:34:11,330 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:34:11,330 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:34:11,330 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=440358
   [druid] 2018-12-06 14:34:11,330 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1249518
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:34:11,331 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:34:11,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:34:11,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:34:11,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 14:34:11,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-06 14:34:11,332 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=433722
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-06 14:34:11,333 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-06 14:34:11,334 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=387973120
   [druid] 2018-12-06 14:34:30,651 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:34:30,652 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:34:30,674 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:34:30,718 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:34:30,863 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:34:31,183 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:34:31,184 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2025250822_0001
   [druid] 2018-12-06 14:34:31,188 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:34:31,200 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:34:31,201 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2025250822_0001_m_000000_0
   [druid] 2018-12-06 14:34:31,220 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:34:31,242 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:34:31,252 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 14:34:31,264 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:34:31,266 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:34:31,295 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:34:31,295 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:34:31,683 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,684 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:34:31,809 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:31,812 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:34:31,893 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:34:31,905 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2025250822_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:34:31,921 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:31,921 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2025250822_0001_m_000000_0' done.
   [druid] 2018-12-06 14:34:31,921 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2025250822_0001_m_000000_0
   [druid] 2018-12-06 14:34:31,922 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:34:31,925 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:34:31,940 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:34:31,940 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:31,946 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:34:31,952 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 14:34:31,953 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:34:32,187 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:34:32,952 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2025250822_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:34:32,953 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:34:32,953 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2025250822_0001_r_000000_0' done.
   [druid] 2018-12-06 14:34:32,956 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:34:33,190 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:34:33,190 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2025250822_0001
   [druid] 2018-12-06 14:34:33,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:34:33,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:34:33,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774216
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:34:33,202 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:34:33,203 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 14:34:33,204 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:34:33,204 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 14:34:33,204 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 14:34:33,204 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 14:34:33,205 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=566231040
   [druid] 2018-12-06 14:57:04,328 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:57:04,330 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:57:04,354 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:57:04,395 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:57:04,462 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:57:04,929 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1591573903_0001
   [druid] 2018-12-06 14:57:04,931 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:57:04,938 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:57:04,951 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:57:04,952 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1591573903_0001_m_000000_0
   [druid] 2018-12-06 14:57:04,976 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:57:05,000 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:57:05,007 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 14:57:05,014 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:57:05,016 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:57:05,049 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:57:05,050 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:57:05,448 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,449 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,449 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,449 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,449 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,450 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,450 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,450 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:05,633 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:05,636 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:57:05,726 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:57:05,735 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1591573903_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:57:05,748 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:05,748 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1591573903_0001_m_000000_0' done.
   [druid] 2018-12-06 14:57:05,748 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1591573903_0001_m_000000_0
   [druid] 2018-12-06 14:57:05,748 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:57:05,758 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:57:05,772 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:57:05,772 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:05,779 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:57:05,784 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 440048 bytes
   [druid] 2018-12-06 14:57:05,784 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:05,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:57:06,486 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1591573903_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:57:06,487 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:57:06,487 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1591573903_0001_r_000000_0' done.
   [druid] 2018-12-06 14:57:06,490 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:57:06,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:57:06,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1591573903_0001
   [druid] 2018-12-06 14:57:06,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:57:06,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:57:06,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=440358
   [druid] 2018-12-06 14:57:06,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=1249518
   [druid] 2018-12-06 14:57:06,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:57:06,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:57:06,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:57:06,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-06 14:57:06,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 14:57:06,960 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=3162
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=433722
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=25
   [druid] 2018-12-06 14:57:06,961 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:57:06,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=3162
   [druid] 2018-12-06 14:57:06,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=25
   [druid] 2018-12-06 14:57:06,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=6324
   [druid] 2018-12-06 14:57:06,962 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=565182464
   [druid] 2018-12-06 14:57:34,234 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:57:34,235 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:57:34,258 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:57:34,303 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:57:34,402 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:57:34,754 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local759892512_0001
   [druid] 2018-12-06 14:57:34,758 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:57:34,764 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:57:34,777 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:57:34,778 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local759892512_0001_m_000000_0
   [druid] 2018-12-06 14:57:34,803 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:57:34,827 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:57:34,836 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 14:57:34,846 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:57:34,848 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:57:34,884 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:57:34,884 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:57:35,263 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,263 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,263 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,263 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,263 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,264 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,264 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,264 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:57:35,405 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:35,409 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:57:35,550 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:57:35,559 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local759892512_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:57:35,574 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:35,575 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local759892512_0001_m_000000_0' done.
   [druid] 2018-12-06 14:57:35,575 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local759892512_0001_m_000000_0
   [druid] 2018-12-06 14:57:35,575 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:57:35,578 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:57:35,590 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:57:35,590 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:35,596 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:57:35,601 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 14:57:35,602 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:57:35,758 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:57:36,214 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local759892512_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:57:36,215 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:57:36,215 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local759892512_0001_r_000000_0' done.
   [druid] 2018-12-06 14:57:36,218 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:57:36,759 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:57:36,759 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local759892512_0001
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774208
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:57:36,771 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:57:36,774 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:57:36,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 14:57:36,776 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 14:57:36,777 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=418381824
   [druid] 2018-12-06 14:59:11,043 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:59:11,045 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:59:11,078 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:59:11,117 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:59:11,162 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:59:11,563 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:59:11,564 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local885741376_0001
   [druid] 2018-12-06 14:59:11,575 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:59:11,592 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:59:11,593 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local885741376_0001_m_000000_0
   [druid] 2018-12-06 14:59:11,622 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:59:11,650 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:59:11,665 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 14:59:11,680 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:59:11,684 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:59:11,720 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:59:11,720 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:59:12,286 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,286 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,287 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,287 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,288 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,288 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,288 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,288 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:12,421 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:12,427 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:59:12,494 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:59:12,504 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local885741376_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:59:12,522 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:12,522 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local885741376_0001_m_000000_0' done.
   [druid] 2018-12-06 14:59:12,523 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local885741376_0001_m_000000_0
   [druid] 2018-12-06 14:59:12,525 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:59:12,531 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:59:12,553 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:59:12,554 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:12,562 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:59:12,575 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 14:59:12,575 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:12,578 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:59:13,287 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local885741376_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:59:13,288 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:59:13,288 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local885741376_0001_r_000000_0' done.
   [druid] 2018-12-06 14:59:13,291 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:59:13,582 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:59:13,583 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local885741376_0001
   [druid] 2018-12-06 14:59:13,596 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774208
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:59:13,597 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 14:59:13,598 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 14:59:13,599 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=415236096
   [druid] 2018-12-06 14:59:33,709 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 14:59:33,711 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 14:59:33,742 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 14:59:33,782 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 14:59:33,852 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 14:59:34,298 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local778289004_0001
   [druid] 2018-12-06 14:59:34,302 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 14:59:34,312 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 14:59:34,325 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 14:59:34,327 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local778289004_0001_m_000000_0
   [druid] 2018-12-06 14:59:34,356 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:59:34,382 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:59:34,393 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 14:59:34,406 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 14:59:34,409 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 14:59:34,438 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 14:59:34,438 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,878 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,879 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:34,879 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 14:59:35,011 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:35,014 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 14:59:35,082 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 14:59:35,095 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local778289004_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:59:35,113 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:35,114 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local778289004_0001_m_000000_0' done.
   [druid] 2018-12-06 14:59:35,114 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local778289004_0001_m_000000_0
   [druid] 2018-12-06 14:59:35,116 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 14:59:35,122 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 14:59:35,136 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 14:59:35,137 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:35,146 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 14:59:35,156 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 14:59:35,156 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 14:59:35,303 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 14:59:35,883 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local778289004_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 14:59:35,883 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 14:59:35,884 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local778289004_0001_r_000000_0' done.
   [druid] 2018-12-06 14:59:35,887 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 14:59:36,304 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 14:59:36,304 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local778289004_0001
   [druid] 2018-12-06 14:59:36,322 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 14:59:36,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 14:59:36,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 14:59:36,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774208
   [druid] 2018-12-06 14:59:36,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 14:59:36,324 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 14:59:36,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 14:59:36,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 14:59:36,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 14:59:36,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 14:59:36,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 14:59:36,326 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 14:59:36,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 14:59:36,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=566231040
   [druid] 2018-12-06 15:00:10,978 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:00:10,980 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:00:11,011 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:00:11,059 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:00:11,104 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:00:11,474 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2103497821_0001
   [druid] 2018-12-06 15:00:11,477 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:00:11,486 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:00:11,497 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:00:11,498 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2103497821_0001_m_000000_0
   [druid] 2018-12-06 15:00:11,521 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:00:11,543 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:00:11,557 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:00:11,571 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:00:11,575 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:00:11,608 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:00:11,608 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:00:12,007 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,008 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,008 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,008 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,008 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,009 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,009 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,009 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:00:12,280 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:00:12,290 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:00:12,378 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:00:12,386 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2103497821_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:00:12,409 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:00:12,409 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2103497821_0001_m_000000_0' done.
   [druid] 2018-12-06 15:00:12,409 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2103497821_0001_m_000000_0
   [druid] 2018-12-06 15:00:12,411 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:00:12,418 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:00:12,434 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:00:12,435 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:00:12,443 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:00:12,452 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 15:00:12,452 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:00:12,480 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:00:13,101 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2103497821_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:00:13,102 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:00:13,102 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2103497821_0001_r_000000_0' done.
   [druid] 2018-12-06 15:00:13,105 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:00:13,482 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:00:13,483 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2103497821_0001
   [druid] 2018-12-06 15:00:13,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:00:13,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:00:13,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774216
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 15:00:13,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:00:13,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 15:00:13,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=482869248
   [druid] 2018-12-06 15:01:18,994 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:01:18,996 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:01:19,040 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:01:19,101 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:01:19,144 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:01:19,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1379178152_0001
   [druid] 2018-12-06 15:01:19,626 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:01:19,639 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:01:19,656 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:01:19,666 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1379178152_0001_m_000000_0
   [druid] 2018-12-06 15:01:19,700 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:01:19,751 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:01:19,766 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:01:19,818 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:01:19,824 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:01:19,874 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:01:19,875 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:01:20,441 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,442 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,442 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,442 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,442 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,443 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,443 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,443 [pool-4-thread-1] INFO  nalysis.mr.au.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-06 15:01:20,607 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:01:20,611 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:01:20,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 15:01:20,695 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:01:20,706 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1379178152_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:01:20,724 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:01:20,724 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1379178152_0001_m_000000_0' done.
   [druid] 2018-12-06 15:01:20,724 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1379178152_0001_m_000000_0
   [druid] 2018-12-06 15:01:20,727 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:01:20,734 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:01:20,753 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:01:20,760 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:01:20,768 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:01:20,790 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 202397 bytes
   [druid] 2018-12-06 15:01:20,790 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:01:21,641 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:01:22,003 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1379178152_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:01:22,004 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:01:22,005 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1379178152_0001_r_000000_0' done.
   [druid] 2018-12-06 15:01:22,008 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:01:22,643 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:01:22,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1379178152_0001
   [druid] 2018-12-06 15:01:22,667 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=202707
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=774216
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:01:22,668 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 15:01:22,669 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1478
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=199439
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=17
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1478
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=17
   [druid] 2018-12-06 15:01:22,670 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=2956
   [druid] 2018-12-06 15:01:22,671 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=573571072
   [druid] 2018-12-06 15:18:10,746 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:18:10,748 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:18:10,784 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:18:10,820 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:18:10,864 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:18:11,267 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1026126722_0001
   [druid] 2018-12-06 15:18:11,269 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:18:11,278 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:18:11,295 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:18:11,296 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1026126722_0001_m_000000_0
   [druid] 2018-12-06 15:18:11,328 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:18:11,359 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:18:11,372 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 15:18:11,388 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:18:11,392 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:18:11,458 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:18:11,459 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:18:11,894 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,894 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,894 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,895 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,895 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,895 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,895 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:11,895 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:18:12,150 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:18:12,155 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:18:12,232 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:18:12,242 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1026126722_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:18:12,261 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:18:12,261 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1026126722_0001_m_000000_0' done.
   [druid] 2018-12-06 15:18:12,261 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1026126722_0001_m_000000_0
   [druid] 2018-12-06 15:18:12,261 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:18:12,267 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:18:12,271 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:18:12,283 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:18:12,284 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:18:12,291 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:18:12,301 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 276735 bytes
   [druid] 2018-12-06 15:18:12,301 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:18:12,756 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:18:12,757 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1026126722_0001
   java.lang.ClassCastException: com.qianfeng.analysis.model.key.StatsUserLcDimension cannot be cast to com.qianfeng.analysis.model.key.StatsUserDimension
	at com.qianfeng.analysis.mr.local.LocalReduce.reduce(LocalReduce.java:17)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:164)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:610)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:444)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:449)
[druid] 2018-12-06 15:18:13,273 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1026126722_0001
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=153
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=461452
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:18:13,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=800726
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=5
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:18:13,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=273571
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=1
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1
   [druid] 2018-12-06 15:18:13,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 15:18:13,315 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1581
   [druid] 2018-12-06 15:18:13,315 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=273154048
   [druid] 2018-12-06 15:21:40,461 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:21:40,463 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:21:40,486 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:21:40,529 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:21:40,612 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:21:40,966 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1276158740_0001
   [druid] 2018-12-06 15:21:40,971 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:21:40,977 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:21:40,991 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:21:40,994 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1276158740_0001_m_000000_0
   [druid] 2018-12-06 15:21:41,021 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:21:41,046 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:21:41,056 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 15:21:41,069 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:21:41,073 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:21:41,143 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:21:41,143 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:21:41,555 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,555 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,556 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:21:41,785 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:21:41,790 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:21:41,862 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:21:41,868 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1276158740_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:21:41,879 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:21:41,879 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1276158740_0001_m_000000_0' done.
   [druid] 2018-12-06 15:21:41,880 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1276158740_0001_m_000000_0
   [druid] 2018-12-06 15:21:41,880 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:21:41,883 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:21:41,896 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:21:41,896 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:21:41,903 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:21:41,911 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 276735 bytes
   [druid] 2018-12-06 15:21:41,912 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:21:41,985 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:21:42,707 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1276158740_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:21:42,710 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:21:42,710 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1276158740_0001_r_000000_0' done.
   [druid] 2018-12-06 15:21:42,712 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:21:42,988 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:21:42,988 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1276158740_0001
   [druid] 2018-12-06 15:21:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:21:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:21:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=277045
   [druid] 2018-12-06 15:21:42,997 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=922904
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:21:42,998 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=273571
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:21:42,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=16
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1581
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=16
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3162
   [druid] 2018-12-06 15:21:43,000 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-06 15:25:32,567 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:25:32,569 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:25:32,597 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:25:32,634 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:25:32,700 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:25:33,044 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:25:33,044 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local188442435_0001
   [druid] 2018-12-06 15:25:33,052 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:25:33,061 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:25:33,061 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local188442435_0001_m_000000_0
   [druid] 2018-12-06 15:25:33,077 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:25:33,092 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:25:33,098 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 15:25:33,105 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:25:33,107 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:25:33,164 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:25:33,164 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:25:33,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,542 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,542 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,542 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,542 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,542 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,543 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:33,738 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:33,740 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:25:33,862 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:25:33,872 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local188442435_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:25:33,880 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:33,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local188442435_0001_m_000000_0' done.
   [druid] 2018-12-06 15:25:33,880 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local188442435_0001_m_000000_0
   [druid] 2018-12-06 15:25:33,880 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:25:33,883 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:25:33,896 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:25:33,896 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:33,903 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:25:33,910 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 276735 bytes
   [druid] 2018-12-06 15:25:33,910 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:34,090 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:25:34,822 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local188442435_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:25:34,823 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:25:34,823 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local188442435_0001_r_000000_0' done.
   [druid] 2018-12-06 15:25:34,825 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:25:35,091 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:25:35,092 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local188442435_0001
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=277045
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=922896
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:25:35,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-06 15:25:35,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:25:35,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:25:35,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:25:35,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1581
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=273571
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:25:35,124 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=16
   [druid] 2018-12-06 15:25:35,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:25:35,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1581
   [druid] 2018-12-06 15:25:35,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=16
   [druid] 2018-12-06 15:25:35,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3162
   [druid] 2018-12-06 15:25:35,125 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=423624704
   [druid] 2018-12-06 15:25:50,903 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:25:50,904 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:25:50,925 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:25:50,959 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:25:51,035 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:25:51,339 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:25:51,340 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local753199043_0001
   [druid] 2018-12-06 15:25:51,348 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:25:51,359 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:25:51,360 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local753199043_0001_m_000000_0
   [druid] 2018-12-06 15:25:51,381 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:25:51,401 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:25:51,409 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:25:51,419 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:25:51,424 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:25:51,468 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:25:51,468 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:25:51,852 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,852 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,853 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:25:51,980 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:51,983 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:25:52,059 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:25:52,068 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local753199043_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:25:52,078 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:52,079 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local753199043_0001_m_000000_0' done.
   [druid] 2018-12-06 15:25:52,079 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local753199043_0001_m_000000_0
   [druid] 2018-12-06 15:25:52,079 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:25:52,083 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:25:52,105 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:25:52,106 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:52,118 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:25:52,127 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 129277 bytes
   [druid] 2018-12-06 15:25:52,128 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:25:52,363 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:25:52,917 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local753199043_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:25:52,918 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:25:52,918 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local753199043_0001_r_000000_0' done.
   [druid] 2018-12-06 15:25:52,921 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:25:53,365 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:25:53,366 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local753199043_0001
   [druid] 2018-12-06 15:25:53,393 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:25:53,394 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:25:53,394 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=129587
   [druid] 2018-12-06 15:25:53,395 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=627980
   [druid] 2018-12-06 15:25:53,395 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:25:53,395 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:25:53,395 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:25:53,395 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:25:53,396 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=739
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=127797
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:25:53,397 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=15
   [druid] 2018-12-06 15:25:53,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:25:53,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=739
   [druid] 2018-12-06 15:25:53,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=15
   [druid] 2018-12-06 15:25:53,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1478
   [druid] 2018-12-06 15:25:53,398 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-06 15:32:54,412 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:32:54,414 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:32:54,542 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:32:54,578 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:32:54,708 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:32:55,075 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:32:55,076 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local756760374_0001
   [druid] 2018-12-06 15:32:55,080 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:32:55,091 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:32:55,091 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local756760374_0001_m_000000_0
   [druid] 2018-12-06 15:32:55,109 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:32:55,129 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:32:55,137 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:32:55,145 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:32:55,147 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:32:55,181 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:32:55,181 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:32:55,568 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,568 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,568 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,569 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,569 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,569 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,569 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,569 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:32:55,694 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:32:55,698 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:32:55,764 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:32:55,791 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local756760374_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:32:55,821 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:32:55,821 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local756760374_0001_m_000000_0' done.
   [druid] 2018-12-06 15:32:55,821 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local756760374_0001_m_000000_0
   [druid] 2018-12-06 15:32:55,821 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:32:55,827 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:32:55,847 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:32:55,847 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:32:55,857 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:32:55,866 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 129277 bytes
   [druid] 2018-12-06 15:32:55,867 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:32:56,115 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:32:56,657 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local756760374_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:32:56,657 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:32:56,658 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local756760374_0001_r_000000_0' done.
   [druid] 2018-12-06 15:32:56,660 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:32:57,118 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:32:57,118 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local756760374_0001
   [druid] 2018-12-06 15:32:57,142 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:32:57,142 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:32:57,142 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=129587
   [druid] 2018-12-06 15:32:57,142 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=627980
   [druid] 2018-12-06 15:32:57,142 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:32:57,143 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:32:57,143 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:32:57,143 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=739
   [druid] 2018-12-06 15:32:57,144 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=127797
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=15
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=739
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=15
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1478
   [druid] 2018-12-06 15:32:57,145 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-06 15:35:04,527 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:35:04,529 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:35:04,595 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:35:04,629 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:35:04,738 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:35:05,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local360387319_0001
   [druid] 2018-12-06 15:35:05,031 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:35:05,037 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:35:05,048 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:35:05,049 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local360387319_0001_m_000000_0
   [druid] 2018-12-06 15:35:05,071 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:35:05,089 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:35:05,096 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:35:05,103 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:35:05,105 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:35:05,136 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:35:05,136 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:35:05,540 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,540 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,541 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:35:05,754 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:35:05,757 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:35:05,838 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:35:05,848 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local360387319_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:35:05,862 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:35:05,862 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local360387319_0001_m_000000_0' done.
   [druid] 2018-12-06 15:35:05,863 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local360387319_0001_m_000000_0
   [druid] 2018-12-06 15:35:05,863 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:35:05,871 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:35:05,891 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:35:05,893 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:35:05,902 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 15:35:05,911 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 129277 bytes
   [druid] 2018-12-06 15:35:05,911 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:35:06,075 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 15:35:06,635 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local360387319_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:35:06,636 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 15:35:06,636 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local360387319_0001_r_000000_0' done.
   [druid] 2018-12-06 15:35:06,641 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 15:35:07,076 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 15:35:07,076 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local360387319_0001
   [druid] 2018-12-06 15:35:07,098 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 15:35:07,098 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 15:35:07,098 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=129587
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=627980
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 15:35:07,099 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=739
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=127797
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=15
   [druid] 2018-12-06 15:35:07,100 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 15:35:07,101 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=739
   [druid] 2018-12-06 15:35:07,101 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=15
   [druid] 2018-12-06 15:35:07,101 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1478
   [druid] 2018-12-06 15:35:07,101 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=568328192
   [druid] 2018-12-06 15:52:20,995 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 15:52:21,000 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 15:52:21,034 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 15:52:21,087 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 15:52:21,143 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 15:52:21,542 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 15:52:21,543 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1990987671_0001
   [druid] 2018-12-06 15:52:21,556 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 15:52:21,571 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 15:52:21,574 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1990987671_0001_m_000000_0
   [druid] 2018-12-06 15:52:21,610 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:52:21,639 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:52:22,031 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 15:52:22,046 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 15:52:22,049 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 15:52:22,084 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 15:52:22,084 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 15:52:24,141 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 15:54:03,407 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:56:31,512 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:56:31,514 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:56:39,244 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:58:17,447 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,448 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,448 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,449 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,450 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,450 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 15:58:17,599 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:58:17,613 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 15:58:17,679 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 15:58:17,691 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1990987671_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 15:58:17,692 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:58:17,693 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1990987671_0001_m_000000_0' done.
   [druid] 2018-12-06 15:58:17,693 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1990987671_0001_m_000000_0
   [druid] 2018-12-06 15:58:17,693 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 15:58:17,698 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 15:58:17,717 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 15:58:17,717 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 15:58:17,725 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:05:19,949 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:05:19,952 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:05:19,978 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:05:20,023 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:05:20,135 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:05:20,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1538859721_0001
   [druid] 2018-12-06 16:05:20,500 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:05:20,507 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:05:20,518 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:05:20,519 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1538859721_0001_m_000000_0
   [druid] 2018-12-06 16:05:20,540 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:05:20,559 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:05:20,569 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 16:05:20,578 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:05:20,581 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:05:20,630 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:05:20,630 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:05:21,034 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,035 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,035 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,035 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,035 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,038 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,038 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,038 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,038 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,039 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,039 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,039 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,039 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,040 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,040 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,040 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,040 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,040 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,041 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,041 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,041 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,041 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,041 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,044 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,045 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,045 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,045 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,045 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,046 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,046 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,046 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,046 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,047 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,047 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,047 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,047 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,047 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,048 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:05:21,166 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:05:21,169 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:05:21,230 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:05:21,239 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1538859721_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:05:21,252 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:05:21,253 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1538859721_0001_m_000000_0' done.
   [druid] 2018-12-06 16:05:21,253 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1538859721_0001_m_000000_0
   [druid] 2018-12-06 16:05:21,253 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:05:21,256 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:05:21,273 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:05:21,274 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:05:21,282 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:05:21,290 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 124666 bytes
   [druid] 2018-12-06 16:05:21,290 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:05:21,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:05:21,990 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1538859721_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:05:21,990 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:05:21,991 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1538859721_0001_r_000000_0' done.
   [druid] 2018-12-06 16:05:21,993 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:05:22,508 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:05:22,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1538859721_0001
   [druid] 2018-12-06 16:05:22,539 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:05:22,540 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:05:22,540 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=124976
   [druid] 2018-12-06 16:05:22,540 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=618766
   [druid] 2018-12-06 16:05:22,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:05:22,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:05:22,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:05:22,541 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 16:05:22,542 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:05:22,542 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:05:22,542 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:05:22,545 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:05:22,545 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:05:22,545 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 16:05:22,545 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=700
   [druid] 2018-12-06 16:05:22,545 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=123264
   [druid] 2018-12-06 16:05:22,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 16:05:22,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:05:22,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:05:22,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=13
   [druid] 2018-12-06 16:05:22,546 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:05:22,547 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=700
   [druid] 2018-12-06 16:05:22,547 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=13
   [druid] 2018-12-06 16:05:22,547 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1400
   [druid] 2018-12-06 16:05:22,548 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=484966400
   [druid] 2018-12-06 16:10:27,480 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:10:27,482 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:10:27,501 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:10:27,537 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:10:27,603 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:10:27,890 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local911736799_0001
   [druid] 2018-12-06 16:10:27,892 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:10:27,898 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:10:27,909 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:10:27,910 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local911736799_0001_m_000000_0
   [druid] 2018-12-06 16:10:27,935 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:10:27,951 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:10:27,958 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/1.log:0+800726
   [druid] 2018-12-06 16:10:27,967 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:10:27,971 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:10:28,035 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:10:28,036 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:10:28,420 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,420 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,420 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,420 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,420 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,421 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,422 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,423 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,423 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,423 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,423 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,423 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,424 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,425 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,426 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,427 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,427 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:28,615 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:28,618 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:10:28,688 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:10:28,700 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local911736799_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:10:28,721 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:28,722 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local911736799_0001_m_000000_0' done.
   [druid] 2018-12-06 16:10:28,722 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local911736799_0001_m_000000_0
   [druid] 2018-12-06 16:10:28,722 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:10:28,727 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:10:28,768 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:10:28,768 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:28,774 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:10:28,781 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 272124 bytes
   [druid] 2018-12-06 16:10:28,781 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:28,903 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:10:29,758 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local911736799_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:10:29,759 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:10:29,759 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local911736799_0001_r_000000_0' done.
   [druid] 2018-12-06 16:10:29,762 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:10:29,905 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:10:29,906 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local911736799_0001
   [druid] 2018-12-06 16:10:29,931 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=272434
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=913674
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:10:29,932 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=1601452
   [druid] 2018-12-06 16:10:29,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:10:29,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:10:29,933 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=1589
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=1542
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=269038
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:10:29,934 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=14
   [druid] 2018-12-06 16:10:29,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:10:29,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=1542
   [druid] 2018-12-06 16:10:29,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=14
   [druid] 2018-12-06 16:10:29,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=3084
   [druid] 2018-12-06 16:10:29,935 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486014976
   [druid] 2018-12-06 16:10:57,249 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:10:57,251 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:10:57,284 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:10:57,330 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:10:57,450 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:10:57,760 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:10:57,766 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:10:57,767 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local774105580_0001
   [druid] 2018-12-06 16:10:57,778 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:10:57,779 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local774105580_0001_m_000000_0
   [druid] 2018-12-06 16:10:57,802 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:10:57,823 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:10:57,830 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 16:10:57,839 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:10:57,842 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:10:57,891 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:10:57,892 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:10:58,281 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,281 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,281 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,281 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,282 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,282 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,282 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,282 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,282 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,283 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,284 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,284 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,284 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,284 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,285 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,285 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,285 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,285 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,285 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,286 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,286 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,286 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,286 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,286 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,287 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,287 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,287 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,287 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,288 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,288 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,288 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,288 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,288 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,289 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,289 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,289 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,289 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,289 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,290 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,290 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,290 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,290 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:10:58,398 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:58,402 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:10:58,445 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:10:58,455 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774105580_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:10:58,465 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:58,466 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774105580_0001_m_000000_0' done.
   [druid] 2018-12-06 16:10:58,466 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local774105580_0001_m_000000_0
   [druid] 2018-12-06 16:10:58,466 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:10:58,470 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:10:58,488 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:10:58,488 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:58,496 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:10:58,506 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 124666 bytes
   [druid] 2018-12-06 16:10:58,506 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:10:58,775 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:10:59,198 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local774105580_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:10:59,199 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:10:59,199 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local774105580_0001_r_000000_0' done.
   [druid] 2018-12-06 16:10:59,201 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:10:59,777 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:10:59,780 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local774105580_0001
   [druid] 2018-12-06 16:10:59,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:10:59,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:10:59,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=124976
   [druid] 2018-12-06 16:10:59,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=618758
   [druid] 2018-12-06 16:10:59,790 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:10:59,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:10:59,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:10:59,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 16:10:59,791 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=700
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=123264
   [druid] 2018-12-06 16:10:59,792 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=13
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=700
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=13
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1400
   [druid] 2018-12-06 16:10:59,793 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=566231040
   [druid] 2018-12-06 16:27:41,469 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:27:41,471 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:27:41,523 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:27:41,584 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:27:41,641 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:27:42,016 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1988762157_0001
   [druid] 2018-12-06 16:27:42,019 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:27:42,027 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:27:42,045 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:27:42,046 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1988762157_0001_m_000000_0
   [druid] 2018-12-06 16:27:42,070 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:27:42,095 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:27:42,139 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 16:27:42,156 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:27:42,160 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:27:42,221 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:27:42,222 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:27:43,195 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 16:27:54,238 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:00,327 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:00,556 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:02,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:03,888 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:05,010 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:06,892 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:06,893 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:10,694 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:10,694 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:12,450 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:16,201 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:19,165 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:19,379 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:21,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:21,323 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 1% reduce 0%
   [druid] 2018-12-06 16:28:29,109 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:29,109 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:31,573 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:34,910 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:35,442 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:36,257 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:37,256 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:38,386 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:38,386 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:39,378 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:40,521 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:41,290 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:41,495 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:28:42,206 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:43,610 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:53,992 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:28:53,992 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:00,387 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:00,387 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:01,945 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:02,730 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:03,425 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:03,642 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:04,842 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:04,843 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 2% reduce 0%
   [druid] 2018-12-06 16:29:05,748 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:06,721 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:06,721 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:07,664 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:08,793 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:10,159 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:10,160 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:11,263 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:14,630 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:14,630 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:29:15,743 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:16,674 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:17,697 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:29:17,698 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:30:50,481 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:30:50,482 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:30:50,508 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:30:50,549 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:30:50,648 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:30:51,078 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:30:51,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1521713687_0001
   [druid] 2018-12-06 16:30:51,090 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:30:51,107 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:30:51,108 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1521713687_0001_m_000000_0
   [druid] 2018-12-06 16:30:51,132 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:30:51,158 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:30:51,167 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 16:30:51,179 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:30:51,184 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:30:51,234 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:30:51,234 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:30:51,695 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,695 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,697 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,697 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,698 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,698 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,698 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,698 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,699 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,700 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,701 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,701 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,701 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,701 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,701 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,702 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,703 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,703 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,703 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,703 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,703 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,704 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,704 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,704 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,705 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,705 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,705 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,705 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,706 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,706 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,706 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,706 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,706 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:30:51,829 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:30:51,832 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:30:51,882 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:30:51,892 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1521713687_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:30:51,906 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:30:51,906 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1521713687_0001_m_000000_0' done.
   [druid] 2018-12-06 16:30:51,906 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1521713687_0001_m_000000_0
   [druid] 2018-12-06 16:30:51,907 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:30:51,912 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:30:51,929 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:30:51,930 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:30:51,938 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:30:51,945 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 124666 bytes
   [druid] 2018-12-06 16:30:51,945 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:30:52,084 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:30:52,680 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1521713687_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:30:52,682 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:30:52,682 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1521713687_0001_r_000000_0' done.
   [druid] 2018-12-06 16:30:52,685 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:30:53,086 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:30:53,086 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1521713687_0001
   [druid] 2018-12-06 16:30:53,109 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:30:53,109 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:30:53,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=124976
   [druid] 2018-12-06 16:30:53,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=618766
   [druid] 2018-12-06 16:30:53,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:30:53,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:30:53,110 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:30:53,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=764466
   [druid] 2018-12-06 16:30:53,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:30:53,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:30:53,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:30:53,118 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:30:53,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:30:53,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=747
   [druid] 2018-12-06 16:30:53,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=700
   [druid] 2018-12-06 16:30:53,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=123264
   [druid] 2018-12-06 16:30:53,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=99
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=13
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=700
   [druid] 2018-12-06 16:30:53,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=13
   [druid] 2018-12-06 16:30:53,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=1400
   [druid] 2018-12-06 16:30:53,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-06 16:32:11,363 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,364 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:32:11,407 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,408 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,408 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,408 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,408 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,408 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,409 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,409 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:11,409 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:32:17,372 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:32:17,375 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:32:17,415 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:32:17,467 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:32:17,515 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:32:18,079 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:32:18,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2074726349_0001
   [druid] 2018-12-06 16:32:18,087 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:32:18,101 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:32:18,102 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2074726349_0001_m_000000_0
   [druid] 2018-12-06 16:32:18,131 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:32:18,158 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:32:18,196 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/2.log:0+382233
   [druid] 2018-12-06 16:32:18,210 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:32:18,213 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:32:18,243 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:32:18,243 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:32:19,237 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 16:37:11,314 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,315 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,315 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,316 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,316 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,316 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,317 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,317 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,317 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,318 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,318 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,318 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,318 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,319 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,319 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,319 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,320 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,320 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,321 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,322 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,323 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,324 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:37:11,490 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:37:11,495 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:43:53,005 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:43:53,007 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:43:53,035 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:43:53,074 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:43:53,152 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:43:53,466 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1880609544_0001
   [druid] 2018-12-06 16:43:53,469 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:43:53,478 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:43:53,491 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:43:53,492 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1880609544_0001_m_000000_0
   [druid] 2018-12-06 16:43:53,516 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:43:53,539 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:43:53,549 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 16:43:53,562 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:43:53,565 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:43:53,620 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:43:53,621 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:43:54,028 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:43:54,029 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:43:54,030 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1880609544_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 13
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 13
	at com.qianfeng.analysis.mr.local.LocalMapper.map(LocalMapper.java:36)
	at com.qianfeng.analysis.mr.local.LocalMapper.map(LocalMapper.java:21)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-06 16:43:54,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 16:43:54,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1880609544_0001
   [druid] 2018-12-06 16:43:54,476 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-06 16:45:41,921 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:45:41,923 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:45:41,951 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:45:42,004 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:45:42,132 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:45:42,795 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local67164537_0001
   [druid] 2018-12-06 16:45:42,799 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:45:42,805 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:45:42,818 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:45:42,819 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local67164537_0001_m_000000_0
   [druid] 2018-12-06 16:45:42,846 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:45:42,872 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:45:42,882 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 16:45:42,901 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:45:42,904 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:45:42,946 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:45:42,946 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:45:43,393 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:45:43,393 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:45:43,393 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:45:43,420 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:45:43,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:45:43,450 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:45:43,455 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local67164537_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:45:43,465 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:45:43,465 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local67164537_0001_m_000000_0' done.
   [druid] 2018-12-06 16:45:43,465 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local67164537_0001_m_000000_0
   [druid] 2018-12-06 16:45:43,465 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:45:43,468 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:45:43,483 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:45:43,483 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:45:43,490 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:45:43,495 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 13929 bytes
   [druid] 2018-12-06 16:45:43,496 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:45:43,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:45:44,267 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local67164537_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:45:44,268 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:45:44,268 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local67164537_0001_r_000000_0' done.
   [druid] 2018-12-06 16:45:44,271 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:45:44,800 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:45:44,801 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local67164537_0001
   [druid] 2018-12-06 16:45:44,812 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:45:44,812 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:45:44,812 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=14251
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=397288
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 16:45:44,813 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=79
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=13769
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:45:44,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=79
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=158
   [druid] 2018-12-06 16:45:44,815 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=429916160
   [druid] 2018-12-06 16:46:03,783 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:46:03,785 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:46:03,822 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:46:03,861 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:46:03,941 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:46:04,246 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:46:04,248 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1363761145_0001
   [druid] 2018-12-06 16:46:04,255 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:46:04,264 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:46:04,265 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1363761145_0001_m_000000_0
   [druid] 2018-12-06 16:46:04,287 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:46:04,308 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:46:04,316 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:46:04,325 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:46:04,327 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:46:04,367 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:46:04,367 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:46:04,773 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:46:04,774 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:46:04,774 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:46:04,796 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:46:04,800 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:46:04,877 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:46:04,884 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1363761145_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:46:04,903 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:46:04,903 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1363761145_0001_m_000000_0' done.
   [druid] 2018-12-06 16:46:04,903 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1363761145_0001_m_000000_0
   [druid] 2018-12-06 16:46:04,904 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:46:04,907 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:46:04,944 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:46:04,948 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:46:04,956 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:46:04,965 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:46:04,965 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:46:05,252 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:46:05,769 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1363761145_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:46:05,770 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:46:05,770 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1363761145_0001_r_000000_0' done.
   [druid] 2018-12-06 16:46:05,773 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:46:06,253 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:46:06,253 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1363761145_0001
   [druid] 2018-12-06 16:46:06,266 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:46:06,266 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:46:06,266 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=7778
   [druid] 2018-12-06 16:46:06,266 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=384356
   [druid] 2018-12-06 16:46:06,267 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:46:06,267 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:46:06,267 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:46:06,267 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=42
   [druid] 2018-12-06 16:46:06,268 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=7368
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=42
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=84
   [druid] 2018-12-06 16:46:06,269 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=428867584
   [druid] 2018-12-06 16:49:13,903 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:49:13,905 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:49:13,936 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:49:13,978 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:49:14,022 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:49:14,422 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1109903258_0001
   [druid] 2018-12-06 16:49:14,425 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:49:14,435 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:49:14,452 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:49:14,454 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1109903258_0001_m_000000_0
   [druid] 2018-12-06 16:49:14,485 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:49:14,518 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:49:14,553 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:49:14,568 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:49:14,572 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:49:14,605 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:49:14,606 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:49:15,036 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:49:15,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:49:15,037 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:49:15,676 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 16:49:43,393 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:49:43,415 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:49:43,421 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:49:43,482 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:49:43,494 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1109903258_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:49:43,498 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:49:43,498 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1109903258_0001_m_000000_0' done.
   [druid] 2018-12-06 16:49:43,498 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1109903258_0001_m_000000_0
   [druid] 2018-12-06 16:49:43,499 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:49:43,506 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:49:43,530 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:49:43,538 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:49:43,548 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:49:43,563 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:49:43,564 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:49:44,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:50:29,621 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:50:38,262 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:50:38,265 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:50:38,296 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:50:38,342 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:50:38,400 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:50:38,796 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:50:38,797 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2016544493_0001
   [druid] 2018-12-06 16:50:38,807 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:50:38,822 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:50:38,823 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2016544493_0001_m_000000_0
   [druid] 2018-12-06 16:50:38,849 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:50:38,876 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:50:38,889 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:50:38,905 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:50:38,908 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:50:38,940 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:50:38,940 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:50:39,616 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:50:39,616 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:50:39,616 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:50:39,654 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:50:39,659 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:50:39,699 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:50:39,714 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2016544493_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:50:39,730 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:50:39,730 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2016544493_0001_m_000000_0' done.
   [druid] 2018-12-06 16:50:39,730 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2016544493_0001_m_000000_0
   [druid] 2018-12-06 16:50:39,731 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:50:39,739 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:50:39,772 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:50:39,775 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:50:39,785 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:50:39,797 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:50:39,798 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:50:39,821 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:51:14,205 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:51:19,693 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 85%
   [druid] 2018-12-06 16:51:30,109 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:51:30,112 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:51:30,154 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:51:30,215 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:51:30,276 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:51:30,906 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:51:30,914 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:51:30,925 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local394723386_0001
   [druid] 2018-12-06 16:51:30,935 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:51:30,938 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local394723386_0001_m_000000_0
   [druid] 2018-12-06 16:51:30,973 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:51:31,008 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:51:31,024 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:51:31,039 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:51:31,044 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:51:31,080 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:51:31,080 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:51:31,553 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:51:31,553 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:51:31,554 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:51:31,575 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:51:31,584 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:51:31,637 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:51:31,646 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local394723386_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:51:31,661 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:51:31,661 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local394723386_0001_m_000000_0' done.
   [druid] 2018-12-06 16:51:31,661 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local394723386_0001_m_000000_0
   [druid] 2018-12-06 16:51:31,663 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:51:31,670 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:51:31,684 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:51:31,685 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:51:31,693 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:51:31,707 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:51:31,707 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:51:32,001 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:51:40,898 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:52:35,242 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 85%
   [druid] 2018-12-06 16:53:15,475 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:53:15,477 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:53:15,501 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:53:15,549 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:53:15,624 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:53:15,936 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:53:15,937 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1498132531_0001
   [druid] 2018-12-06 16:53:15,945 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:53:15,962 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:53:15,963 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1498132531_0001_m_000000_0
   [druid] 2018-12-06 16:53:15,989 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:53:16,013 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:53:16,020 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:53:16,031 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:53:16,034 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:53:16,064 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:53:16,064 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:53:16,463 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:53:16,463 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:53:16,463 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:53:16,484 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:53:16,487 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:53:16,517 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:53:16,527 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1498132531_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:53:16,539 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:53:16,539 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1498132531_0001_m_000000_0' done.
   [druid] 2018-12-06 16:53:16,540 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1498132531_0001_m_000000_0
   [druid] 2018-12-06 16:53:16,540 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:53:16,545 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:53:16,566 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:53:16,570 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:53:16,579 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:53:16,590 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:53:16,591 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:53:16,942 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:53:17,216 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1498132531_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:53:17,217 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:53:17,217 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1498132531_0001_r_000000_0' done.
   [druid] 2018-12-06 16:53:17,220 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:53:17,943 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:53:17,943 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1498132531_0001
   [druid] 2018-12-06 16:53:17,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:53:17,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:53:17,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=7778
   [druid] 2018-12-06 16:53:17,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=384356
   [druid] 2018-12-06 16:53:17,956 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:53:17,957 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=42
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=7368
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:53:17,958 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=42
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=84
   [druid] 2018-12-06 16:53:17,959 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=432013312
   [druid] 2018-12-06 16:54:47,140 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:54:47,145 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:54:47,183 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:54:47,229 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:54:47,300 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:54:47,588 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:54:47,590 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local648244851_0001
   [druid] 2018-12-06 16:54:47,597 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:54:47,610 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:54:47,611 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local648244851_0001_m_000000_0
   [druid] 2018-12-06 16:54:47,631 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:54:47,650 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:54:47,657 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:54:47,666 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:54:47,670 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:54:47,703 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:54:47,703 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:54:48,140 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:54:48,140 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:54:48,140 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:54:48,169 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:54:48,175 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:54:48,210 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:54:48,217 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local648244851_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:54:48,230 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:54:48,230 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local648244851_0001_m_000000_0' done.
   [druid] 2018-12-06 16:54:48,230 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local648244851_0001_m_000000_0
   [druid] 2018-12-06 16:54:48,230 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:54:48,236 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:54:48,251 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:54:48,252 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:54:48,258 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:54:48,266 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:54:48,267 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:54:48,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:54:48,954 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local648244851_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:54:48,955 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:54:48,955 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local648244851_0001_r_000000_0' done.
   [druid] 2018-12-06 16:54:48,958 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:54:49,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:54:49,819 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local648244851_0001
   [druid] 2018-12-06 16:54:49,835 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:54:49,835 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:54:49,835 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=7778
   [druid] 2018-12-06 16:54:49,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=384348
   [druid] 2018-12-06 16:54:49,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:54:49,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:54:49,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:54:49,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 16:54:49,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:54:49,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:54:49,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:54:49,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:54:49,837 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:54:49,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 16:54:49,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=42
   [druid] 2018-12-06 16:54:49,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=7368
   [druid] 2018-12-06 16:54:49,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 16:54:49,838 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:54:49,839 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:54:49,839 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 16:54:49,839 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:54:49,839 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=42
   [druid] 2018-12-06 16:54:49,839 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 16:54:49,840 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=84
   [druid] 2018-12-06 16:54:49,840 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-06 16:55:19,204 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 16:55:19,205 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 16:55:19,227 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 16:55:19,267 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 16:55:19,333 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 16:55:19,692 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local50765575_0001
   [druid] 2018-12-06 16:55:19,723 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 16:55:19,730 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 16:55:19,875 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 16:55:19,876 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local50765575_0001_m_000000_0
   [druid] 2018-12-06 16:55:19,899 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:55:19,915 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:55:19,921 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 16:55:19,930 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 16:55:19,933 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 16:55:19,966 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 16:55:19,966 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 16:55:20,378 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:55:20,378 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:55:20,378 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 16:55:20,401 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:55:20,404 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 16:55:20,437 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 16:55:20,442 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local50765575_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:55:20,452 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:55:20,452 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local50765575_0001_m_000000_0' done.
   [druid] 2018-12-06 16:55:20,453 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local50765575_0001_m_000000_0
   [druid] 2018-12-06 16:55:20,453 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 16:55:20,458 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 16:55:20,476 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 16:55:20,476 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:55:20,484 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 16:55:20,492 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7454 bytes
   [druid] 2018-12-06 16:55:20,492 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 16:55:20,695 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 16:55:21,178 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local50765575_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 16:55:21,181 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 16:55:21,181 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local50765575_0001_r_000000_0' done.
   [druid] 2018-12-06 16:55:21,184 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 16:55:21,696 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 16:55:21,696 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local50765575_0001
   [druid] 2018-12-06 16:55:21,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 16:55:21,714 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=7778
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=384340
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 16:55:21,715 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 16:55:21,718 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 16:55:21,718 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 16:55:21,718 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=42
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=7368
   [druid] 2018-12-06 16:55:21,721 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 16:55:21,722 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 16:55:21,722 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 16:55:21,722 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 16:55:21,722 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 16:55:21,722 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=42
   [druid] 2018-12-06 16:55:21,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 16:55:21,723 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=84
   [druid] 2018-12-06 16:55:21,724 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=472907776
   [druid] 2018-12-06 17:01:04,282 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:01:04,284 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:01:04,310 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:01:04,361 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:01:04,484 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:01:04,829 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:01:04,829 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1402273194_0001
   [druid] 2018-12-06 17:01:04,835 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:01:04,848 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:01:04,848 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1402273194_0001_m_000000_0
   [druid] 2018-12-06 17:01:04,871 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:01:04,894 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:01:04,904 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:01:04,916 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:01:04,919 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:01:04,969 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:01:04,970 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:01:05,364 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 17:01:05,365 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 17:01:05,365 [pool-4-thread-1] INFO  .analysis.mr.local.LocalMapper {1} - serverTime或者uuid或者u_sd不能为空
   [druid] 2018-12-06 17:01:05,400 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:01:05,404 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:01:05,695 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 17:01:05,702 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1402273194_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:01:05,715 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:01:05,715 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1402273194_0001_m_000000_0' done.
   [druid] 2018-12-06 17:01:05,715 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1402273194_0001_m_000000_0
   [druid] 2018-12-06 17:01:05,715 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:01:05,722 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:01:05,742 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:01:05,743 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:01:05,750 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:01:05,762 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 13929 bytes
   [druid] 2018-12-06 17:01:05,762 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:01:05,834 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 17:01:06,485 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1402273194_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:01:06,487 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:01:06,488 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1402273194_0001_r_000000_0' done.
   [druid] 2018-12-06 17:01:06,491 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:01:06,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:01:06,836 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1402273194_0001
   [druid] 2018-12-06 17:01:06,848 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:01:06,848 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:01:06,848 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=14251
   [druid] 2018-12-06 17:01:06,848 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=397304
   [druid] 2018-12-06 17:01:06,849 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:01:06,849 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:01:06,849 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:01:06,850 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:01:06,850 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:01:06,850 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:01:06,851 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:01:06,851 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:01:06,851 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:01:06,853 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=79
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=13769
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=7
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:01:06,854 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=79
   [druid] 2018-12-06 17:01:06,855 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=7
   [druid] 2018-12-06 17:01:06,855 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=158
   [druid] 2018-12-06 17:01:06,855 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=432013312
   [druid] 2018-12-06 17:44:47,011 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:44:47,013 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:44:47,045 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:44:47,098 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:44:47,191 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:44:47,618 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1601694425_0001
   [druid] 2018-12-06 17:44:47,622 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:44:47,630 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:44:47,647 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:44:47,662 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1601694425_0001_m_000000_0
   [druid] 2018-12-06 17:44:47,695 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:44:47,724 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:44:47,736 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:44:47,749 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:44:47,751 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:44:47,795 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:44:47,795 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:44:48,253 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:44:48,257 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:44:48,276 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 17:44:48,284 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1601694425_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:44:48,294 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:44:48,295 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1601694425_0001_m_000000_0' done.
   [druid] 2018-12-06 17:44:48,295 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1601694425_0001_m_000000_0
   [druid] 2018-12-06 17:44:48,295 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:44:48,299 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:44:48,318 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:44:48,319 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:44:48,327 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:44:48,335 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1571 bytes
   [druid] 2018-12-06 17:44:48,335 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:44:48,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 17:44:49,085 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1601694425_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:44:49,085 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:44:49,086 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1601694425_0001_r_000000_0' done.
   [druid] 2018-12-06 17:44:49,089 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:44:49,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:44:49,623 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1601694425_0001
   [druid] 2018-12-06 17:44:50,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:44:50,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:44:50,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1893
   [druid] 2018-12-06 17:44:50,045 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=390560
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:44:50,046 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=12
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1545
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=5
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:44:50,047 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=12
   [druid] 2018-12-06 17:44:50,048 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=5
   [druid] 2018-12-06 17:44:50,048 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=24
   [druid] 2018-12-06 17:44:50,048 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=438304768
   [druid] 2018-12-06 17:45:06,941 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:45:06,945 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:45:06,975 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:45:07,023 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:45:07,144 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:45:07,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1245771897_0001
   [druid] 2018-12-06 17:45:07,467 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:45:07,473 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:45:07,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:45:07,485 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1245771897_0001_m_000000_0
   [druid] 2018-12-06 17:45:07,508 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:45:07,527 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:45:07,533 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 17:45:07,541 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:45:07,543 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:45:07,572 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:45:07,572 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:45:08,003 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:45:08,007 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:45:08,025 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 17:45:08,031 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1245771897_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:45:08,041 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:45:08,042 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1245771897_0001_m_000000_0' done.
   [druid] 2018-12-06 17:45:08,042 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1245771897_0001_m_000000_0
   [druid] 2018-12-06 17:45:08,042 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:45:08,046 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:45:08,066 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:45:08,067 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:45:08,073 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:45:08,082 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1038 bytes
   [druid] 2018-12-06 17:45:08,082 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:45:08,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 17:45:08,749 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1245771897_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:45:08,750 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:45:08,750 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1245771897_0001_r_000000_0' done.
   [druid] 2018-12-06 17:45:08,753 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:45:09,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:45:09,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1245771897_0001
   [druid] 2018-12-06 17:45:09,491 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:45:09,491 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:45:09,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1362
   [druid] 2018-12-06 17:45:09,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389496
   [druid] 2018-12-06 17:45:09,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:45:09,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:45:09,492 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:45:09,493 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1020
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:45:09,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=3
   [druid] 2018-12-06 17:45:09,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:45:09,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 17:45:09,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=3
   [druid] 2018-12-06 17:45:09,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 17:45:09,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=568328192
   [druid] 2018-12-06 17:48:36,602 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:48:36,604 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:48:36,630 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:48:36,681 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:48:36,796 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:48:37,114 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1538675750_0001
   [druid] 2018-12-06 17:48:37,118 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:48:37,125 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:48:37,138 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:48:37,139 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1538675750_0001_m_000000_0
   [druid] 2018-12-06 17:48:37,168 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:48:37,189 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:48:37,198 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:48:37,210 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:48:37,212 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:48:37,242 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:48:37,242 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:48:38,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 17:48:39,383 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:48:39,386 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:48:39,410 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1538675750_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:48:39,419 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:48:39,419 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1538675750_0001_m_000000_0' done.
   [druid] 2018-12-06 17:48:39,419 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1538675750_0001_m_000000_0
   [druid] 2018-12-06 17:48:39,420 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:48:39,423 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:48:39,438 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:48:39,439 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:48:39,446 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:48:39,456 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 17:48:39,456 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:48:39,484 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1538675750_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:48:39,485 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:48:39,485 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1538675750_0001_r_000000_0' done.
   [druid] 2018-12-06 17:48:39,488 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:48:40,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:48:40,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1538675750_0001
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387438
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:48:40,134 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:48:40,135 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:48:40,135 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:48:40,135 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 17:48:40,137 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 17:48:40,138 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 17:48:40,141 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=543162368
   [druid] 2018-12-06 17:49:04,620 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:49:04,622 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:49:04,656 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:49:04,707 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:49:04,789 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:49:05,102 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local944465492_0001
   [druid] 2018-12-06 17:49:05,105 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:49:05,112 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:49:05,125 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:49:05,128 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local944465492_0001_m_000000_0
   [druid] 2018-12-06 17:49:05,153 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:49:05,178 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:49:05,188 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 17:49:05,200 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:49:05,205 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:49:05,242 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:49:05,243 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:49:06,105 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 17:49:06,728 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:49:06,731 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:49:06,773 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local944465492_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:49:06,782 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:49:06,783 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local944465492_0001_m_000000_0' done.
   [druid] 2018-12-06 17:49:06,783 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local944465492_0001_m_000000_0
   [druid] 2018-12-06 17:49:06,783 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:49:06,787 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:49:06,811 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:49:06,815 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:49:06,824 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:49:06,834 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 17:49:06,834 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:49:06,857 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local944465492_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:49:06,858 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:49:06,858 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local944465492_0001_r_000000_0' done.
   [druid] 2018-12-06 17:49:06,861 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:49:07,106 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:49:07,106 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local944465492_0001
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=326
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387432
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:49:07,119 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:49:07,121 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 17:49:07,122 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 17:49:07,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 17:49:07,123 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=546308096
   [druid] 2018-12-06 17:54:38,195 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:54:38,197 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:54:38,227 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:54:38,272 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:54:38,362 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:54:38,875 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:54:38,878 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local993148952_0001
   [druid] 2018-12-06 17:54:38,881 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:54:38,893 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:54:38,894 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local993148952_0001_m_000000_0
   [druid] 2018-12-06 17:54:38,929 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:54:38,946 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:54:38,954 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:54:38,965 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:54:38,968 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:54:39,000 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:54:39,001 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:54:39,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 17:54:40,933 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:54:40,936 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:54:40,959 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local993148952_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:54:40,967 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:54:40,967 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local993148952_0001_m_000000_0' done.
   [druid] 2018-12-06 17:54:40,967 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local993148952_0001_m_000000_0
   [druid] 2018-12-06 17:54:40,968 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:54:40,973 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:54:40,992 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:54:40,993 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:54:41,009 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:54:41,018 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 17:54:41,018 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:54:41,045 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local993148952_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:54:41,045 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:54:41,046 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local993148952_0001_r_000000_0' done.
   [druid] 2018-12-06 17:54:41,048 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:54:41,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:54:41,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local993148952_0001
   [druid] 2018-12-06 17:54:41,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:54:41,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:54:41,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 17:54:41,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387430
   [druid] 2018-12-06 17:54:41,896 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:54:41,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:54:41,897 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:54:41,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:54:41,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:54:41,898 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:54:41,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:54:41,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:54:41,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:54:41,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:54:41,899 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 17:54:41,900 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 17:54:41,901 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 17:54:41,901 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=541065216
   [druid] 2018-12-06 17:55:36,794 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:55:36,795 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:55:36,827 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:55:36,915 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:55:37,011 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:55:37,312 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:55:37,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1135745981_0001
   [druid] 2018-12-06 17:55:37,317 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:55:37,328 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:55:37,329 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1135745981_0001_m_000000_0
   [druid] 2018-12-06 17:55:37,354 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:55:37,376 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:55:37,383 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:55:37,395 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:55:37,403 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:55:37,441 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:55:37,441 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:55:38,322 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 17:55:39,393 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:55:39,396 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:55:39,424 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1135745981_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:55:39,436 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:55:39,436 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1135745981_0001_m_000000_0' done.
   [druid] 2018-12-06 17:55:39,437 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1135745981_0001_m_000000_0
   [druid] 2018-12-06 17:55:39,437 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:55:39,441 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:55:39,458 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:55:39,459 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:55:39,465 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:55:39,478 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 17:55:39,478 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:55:39,512 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1135745981_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:55:39,513 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:55:39,513 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1135745981_0001_r_000000_0' done.
   [druid] 2018-12-06 17:55:39,516 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:55:40,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:55:40,327 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1135745981_0001
   [druid] 2018-12-06 17:55:40,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:55:40,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:55:40,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 17:55:40,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387438
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:55:40,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:55:40,346 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 17:55:40,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=541065216
   [druid] 2018-12-06 17:57:54,845 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:57:54,847 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:57:54,871 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:57:54,913 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:57:55,029 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:57:55,405 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1239095269_0001
   [druid] 2018-12-06 17:57:55,414 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:57:55,422 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:57:55,438 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:57:55,439 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1239095269_0001_m_000000_0
   [druid] 2018-12-06 17:57:55,471 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:57:55,493 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:57:55,502 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:57:55,512 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:57:55,516 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:57:55,579 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:57:55,581 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:57:56,021 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:57:56,022 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:57:56,022 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1239095269_0001
   java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 13
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 13
	at com.qianfeng.analysis.mr.session.SessionMapper.map(SessionMapper.java:40)
	at com.qianfeng.analysis.mr.session.SessionMapper.map(SessionMapper.java:21)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-06 17:57:56,409 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 17:57:56,410 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1239095269_0001
   [druid] 2018-12-06 17:57:56,415 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-06 17:58:33,528 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:58:33,529 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:58:33,553 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:58:33,599 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:58:33,675 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:58:34,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1073586418_0001
   [druid] 2018-12-06 17:58:34,028 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:58:34,034 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:58:34,049 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:58:34,050 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1073586418_0001_m_000000_0
   [druid] 2018-12-06 17:58:34,074 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:58:34,097 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:58:34,107 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 17:58:34,116 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:58:34,119 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:58:34,157 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:58:34,158 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:58:34,635 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:58:34,641 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:58:34,671 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 17:58:34,680 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1073586418_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:58:34,693 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:58:34,694 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1073586418_0001_m_000000_0' done.
   [druid] 2018-12-06 17:58:34,694 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1073586418_0001_m_000000_0
   [druid] 2018-12-06 17:58:34,695 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:58:34,699 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:58:34,715 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:58:34,716 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:58:34,725 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:58:34,731 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 21230 bytes
   [druid] 2018-12-06 17:58:34,731 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:58:35,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 17:58:35,658 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1073586418_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:58:35,660 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:58:35,660 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1073586418_0001_r_000000_0' done.
   [druid] 2018-12-06 17:58:35,664 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:58:36,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:58:36,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1073586418_0001
   [druid] 2018-12-06 17:58:36,052 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:58:36,052 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:58:36,053 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21552
   [druid] 2018-12-06 17:58:36,053 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411910
   [druid] 2018-12-06 17:58:36,054 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:58:36,054 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:58:36,054 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:58:36,055 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 17:58:36,055 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:58:36,055 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:58:36,055 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:58:36,056 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:58:36,056 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:58:36,056 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 17:58:36,057 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=164
   [druid] 2018-12-06 17:58:36,057 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20900
   [druid] 2018-12-06 17:58:36,057 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 17:58:36,057 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:58:36,057 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:58:36,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 17:58:36,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:58:36,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=164
   [druid] 2018-12-06 17:58:36,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 17:58:36,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=328
   [druid] 2018-12-06 17:58:36,060 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486539264
   [druid] 2018-12-06 17:59:19,557 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 17:59:19,559 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 17:59:19,584 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 17:59:19,624 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 17:59:19,705 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 17:59:20,003 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local730853739_0001
   [druid] 2018-12-06 17:59:20,006 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 17:59:20,012 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 17:59:20,027 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 17:59:20,028 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local730853739_0001_m_000000_0
   [druid] 2018-12-06 17:59:20,062 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:59:20,084 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:59:20,092 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 17:59:20,105 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 17:59:20,109 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 17:59:20,141 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 17:59:20,141 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 17:59:20,566 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:59:20,570 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 17:59:20,600 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 17:59:20,610 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local730853739_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:59:20,624 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:59:20,624 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local730853739_0001_m_000000_0' done.
   [druid] 2018-12-06 17:59:20,624 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local730853739_0001_m_000000_0
   [druid] 2018-12-06 17:59:20,625 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 17:59:20,630 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 17:59:20,646 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 17:59:20,647 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:59:20,654 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 17:59:20,665 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 17:59:20,665 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 17:59:21,008 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 17:59:21,375 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local730853739_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 17:59:21,377 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 17:59:21,378 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local730853739_0001_r_000000_0' done.
   [druid] 2018-12-06 17:59:21,382 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 17:59:22,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 17:59:22,009 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local730853739_0001
   [druid] 2018-12-06 17:59:22,023 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 17:59:22,023 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 17:59:22,023 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 17:59:22,023 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392478
   [druid] 2018-12-06 17:59:22,023 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 17:59:22,024 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 17:59:22,024 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 17:59:22,025 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 17:59:22,025 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 17:59:22,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 17:59:22,026 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 17:59:22,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 17:59:22,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 17:59:22,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 17:59:22,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 17:59:22,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 17:59:22,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=487063552
   [druid] 2018-12-06 18:01:42,919 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 18:01:42,920 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 18:01:42,942 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 18:01:42,985 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 18:01:43,090 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 18:01:43,431 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 18:01:43,435 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local753907379_0001
   [druid] 2018-12-06 18:01:43,443 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 18:01:43,455 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 18:01:43,456 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local753907379_0001_m_000000_0
   [druid] 2018-12-06 18:01:43,481 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:01:43,503 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:01:43,511 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 18:01:43,520 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 18:01:43,523 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 18:01:43,565 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 18:01:43,565 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 18:01:44,042 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:01:44,046 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 18:01:44,071 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 18:01:44,080 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local753907379_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:01:44,098 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:01:44,099 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local753907379_0001_m_000000_0' done.
   [druid] 2018-12-06 18:01:44,099 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local753907379_0001_m_000000_0
   [druid] 2018-12-06 18:01:44,099 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 18:01:44,117 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:01:44,135 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:01:44,139 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:01:44,147 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 18:01:44,158 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 18:01:44,158 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:01:44,438 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 18:01:44,741 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local753907379_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:01:44,743 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 18:01:44,744 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local753907379_0001_r_000000_0' done.
   [druid] 2018-12-06 18:01:44,747 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 18:01:45,439 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 18:01:45,439 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local753907379_0001
   [druid] 2018-12-06 18:01:45,468 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 18:01:45,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 18:01:45,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 18:01:45,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392478
   [druid] 2018-12-06 18:01:45,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 18:01:45,469 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 18:01:45,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 18:01:45,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 18:01:45,470 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 18:01:45,471 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 18:01:45,472 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 18:01:45,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 18:01:45,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 18:01:45,473 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=429916160
   [druid] 2018-12-06 18:42:39,447 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 18:42:39,450 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 18:42:39,488 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 18:42:39,540 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 18:42:39,603 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 18:42:40,048 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1406341915_0001
   [druid] 2018-12-06 18:42:40,053 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 18:42:40,064 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 18:42:40,083 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 18:42:40,084 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1406341915_0001_m_000000_0
   [druid] 2018-12-06 18:42:40,120 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:42:40,159 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:42:40,215 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 18:42:40,228 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 18:42:40,232 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 18:42:40,315 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 18:42:40,315 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 18:42:41,055 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 18:42:42,314 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:42:42,319 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 18:42:42,350 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1406341915_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:42:42,363 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:42:42,364 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1406341915_0001_m_000000_0' done.
   [druid] 2018-12-06 18:42:42,364 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1406341915_0001_m_000000_0
   [druid] 2018-12-06 18:42:42,364 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 18:42:42,372 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:42:42,392 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:42:42,393 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:42:42,402 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 18:42:42,417 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 18:42:42,418 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:42:42,517 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1406341915_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:42:42,519 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 18:42:42,519 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1406341915_0001_r_000000_0' done.
   [druid] 2018-12-06 18:42:42,525 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 18:42:43,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 18:42:43,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1406341915_0001
   [druid] 2018-12-06 18:42:43,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 18:42:43,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 18:42:43,078 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387438
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 18:42:43,079 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 18:42:43,080 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 18:42:43,081 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=571473920
   [druid] 2018-12-06 18:43:28,285 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 18:43:28,287 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 18:43:28,318 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 18:43:28,363 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 18:43:28,439 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 18:43:28,843 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local32978530_0001
   [druid] 2018-12-06 18:43:28,846 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 18:43:28,858 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 18:43:28,876 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 18:43:28,878 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local32978530_0001_m_000000_0
   [druid] 2018-12-06 18:43:28,915 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:43:28,951 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:43:29,016 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 18:43:29,036 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 18:43:29,042 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 18:43:29,076 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 18:43:29,076 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 18:43:29,848 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 18:43:31,101 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:43:31,106 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 18:43:31,163 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local32978530_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:43:31,181 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:43:31,181 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local32978530_0001_m_000000_0' done.
   [druid] 2018-12-06 18:43:31,181 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local32978530_0001_m_000000_0
   [druid] 2018-12-06 18:43:31,184 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 18:43:31,189 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:43:31,203 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:43:31,219 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:43:31,231 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 18:43:31,247 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 18:43:31,248 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:43:31,341 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local32978530_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:43:31,342 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 18:43:31,343 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local32978530_0001_r_000000_0' done.
   [druid] 2018-12-06 18:43:31,345 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 18:43:31,850 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 18:43:31,850 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local32978530_0001
   [druid] 2018-12-06 18:43:31,865 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 18:43:31,865 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 18:43:31,865 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387422
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 18:43:31,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 18:43:31,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 18:43:31,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 18:43:31,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 18:43:31,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=563085312
   [druid] 2018-12-06 18:52:18,628 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 18:52:18,630 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 18:52:18,678 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 18:52:18,729 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 18:52:18,839 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 18:52:19,284 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1872950066_0001
   [druid] 2018-12-06 18:52:19,290 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 18:52:19,296 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 18:52:19,308 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 18:52:19,308 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1872950066_0001_m_000000_0
   [druid] 2018-12-06 18:52:19,334 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:52:19,355 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:52:19,364 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 18:52:19,373 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 18:52:19,376 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 18:52:19,449 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 18:52:19,449 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 18:52:20,289 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 18:52:21,474 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:21,477 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 18:52:21,495 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 18:52:21,504 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1872950066_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:52:21,517 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:21,518 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1872950066_0001_m_000000_0' done.
   [druid] 2018-12-06 18:52:21,518 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1872950066_0001_m_000000_0
   [druid] 2018-12-06 18:52:21,518 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 18:52:21,522 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:52:21,535 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:52:21,536 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:21,542 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 18:52:21,549 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1016 bytes
   [druid] 2018-12-06 18:52:21,549 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:21,817 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1872950066_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:52:21,818 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 18:52:21,818 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1872950066_0001_r_000000_0' done.
   [druid] 2018-12-06 18:52:21,820 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 18:52:22,292 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 18:52:22,292 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1872950066_0001
   [druid] 2018-12-06 18:52:22,310 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 18:52:22,310 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 18:52:22,310 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1338
   [druid] 2018-12-06 18:52:22,310 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389466
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 18:52:22,312 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=998
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 18:52:22,313 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 18:52:22,314 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=424673280
   [druid] 2018-12-06 18:52:39,307 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 18:52:39,310 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 18:52:39,339 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 18:52:39,441 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 18:52:39,481 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 18:52:39,860 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 18:52:39,861 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1303121485_0001
   [druid] 2018-12-06 18:52:39,869 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 18:52:39,884 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 18:52:39,885 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1303121485_0001_m_000000_0
   [druid] 2018-12-06 18:52:39,910 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:52:39,932 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:52:39,938 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 18:52:39,948 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 18:52:39,951 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 18:52:39,989 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 18:52:39,990 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 18:52:40,864 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 18:52:41,607 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:41,610 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 18:52:41,629 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 18:52:41,634 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1303121485_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:52:41,644 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:41,645 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1303121485_0001_m_000000_0' done.
   [druid] 2018-12-06 18:52:41,645 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1303121485_0001_m_000000_0
   [druid] 2018-12-06 18:52:41,654 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 18:52:41,665 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 18:52:41,688 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 18:52:41,696 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:41,704 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 18:52:41,715 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1094 bytes
   [druid] 2018-12-06 18:52:41,715 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 18:52:41,865 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1303121485_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 18:52:41,865 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 18:52:41,866 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1303121485_0001_r_000000_0' done.
   [druid] 2018-12-06 18:52:41,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 18:52:41,869 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 18:52:42,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1303121485_0001
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1418
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389624
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 18:52:42,880 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 18:52:42,884 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 18:52:42,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 18:52:42,886 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1076
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=3
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=3
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 18:52:42,887 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=574619648
   [druid] 2018-12-06 22:28:32,967 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:28:32,967 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:28:33,059 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:28:33,219 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:28:33,371 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:28:33,743 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:28:33,746 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1376737510_0001
   [druid] 2018-12-06 22:28:33,755 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:28:33,770 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:28:33,772 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1376737510_0001_m_000000_0
   [druid] 2018-12-06 22:28:33,795 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:28:33,820 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:28:33,828 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:28:33,835 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:28:33,838 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:28:33,900 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:28:33,900 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:28:34,753 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:40:14,526 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:40:14,529 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:40:14,581 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:40:14,663 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:40:14,708 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:40:14,999 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local34407324_0001
   [druid] 2018-12-06 22:40:15,022 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:40:15,029 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:40:15,045 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:40:15,046 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local34407324_0001_m_000000_0
   [druid] 2018-12-06 22:40:15,070 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:40:15,091 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:40:15,099 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:40:15,112 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:40:15,114 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:40:15,166 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:40:15,166 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:40:16,002 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:40:18,594 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:40:18,598 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:40:18,653 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:40:18,683 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local34407324_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:40:18,699 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:40:18,700 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local34407324_0001_m_000000_0' done.
   [druid] 2018-12-06 22:40:18,700 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local34407324_0001_m_000000_0
   [druid] 2018-12-06 22:40:18,700 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:40:18,708 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:40:18,724 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:40:18,727 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:40:18,737 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:40:18,745 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 19842 bytes
   [druid] 2018-12-06 22:40:18,745 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:42:00,670 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:42:00,672 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:42:00,716 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:42:00,757 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:42:00,825 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:42:01,111 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:42:01,111 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1326700266_0001
   [druid] 2018-12-06 22:42:01,117 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:42:01,129 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:42:01,129 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1326700266_0001_m_000000_0
   [druid] 2018-12-06 22:42:01,153 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:42:01,172 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:42:01,181 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:42:01,193 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:42:01,196 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:42:01,237 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:42:01,238 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:42:02,116 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:42:02,220 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:42:02,220 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:42:02,221 [Thread-4       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1326700266_0001
   java.lang.Exception: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:406)
Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.ArrayList.rangeCheck(ArrayList.java:653)
	at java.util.ArrayList.get(ArrayList.java:429)
	at com.qianfeng.analysis.util.MemberUtil.insertMemberId(MemberUtil.java:60)
	at com.qianfeng.analysis.mr.nm.NewMemberMapper.map(NewMemberMapper.java:66)
	at com.qianfeng.analysis.mr.nm.NewMemberMapper.map(NewMemberMapper.java:25)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:268)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-06 22:42:03,120 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1326700266_0001
   [druid] 2018-12-06 22:42:03,146 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 0
   [druid] 2018-12-06 22:43:10,883 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:43:10,885 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:43:10,915 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:43:10,958 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:43:11,113 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:43:11,437 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2142322522_0001
   [druid] 2018-12-06 22:43:11,439 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:43:11,445 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:43:11,458 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:43:11,459 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2142322522_0001_m_000000_0
   [druid] 2018-12-06 22:43:11,484 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:43:11,511 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:43:11,522 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:43:11,535 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:43:11,538 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:43:11,576 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:43:11,576 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:43:12,441 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:43:13,943 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:43:13,946 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:43:13,963 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:43:13,970 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2142322522_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:43:13,983 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:43:13,983 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2142322522_0001_m_000000_0' done.
   [druid] 2018-12-06 22:43:13,983 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2142322522_0001_m_000000_0
   [druid] 2018-12-06 22:43:13,983 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:43:13,987 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:43:13,999 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:43:13,999 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:43:14,004 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:43:14,012 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1016 bytes
   [druid] 2018-12-06 22:43:14,012 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:43:14,133 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2142322522_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:43:14,134 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:43:14,134 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2142322522_0001_r_000000_0' done.
   [druid] 2018-12-06 22:43:14,136 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:43:14,443 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:43:14,444 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2142322522_0001
   [druid] 2018-12-06 22:43:14,484 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:43:14,485 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:43:14,485 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1338
   [druid] 2018-12-06 22:43:14,486 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389466
   [druid] 2018-12-06 22:43:14,486 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:43:14,486 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:43:14,495 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:43:14,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 22:43:14,496 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:43:14,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:43:14,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:43:14,497 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:43:14,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:43:14,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 22:43:14,498 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 22:43:14,499 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=998
   [druid] 2018-12-06 22:43:14,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 22:43:14,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:43:14,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:43:14,501 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 22:43:14,501 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:43:14,501 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 22:43:14,501 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 22:43:14,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 22:43:14,502 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=550502400
   [druid] 2018-12-06 22:45:42,751 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:45:42,754 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:45:42,779 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:45:42,821 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:45:42,903 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:45:43,193 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1821760713_0001
   [druid] 2018-12-06 22:45:43,197 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:45:43,204 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:45:43,217 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:45:43,218 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1821760713_0001_m_000000_0
   [druid] 2018-12-06 22:45:43,245 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:45:43,265 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:45:43,276 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:45:43,288 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:45:43,293 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:45:43,347 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:45:43,347 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:45:44,201 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:45:45,974 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:45:45,977 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:45:45,995 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:45:46,004 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1821760713_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:45:46,017 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:45:46,018 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1821760713_0001_m_000000_0' done.
   [druid] 2018-12-06 22:45:46,018 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1821760713_0001_m_000000_0
   [druid] 2018-12-06 22:45:46,018 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:45:46,022 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:45:46,037 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:45:46,038 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:45:46,044 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:45:46,053 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1016 bytes
   [druid] 2018-12-06 22:45:46,053 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:45:46,201 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1821760713_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:45:46,202 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:45:46,203 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1821760713_0001_r_000000_0' done.
   [druid] 2018-12-06 22:45:46,206 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:45:46,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:45:46,210 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1821760713_0001
   [druid] 2018-12-06 22:45:46,227 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:45:46,228 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:45:46,230 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1338
   [druid] 2018-12-06 22:45:46,230 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389466
   [druid] 2018-12-06 22:45:46,230 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:45:46,230 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:45:46,231 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:45:46,231 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 22:45:46,231 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:45:46,231 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:45:46,231 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=998
   [druid] 2018-12-06 22:45:46,232 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 22:45:46,233 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 22:45:46,235 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 22:45:46,236 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=566231040
   [druid] 2018-12-06 22:49:15,016 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:49:15,018 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:49:15,048 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:49:15,106 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:49:15,180 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:49:15,481 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local2015131979_0001
   [druid] 2018-12-06 22:49:15,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:49:15,490 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:49:15,501 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:49:15,501 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2015131979_0001_m_000000_0
   [druid] 2018-12-06 22:49:15,523 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:49:15,546 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:49:15,555 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:49:15,563 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:49:15,566 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:49:15,612 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:49:15,613 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:49:16,485 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:49:17,516 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:17,519 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:49:17,543 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2015131979_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:49:17,552 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:17,552 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2015131979_0001_m_000000_0' done.
   [druid] 2018-12-06 22:49:17,552 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2015131979_0001_m_000000_0
   [druid] 2018-12-06 22:49:17,557 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:49:17,562 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:49:17,577 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:49:17,577 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:17,584 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:49:17,591 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-06 22:49:17,591 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:17,615 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2015131979_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:49:17,616 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:49:17,616 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2015131979_0001_r_000000_0' done.
   [druid] 2018-12-06 22:49:17,620 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:49:18,487 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:49:18,487 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local2015131979_0001
   [druid] 2018-12-06 22:49:18,512 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:49:18,512 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:49:18,513 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=324
   [druid] 2018-12-06 22:49:18,513 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=387438
   [druid] 2018-12-06 22:49:18,513 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:49:18,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:49:18,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:49:18,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 22:49:18,514 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:49:18,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:49:18,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:49:18,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:49:18,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:49:18,516 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 22:49:18,517 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=0
   [druid] 2018-12-06 22:49:18,517 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=0
   [druid] 2018-12-06 22:49:18,517 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 22:49:18,518 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:49:18,518 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:49:18,518 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=0
   [druid] 2018-12-06 22:49:18,518 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:49:18,519 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=0
   [druid] 2018-12-06 22:49:18,519 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=0
   [druid] 2018-12-06 22:49:18,519 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=0
   [druid] 2018-12-06 22:49:18,520 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=569376768
   [druid] 2018-12-06 22:49:33,114 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:49:33,116 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:49:33,144 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:49:33,190 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:49:33,268 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:49:33,586 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:49:33,587 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local342460672_0001
   [druid] 2018-12-06 22:49:33,593 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:49:33,607 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:49:33,608 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local342460672_0001_m_000000_0
   [druid] 2018-12-06 22:49:33,637 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:49:33,659 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:49:33,670 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 22:49:33,681 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:49:33,684 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:49:33,718 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:49:33,719 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:49:34,590 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:49:35,587 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:35,590 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:49:35,608 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:49:35,616 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local342460672_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:49:35,626 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:35,626 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local342460672_0001_m_000000_0' done.
   [druid] 2018-12-06 22:49:35,626 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local342460672_0001_m_000000_0
   [druid] 2018-12-06 22:49:35,627 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:49:35,630 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:49:35,647 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:49:35,648 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:35,654 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:49:35,661 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1094 bytes
   [druid] 2018-12-06 22:49:35,661 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:49:35,767 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local342460672_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:49:35,768 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:49:35,768 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local342460672_0001_r_000000_0' done.
   [druid] 2018-12-06 22:49:35,772 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:49:36,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:49:36,593 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local342460672_0001
   [druid] 2018-12-06 22:49:36,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:49:36,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:49:36,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1418
   [druid] 2018-12-06 22:49:36,640 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389616
   [druid] 2018-12-06 22:49:36,641 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:49:36,641 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:49:36,642 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:49:36,642 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 22:49:36,643 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:49:36,643 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:49:36,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:49:36,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:49:36,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:49:36,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 22:49:36,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 22:49:36,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1076
   [druid] 2018-12-06 22:49:36,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 22:49:36,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:49:36,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:49:36,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=3
   [druid] 2018-12-06 22:49:36,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:49:36,650 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 22:49:36,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=3
   [druid] 2018-12-06 22:49:36,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 22:49:36,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=571473920
   [druid] 2018-12-06 22:50:53,065 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:50:53,067 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:50:53,090 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:50:53,129 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:50:53,201 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:50:53,500 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local18340168_0001
   [druid] 2018-12-06 22:50:53,503 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:50:53,511 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:50:53,521 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:50:53,522 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local18340168_0001_m_000000_0
   [druid] 2018-12-06 22:50:53,548 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:50:53,572 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:50:53,580 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:50:53,592 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:50:53,596 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:50:53,640 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:50:53,641 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:50:54,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:50:57,504 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:50:57,506 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:50:57,532 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:50:57,545 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local18340168_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:50:57,557 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:50:57,557 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local18340168_0001_m_000000_0' done.
   [druid] 2018-12-06 22:50:57,557 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local18340168_0001_m_000000_0
   [druid] 2018-12-06 22:50:57,560 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:50:57,564 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:50:57,582 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:50:57,583 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:50:57,589 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:50:57,597 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 19018 bytes
   [druid] 2018-12-06 22:50:57,598 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:50:57,834 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local18340168_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:50:57,835 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:50:57,835 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local18340168_0001_r_000000_0' done.
   [druid] 2018-12-06 22:50:57,837 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:50:58,525 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:50:58,525 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local18340168_0001
   [druid] 2018-12-06 22:50:58,547 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:50:58,548 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:50:58,548 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=19340
   [druid] 2018-12-06 22:50:58,550 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=425454
   [druid] 2018-12-06 22:50:58,550 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:50:58,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:50:58,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:50:58,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 22:50:58,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:50:58,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:50:58,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:50:58,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:50:58,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:50:58,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 22:50:58,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=158
   [druid] 2018-12-06 22:50:58,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=18700
   [druid] 2018-12-06 22:50:58,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 22:50:58,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:50:58,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:50:58,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 22:50:58,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:50:58,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=158
   [druid] 2018-12-06 22:50:58,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 22:50:58,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=316
   [druid] 2018-12-06 22:50:58,557 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=568328192
   [druid] 2018-12-06 22:51:13,032 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:51:13,035 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:51:13,068 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:51:13,173 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:51:13,210 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:51:13,512 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:51:13,515 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local843084435_0001
   [druid] 2018-12-06 22:51:13,518 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:51:13,530 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:51:13,531 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local843084435_0001_m_000000_0
   [druid] 2018-12-06 22:51:13,551 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:51:13,572 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:51:13,581 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 22:51:13,589 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:51:13,592 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:51:13,631 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:51:13,631 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:51:14,520 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:51:15,560 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:51:15,562 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:51:15,585 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:51:15,595 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local843084435_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:51:15,619 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:51:15,620 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local843084435_0001_m_000000_0' done.
   [druid] 2018-12-06 22:51:15,620 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local843084435_0001_m_000000_0
   [druid] 2018-12-06 22:51:15,620 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:51:15,623 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:51:15,636 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:51:15,636 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:51:15,642 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:51:15,649 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11701 bytes
   [druid] 2018-12-06 22:51:15,649 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:51:15,825 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local843084435_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:51:15,826 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:51:15,826 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local843084435_0001_r_000000_0' done.
   [druid] 2018-12-06 22:51:15,829 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:51:16,521 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:51:16,523 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local843084435_0001
   [druid] 2018-12-06 22:51:16,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:51:16,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:51:16,551 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=12025
   [druid] 2018-12-06 22:51:16,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=410830
   [druid] 2018-12-06 22:51:16,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:51:16,552 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:51:16,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:51:16,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 22:51:16,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:51:16,553 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:51:16,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:51:16,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:51:16,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:51:16,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 22:51:16,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=88
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11523
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 22:51:16,555 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:51:16,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=88
   [druid] 2018-12-06 22:51:16,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 22:51:16,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=176
   [druid] 2018-12-06 22:51:16,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=567279616
   [druid] 2018-12-06 22:59:28,812 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:59:28,814 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:59:28,843 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:59:28,889 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:59:28,985 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:59:29,325 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local975279022_0001
   [druid] 2018-12-06 22:59:29,329 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:59:29,335 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:59:29,350 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:59:29,351 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local975279022_0001_m_000000_0
   [druid] 2018-12-06 22:59:29,376 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:59:29,398 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:59:29,408 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 22:59:29,419 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:59:29,423 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:59:29,490 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:59:29,490 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:59:30,340 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:59:32,151 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:32,154 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:59:32,172 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:59:32,180 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local975279022_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:59:32,191 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:32,191 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local975279022_0001_m_000000_0' done.
   [druid] 2018-12-06 22:59:32,191 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local975279022_0001_m_000000_0
   [druid] 2018-12-06 22:59:32,192 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:59:32,195 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:59:32,206 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:59:32,207 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:32,212 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:59:32,221 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1016 bytes
   [druid] 2018-12-06 22:59:32,221 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:32,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 22:59:32,353 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local975279022_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:59:32,354 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:59:32,354 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local975279022_0001_r_000000_0' done.
   [druid] 2018-12-06 22:59:32,357 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:59:33,344 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:59:33,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local975279022_0001
   [druid] 2018-12-06 22:59:33,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:59:33,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:59:33,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1338
   [druid] 2018-12-06 22:59:33,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389458
   [druid] 2018-12-06 22:59:33,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:59:33,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:59:33,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:59:33,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:59:33,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 22:59:33,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 22:59:33,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=998
   [druid] 2018-12-06 22:59:33,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 22:59:33,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:59:33,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:59:33,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=6
   [druid] 2018-12-06 22:59:33,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:59:33,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 22:59:33,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=6
   [druid] 2018-12-06 22:59:33,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 22:59:33,391 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=537919488
   [druid] 2018-12-06 22:59:50,310 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 22:59:50,312 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 22:59:50,366 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 22:59:50,416 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 22:59:50,493 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 22:59:50,813 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 22:59:50,814 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local258624091_0001
   [druid] 2018-12-06 22:59:50,820 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 22:59:50,833 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 22:59:50,833 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local258624091_0001_m_000000_0
   [druid] 2018-12-06 22:59:50,887 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:59:50,905 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:59:50,913 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 22:59:50,921 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 22:59:50,923 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 22:59:50,957 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 22:59:50,958 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 22:59:51,818 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 0% reduce 0%
   [druid] 2018-12-06 22:59:52,747 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:52,749 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 22:59:52,765 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 22:59:52,773 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local258624091_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:59:52,784 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:52,784 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local258624091_0001_m_000000_0' done.
   [druid] 2018-12-06 22:59:52,784 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local258624091_0001_m_000000_0
   [druid] 2018-12-06 22:59:52,785 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 22:59:52,789 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 22:59:52,807 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 22:59:52,807 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:52,813 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 22:59:52,821 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 22:59:52,821 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 1094 bytes
   [druid] 2018-12-06 22:59:52,821 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 22:59:52,917 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local258624091_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 22:59:52,918 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 22:59:52,918 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local258624091_0001_r_000000_0' done.
   [druid] 2018-12-06 22:59:52,921 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 22:59:53,821 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 22:59:53,822 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local258624091_0001
   [druid] 2018-12-06 22:59:53,858 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 22:59:53,858 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 22:59:53,858 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=1418
   [druid] 2018-12-06 22:59:53,859 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=389616
   [druid] 2018-12-06 22:59:53,859 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 22:59:53,860 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 22:59:53,862 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 22:59:53,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 22:59:53,866 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 22:59:53,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 22:59:53,867 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 22:59:53,868 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 22:59:53,868 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 22:59:53,868 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 22:59:53,869 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=8
   [druid] 2018-12-06 22:59:53,870 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=1076
   [druid] 2018-12-06 22:59:53,871 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 22:59:53,871 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 22:59:53,871 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 22:59:53,872 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=3
   [druid] 2018-12-06 22:59:53,872 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 22:59:53,873 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=8
   [druid] 2018-12-06 22:59:53,873 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=3
   [druid] 2018-12-06 22:59:53,873 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=16
   [druid] 2018-12-06 22:59:53,874 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=544210944
   [druid] 2018-12-06 23:07:39,915 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:07:39,917 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:07:39,935 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:07:39,972 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:07:40,053 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:07:40,337 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:07:40,341 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local954187576_0001
   [druid] 2018-12-06 23:07:40,343 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:07:40,354 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:07:40,355 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local954187576_0001_m_000000_0
   [druid] 2018-12-06 23:07:40,380 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:07:40,404 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:07:40,413 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 23:07:40,426 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:07:40,428 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:07:40,475 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:07:40,475 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:07:40,984 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:40,988 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:07:41,028 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:07:41,034 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local954187576_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:07:41,045 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:41,045 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local954187576_0001_m_000000_0' done.
   [druid] 2018-12-06 23:07:41,045 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local954187576_0001_m_000000_0
   [druid] 2018-12-06 23:07:41,046 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:07:41,052 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:07:41,070 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:07:41,071 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:41,078 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:07:41,088 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 21230 bytes
   [druid] 2018-12-06 23:07:41,088 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:41,345 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:07:41,953 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local954187576_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:07:41,954 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:07:41,954 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local954187576_0001_r_000000_0' done.
   [druid] 2018-12-06 23:07:41,957 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:07:42,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:07:42,347 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local954187576_0001
   [druid] 2018-12-06 23:07:42,377 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:07:42,378 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:07:42,379 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21552
   [druid] 2018-12-06 23:07:42,380 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411902
   [druid] 2018-12-06 23:07:42,381 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:07:42,382 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:07:42,382 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:07:42,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 23:07:42,383 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:07:42,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:07:42,384 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:07:42,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:07:42,385 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:07:42,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 23:07:42,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=164
   [druid] 2018-12-06 23:07:42,386 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20900
   [druid] 2018-12-06 23:07:42,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 23:07:42,387 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:07:42,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:07:42,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 23:07:42,388 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:07:42,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=164
   [druid] 2018-12-06 23:07:42,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 23:07:42,389 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=328
   [druid] 2018-12-06 23:07:42,390 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=439353344
   [druid] 2018-12-06 23:07:57,917 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:07:57,919 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:07:57,942 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:07:57,980 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:07:58,050 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:07:58,504 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:07:58,505 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local229519066_0001
   [druid] 2018-12-06 23:07:58,511 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:07:58,523 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:07:58,524 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local229519066_0001_m_000000_0
   [druid] 2018-12-06 23:07:58,548 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:07:58,573 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:07:58,580 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 23:07:58,588 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:07:58,592 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:07:58,632 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:07:58,632 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:07:59,201 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:59,206 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:07:59,280 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:07:59,288 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local229519066_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:07:59,310 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:59,311 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local229519066_0001_m_000000_0' done.
   [druid] 2018-12-06 23:07:59,311 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local229519066_0001_m_000000_0
   [druid] 2018-12-06 23:07:59,312 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:07:59,315 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:07:59,334 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:07:59,340 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:59,346 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:07:59,352 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 23:07:59,353 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:07:59,509 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:08:00,002 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local229519066_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:08:00,003 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:08:00,004 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local229519066_0001_r_000000_0' done.
   [druid] 2018-12-06 23:08:00,007 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:08:00,510 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:08:00,511 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local229519066_0001
   [druid] 2018-12-06 23:08:00,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:08:00,554 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:08:00,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 23:08:00,556 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392478
   [druid] 2018-12-06 23:08:00,557 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:08:00,557 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:08:00,557 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:08:00,558 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 23:08:00,559 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:08:00,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:08:00,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:08:00,560 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:08:00,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:08:00,561 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 23:08:00,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 23:08:00,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 23:08:00,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 23:08:00,562 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 23:08:00,563 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 23:08:00,564 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=438304768
   [druid] 2018-12-06 23:16:11,062 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:16:11,064 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:16:11,095 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:16:11,149 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:16:11,250 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:16:11,589 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:16:11,592 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1687074277_0001
   [druid] 2018-12-06 23:16:11,595 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:16:11,607 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:16:11,607 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1687074277_0001_m_000000_0
   [druid] 2018-12-06 23:16:11,627 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:16:11,647 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:16:11,656 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 23:16:11,665 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:16:11,667 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:16:11,742 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:16:11,743 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:16:12,233 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:12,237 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:16:12,268 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:16:12,320 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1687074277_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:16:12,336 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:12,337 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1687074277_0001_m_000000_0' done.
   [druid] 2018-12-06 23:16:12,337 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1687074277_0001_m_000000_0
   [druid] 2018-12-06 23:16:12,338 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:16:12,344 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:16:12,365 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:16:12,366 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:12,374 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:16:12,385 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 21230 bytes
   [druid] 2018-12-06 23:16:12,386 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:12,600 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:16:13,727 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1687074277_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:16:13,729 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:16:13,730 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1687074277_0001_r_000000_0' done.
   [druid] 2018-12-06 23:16:13,734 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:16:14,602 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:16:14,603 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1687074277_0001
   [druid] 2018-12-06 23:16:14,643 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:16:14,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:16:14,644 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21552
   [druid] 2018-12-06 23:16:14,645 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411910
   [druid] 2018-12-06 23:16:14,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:16:14,646 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:16:14,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:16:14,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 23:16:14,647 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:16:14,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:16:14,648 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:16:14,649 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:16:14,649 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:16:14,649 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 23:16:14,650 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=164
   [druid] 2018-12-06 23:16:14,650 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20900
   [druid] 2018-12-06 23:16:14,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 23:16:14,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:16:14,651 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:16:14,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 23:16:14,652 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:16:14,653 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=164
   [druid] 2018-12-06 23:16:14,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 23:16:14,654 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=328
   [druid] 2018-12-06 23:16:14,655 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=430964736
   [druid] 2018-12-06 23:16:39,598 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:16:39,601 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:16:39,628 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:16:39,671 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:16:39,739 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:16:40,030 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:16:40,031 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local973526443_0001
   [druid] 2018-12-06 23:16:40,036 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:16:40,047 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:16:40,048 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local973526443_0001_m_000000_0
   [druid] 2018-12-06 23:16:40,068 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:16:40,085 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:16:40,093 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 23:16:40,104 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:16:40,107 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:16:40,147 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:16:40,147 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:16:40,659 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:40,664 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:16:40,851 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:16:40,878 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local973526443_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:16:40,894 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:40,895 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local973526443_0001_m_000000_0' done.
   [druid] 2018-12-06 23:16:40,895 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local973526443_0001_m_000000_0
   [druid] 2018-12-06 23:16:40,897 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:16:40,904 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:16:40,926 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:16:40,926 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:40,933 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:16:40,941 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 23:16:40,941 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:16:41,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:16:41,671 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local973526443_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:16:41,673 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:16:41,673 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local973526443_0001_r_000000_0' done.
   [druid] 2018-12-06 23:16:41,679 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:16:42,038 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:16:42,039 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local973526443_0001
   [druid] 2018-12-06 23:16:42,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:16:42,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:16:42,058 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 23:16:42,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392478
   [druid] 2018-12-06 23:16:42,059 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:16:42,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:16:42,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:16:42,061 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:16:42,062 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 23:16:42,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 23:16:42,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 23:16:42,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 23:16:42,063 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:16:42,065 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:16:42,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 23:16:42,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:16:42,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 23:16:42,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 23:16:42,066 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 23:16:42,067 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=418381824
   [druid] 2018-12-06 23:19:07,186 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:19:07,188 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:19:07,213 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:19:07,261 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:19:07,356 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:19:07,617 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1352031564_0001
   [druid] 2018-12-06 23:19:07,628 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:19:07,636 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:19:07,651 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:19:07,652 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1352031564_0001_m_000000_0
   [druid] 2018-12-06 23:19:07,674 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:19:07,695 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:19:07,703 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 23:19:07,713 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:19:07,717 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:19:07,771 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:19:07,772 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:19:08,270 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:08,273 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:19:08,406 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:19:08,419 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1352031564_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:19:08,434 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:08,434 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1352031564_0001_m_000000_0' done.
   [druid] 2018-12-06 23:19:08,434 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1352031564_0001_m_000000_0
   [druid] 2018-12-06 23:19:08,435 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:19:08,441 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:19:08,458 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:19:08,458 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:08,466 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:19:08,478 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 21230 bytes
   [druid] 2018-12-06 23:19:08,478 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:08,621 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:19:09,172 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1352031564_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:19:09,173 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:19:09,173 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1352031564_0001_r_000000_0' done.
   [druid] 2018-12-06 23:19:09,177 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:19:09,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:19:09,622 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1352031564_0001
   [druid] 2018-12-06 23:19:09,635 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21552
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411910
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:19:09,636 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=164
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20900
   [druid] 2018-12-06 23:19:09,637 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=164
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 23:19:09,638 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=328
   [druid] 2018-12-06 23:19:09,639 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=486539264
   [druid] 2018-12-06 23:19:26,010 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:19:26,019 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:19:26,047 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:19:26,096 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:19:26,171 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:19:26,437 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local322464914_0001
   [druid] 2018-12-06 23:19:26,442 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:19:26,448 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:19:26,459 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:19:26,460 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local322464914_0001_m_000000_0
   [druid] 2018-12-06 23:19:26,487 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:19:26,513 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:19:26,523 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 23:19:26,533 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:19:26,536 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:19:26,579 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:19:26,579 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:19:27,060 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:27,062 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:19:27,118 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:19:27,124 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local322464914_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:19:27,140 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:27,140 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local322464914_0001_m_000000_0' done.
   [druid] 2018-12-06 23:19:27,140 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local322464914_0001_m_000000_0
   [druid] 2018-12-06 23:19:27,141 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:19:27,145 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:19:27,163 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:19:27,165 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:27,173 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:19:27,182 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 23:19:27,182 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:19:27,443 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:19:27,860 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local322464914_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:19:27,863 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:19:27,863 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local322464914_0001_r_000000_0' done.
   [druid] 2018-12-06 23:19:27,873 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:19:28,444 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:19:28,444 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local322464914_0001
   [druid] 2018-12-06 23:19:28,458 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:19:28,459 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:19:28,459 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 23:19:28,459 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392478
   [druid] 2018-12-06 23:19:28,459 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:19:28,459 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:19:28,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:19:28,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 23:19:28,460 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 23:19:28,461 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 23:19:28,462 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 23:19:28,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 23:19:28,463 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=574619648
   [druid] 2018-12-06 23:24:18,120 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:24:18,122 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:24:18,151 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:24:18,216 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:24:18,302 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:24:18,621 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:24:18,624 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1487549208_0001
   [druid] 2018-12-06 23:24:18,627 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:24:18,640 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:24:18,640 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1487549208_0001_m_000000_0
   [druid] 2018-12-06 23:24:18,663 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:24:18,687 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:24:18,697 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/11/part-m-00000:0+40442
   [druid] 2018-12-06 23:24:18,709 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:24:18,712 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:24:18,749 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:24:18,750 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:24:19,244 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:19,247 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:24:19,281 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:24:19,287 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1487549208_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:24:19,298 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:19,298 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1487549208_0001_m_000000_0' done.
   [druid] 2018-12-06 23:24:19,299 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1487549208_0001_m_000000_0
   [druid] 2018-12-06 23:24:19,299 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:24:19,302 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:24:19,316 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:24:19,317 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:19,323 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:24:19,328 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 21230 bytes
   [druid] 2018-12-06 23:24:19,328 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:19,626 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:24:19,921 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1487549208_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:24:19,922 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:24:19,923 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1487549208_0001_r_000000_0' done.
   [druid] 2018-12-06 23:24:19,925 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:24:20,627 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:24:20,627 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1487549208_0001
   [druid] 2018-12-06 23:24:20,659 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:24:20,659 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:24:20,661 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=21552
   [druid] 2018-12-06 23:24:20,662 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=411910
   [druid] 2018-12-06 23:24:20,662 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:24:20,662 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:24:20,663 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:24:20,663 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=80884
   [druid] 2018-12-06 23:24:20,663 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:24:20,663 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:24:20,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:24:20,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:24:20,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:24:20,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=82
   [druid] 2018-12-06 23:24:20,664 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=164
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=20900
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=106
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=12
   [druid] 2018-12-06 23:24:20,665 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:24:20,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=164
   [druid] 2018-12-06 23:24:20,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=12
   [druid] 2018-12-06 23:24:20,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=328
   [druid] 2018-12-06 23:24:20,666 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=418381824
   [druid] 2018-12-06 23:24:44,514 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-06 23:24:44,516 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-06 23:24:44,540 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
   [druid] 2018-12-06 23:24:44,581 [main           ] WARN  apache.hadoop.mapred.JobClient {1} - No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
   [druid] 2018-12-06 23:24:44,678 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-06 23:24:44,972 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-06 23:24:44,972 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Running job: job_local1450280221_0001
   [druid] 2018-12-06 23:24:44,978 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-06 23:24:44,989 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-06 23:24:44,990 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1450280221_0001_m_000000_0
   [druid] 2018-12-06 23:24:45,012 [pool-4-thread-1] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:24:45,031 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:24:45,040 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://hadoop:8020/ods/11/12/part-m-000001:0+22487
   [druid] 2018-12-06 23:24:45,051 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-06 23:24:45,054 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - io.sort.mb = 100
   [druid] 2018-12-06 23:24:45,086 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - data buffer = 79691776/99614720
   [druid] 2018-12-06 23:24:45,086 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - record buffer = 262144/327680
   [druid] 2018-12-06 23:24:45,531 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:45,545 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-06 23:24:45,593 [pool-4-thread-1] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-06 23:24:45,606 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1450280221_0001_m_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:24:45,623 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:45,623 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1450280221_0001_m_000000_0' done.
   [druid] 2018-12-06 23:24:45,623 [pool-4-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1450280221_0001_m_000000_0
   [druid] 2018-12-06 23:24:45,624 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Map task executor complete.
   [druid] 2018-12-06 23:24:45,627 [Thread-4       ] WARN  mapreduce.Counters             {1} - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
   [druid] 2018-12-06 23:24:45,640 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorPlugin : null
   [druid] 2018-12-06 23:24:45,640 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:45,645 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-06 23:24:45,652 [Thread-4       ] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 11517 bytes
   [druid] 2018-12-06 23:24:45,652 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-06 23:24:45,977 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 0%
   [druid] 2018-12-06 23:24:46,279 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1450280221_0001_r_000000_0 is done. And is in the process of commiting
   [druid] 2018-12-06 23:24:46,281 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-06 23:24:46,282 [Thread-4       ] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1450280221_0001_r_000000_0' done.
   [druid] 2018-12-06 23:24:46,289 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output path is null in cleanup
   [druid] 2018-12-06 23:24:46,981 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -  map 100% reduce 100%
   [druid] 2018-12-06 23:24:46,982 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Job complete: job_local1450280221_0001
   [druid] 2018-12-06 23:24:47,025 [main           ] INFO  apache.hadoop.mapred.JobClient {1} - Counters: 22
   [druid] 2018-12-06 23:24:47,025 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   File System Counters
   [druid] 2018-12-06 23:24:47,027 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes read=11841
   [druid] 2018-12-06 23:24:47,028 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of bytes written=392486
   [druid] 2018-12-06 23:24:47,030 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of read operations=0
   [druid] 2018-12-06 23:24:47,031 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of large read operations=0
   [druid] 2018-12-06 23:24:47,031 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     FILE: Number of write operations=0
   [druid] 2018-12-06 23:24:47,032 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes read=44974
   [druid] 2018-12-06 23:24:47,032 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of bytes written=0
   [druid] 2018-12-06 23:24:47,033 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of read operations=10
   [druid] 2018-12-06 23:24:47,033 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of large read operations=0
   [druid] 2018-12-06 23:24:47,033 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     HDFS: Number of write operations=0
   [druid] 2018-12-06 23:24:47,034 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -   Map-Reduce Framework
   [druid] 2018-12-06 23:24:47,034 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map input records=45
   [druid] 2018-12-06 23:24:47,034 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output records=90
   [druid] 2018-12-06 23:24:47,034 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Map output bytes=11335
   [druid] 2018-12-06 23:24:47,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Input split bytes=107
   [druid] 2018-12-06 23:24:47,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine input records=0
   [druid] 2018-12-06 23:24:47,035 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Combine output records=0
   [druid] 2018-12-06 23:24:47,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input groups=9
   [druid] 2018-12-06 23:24:47,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce shuffle bytes=0
   [druid] 2018-12-06 23:24:47,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce input records=90
   [druid] 2018-12-06 23:24:47,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Reduce output records=9
   [druid] 2018-12-06 23:24:47,036 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Spilled Records=180
   [druid] 2018-12-06 23:24:47,037 [main           ] INFO  apache.hadoop.mapred.JobClient {1} -     Total committed heap usage (bytes)=433061888
   